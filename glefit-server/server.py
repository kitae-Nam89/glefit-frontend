# -*- coding: utf-8 -*-
import os, re, json, time, sqlite3, unicodedata
from dotenv import load_dotenv
from flask import Flask, request, jsonify
from flask_cors import CORS

# [ADD] Auth imports
from datetime import datetime, timedelta
from functools import wraps
import jwt
from passlib.hash import pbkdf2_sha256 as bcrypt


from openai import OpenAI
import yaml
from collections import defaultdict
# --- [LOCAL SPELLCHECK] begin ---
import os, re
from symspellpy import SymSpell, Verbosity
import uuid

_HANGUL_RE = re.compile(r"[ê°€-í£]+")
DATA_DIR = "data"
KO_WORDS_PATH = os.path.join(DATA_DIR, "ko_words.txt")   # "ë‹¨ì–´<TAB>ë¹ˆë„"
WHITE_PATH    = os.path.join(DATA_DIR, "whitelist.txt")  # ì¤„ë‹¹ 1ê°œ ë‹¨ì–´

_sym = None
_whitelist = set()

def _init_symspell():
    import os
    os.makedirs(DATA_DIR, exist_ok=True)
    global _sym, _whitelist
    _sym = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)

    if os.path.exists(KO_WORDS_PATH):
        _sym.load_dictionary(KO_WORDS_PATH, term_index=0, count_index=1,
                             separator="\t", encoding="utf-8")

    custom_path = os.path.join(DATA_DIR, "custom_words.txt")
    if os.path.exists(custom_path):
        _sym.load_dictionary(custom_path, term_index=0, count_index=1,
                             separator="\t", encoding="utf-8")

    _whitelist = set()
    if os.path.exists(WHITE_PATH):
        for enc in ("utf-8","utf-8-sig","cp949","euc-kr"):
            try:
                with open(WHITE_PATH,"r",encoding=enc) as f:
                    _whitelist = {ln.strip() for ln in f if ln.strip()}
                break
            except UnicodeDecodeError:
                continue

    print(f"ğŸ”¤ SymSpell ready: words={len(_sym.words)}, whitelist={len(_whitelist)}")

def _token_spans_ko(text: str):
    """í•œê¸€ ì—°ì†êµ¬ê°„ì„ í† í°ìœ¼ë¡œ ë½‘ì•„ (start, end, token)"""
    for m in _HANGUL_RE.finditer(text or ""):
        yield m.start(), m.end(), m.group()
# --- [LOCAL SPELLCHECK] end ---


# ================== ê¸°ë³¸ ì„¤ì • ==================
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (.env í™•ì¸)")

client = OpenAI(api_key=OPENAI_API_KEY, timeout=30)

MODEL = "gpt-4o"
DB_PATH = "rewrite.db"
MAX_CHARS_PER_CHUNK = 4000

# [ADD] JWT config
JWT_SECRET = os.getenv("JWT_SECRET", "CHANGE_ME_TO_RANDOM_SECRET")
JWT_ALG = "HS256"
# [ADD] ensure users table
def ensure_users_table():
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS users (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        username TEXT UNIQUE NOT NULL,
        password_hash TEXT NOT NULL,
        is_active INTEGER DEFAULT 0,
        paid_until TEXT,
        role TEXT DEFAULT 'user',
        notes TEXT
    )
    """)
    conn.commit()
    conn.close()

ensure_users_table()

def migrate_users_table():
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    # ê³ ê° ì ‘ì† ì£¼ì†Œ ë³´ê´€(ì„ íƒ)
    try:
        cur.execute("ALTER TABLE users ADD COLUMN site_url TEXT")
    except Exception:
        pass
    # ìƒì„± ì‹œê°(ê´€ë¦¬ í¸ì˜)
    try:
        cur.execute("ALTER TABLE users ADD COLUMN created_at TEXT")
    except Exception:
        pass

    # â˜…â˜…â˜… ë™ì‹œì ‘ì† ì œì–´ìš© ì»¬ëŸ¼ ì¶”ê°€ â˜…â˜…â˜…
    try:
        cur.execute("ALTER TABLE users ADD COLUMN token_version INTEGER DEFAULT 0")
    except Exception:
        pass
    try:
        cur.execute("ALTER TABLE users ADD COLUMN last_jti TEXT")
    except Exception:
        pass

    conn.commit()
    conn.close()

migrate_users_table()

# [ADD] user helpers & guards
def _get_user(username: str):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("SELECT id, username, password_hash, is_active, paid_until, role FROM users WHERE username = ?", (username,))
    row = cur.fetchone()
    conn.close()
    if not row:
        return None
    return {
        "id": row[0], "username": row[1], "password_hash": row[2],
        "is_active": bool(row[3]),
        "paid_until": row[4],
        "role": row[5] or "user",
    }

def _remaining_days(paid_until: str) -> int:
    if not paid_until:
        return 0
    try:
        delta = datetime.fromisoformat(paid_until) - datetime.utcnow()
        return max(0, delta.days)
    except Exception:
        return 0

def _is_paid_and_active(u: dict) -> bool:
    if not u or not u.get("is_active"):
        return False
    try:
        pu = u.get("paid_until")
        if not pu:
            return False
        return datetime.utcnow() <= datetime.fromisoformat(pu)
    except Exception:
        return False

def _origin_allowed(user_site_url: str) -> bool:
    if not user_site_url:
        return True  # ì£¼ì†Œ ì œí•œ ì•ˆ ê±´ ê³„ì •
    origin = (request.headers.get("Origin") or "").lower()
    referer = (request.headers.get("Referer") or "").lower()
    target = user_site_url.lower()
    return (target in origin) or (target in referer)

def require_user(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        if request.method == "OPTIONS":
            return "", 200

        auth = request.headers.get("Authorization","").strip()
        if not auth.startswith("Bearer "):
            return jsonify({"error":"Unauthorized"}), 401
        token = auth.split(" ",1)[1]

        try:
            data = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALG])
        except Exception:
            return jsonify({"error":"Invalid token"}), 401

        username = data.get("sub","")
        tok_ver  = int(data.get("ver", 0) or 0)
        tok_jti  = data.get("jti","") or ""

        # DBì—ì„œ ìµœì‹  ìƒíƒœ(í™œì„±/ê¸°ê°„/ì‚¬ì´íŠ¸/ë²„ì „/JTI) í™•ì¸
        conn = sqlite3.connect(DB_PATH)
        cur  = conn.cursor()
        cur.execute("SELECT is_active, paid_until, site_url, token_version, last_jti FROM users WHERE username=?", (username,))
        row = cur.fetchone()
        conn.close()

        if not row:
            return jsonify({"error":"Unauthorized"}), 401

        is_active, paid_until, site_url, db_ver, db_jti = row[0], row[1], (row[2] or ""), int(row[3] or 0), (row[4] or "")

        # ê²°ì œ/ê¸°ê°„/í™œì„± ì²´í¬
        try:
            if not is_active or not paid_until or datetime.utcnow() > datetime.fromisoformat(paid_until):
                return jsonify({"error":"Payment required or expired"}), 402
        except Exception:
            return jsonify({"error":"Payment required or expired"}), 402

        # â˜… ë‹¨ì¼ ë¡œê·¸ì¸ ê°•ì œ: í† í°ì˜ ver/jtiê°€ DBì˜ ìµœì‹ ê°’ê³¼ ì¼ì¹˜í•´ì•¼ í†µê³¼
        if tok_ver != db_ver or (db_jti and tok_jti != db_jti):
            return jsonify({"error":"Session invalidated. Please log in again.", "code":"SESSION"}), 401

        # ë„ë©”ì¸ ì œí•œ(ì˜µì…˜)
        if site_url:
            origin  = (request.headers.get("Origin") or "").lower()
            referer = (request.headers.get("Referer") or "").lower()
            if site_url.lower() not in origin and site_url.lower() not in referer:
                return jsonify({"error":"Origin not allowed"}), 403

        return fn(*args, **kwargs)
    return wrapper

def require_admin(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        auth = request.headers.get("Authorization","").strip()
        if not auth.startswith("Bearer "):
            return jsonify({"error":"Unauthorized"}), 401
        token = auth.split(" ",1)[1]

        try:
            data = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALG])
        except Exception:
            return jsonify({"error":"Invalid token"}), 401

        username = data.get("sub","")
        tok_ver  = int(data.get("ver", 0) or 0)
        tok_jti  = data.get("jti","") or ""

        conn = sqlite3.connect(DB_PATH)
        cur  = conn.cursor()
        cur.execute("SELECT role, is_active, paid_until, token_version, last_jti FROM users WHERE username=?", (username,))
        row = cur.fetchone()
        conn.close()

        if not row:
            return jsonify({"error":"Unauthorized"}), 401

        role, is_active, paid_until, db_ver, db_jti = (row[0] or "user"), row[1], row[2], int(row[3] or 0), (row[4] or "")

        # ê²°ì œ/ê¸°ê°„/í™œì„± ì²´í¬
        try:
            if not is_active or not paid_until or datetime.utcnow() > datetime.fromisoformat(paid_until):
                return jsonify({"error":"Payment required or expired"}), 402
        except Exception:
            return jsonify({"error":"Payment required or expired"}), 402

        # ë‹¨ì¼ ë¡œê·¸ì¸ ê°•ì œ
        if tok_ver != db_ver or (db_jti and tok_jti != db_jti):
            return jsonify({"error":"Session invalidated. Please log in again.", "code":"SESSION"}), 401

        if role != "admin":
            return jsonify({"error":"Admin only"}), 403

        return fn(*args, **kwargs)
    return wrapper


RULE_PATH = os.getenv("RULE_PATH", "kr-medhealth.yaml")
RULES = {}   # {"rules":[{...}], ...}
RULES_INDEX = {}  # {rule_id: rule_obj}

# ================== ìœ í‹¸ ==================
def search_db(sentence):
    try:
        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()
        cur.execute("SELECT alternative FROM sentences WHERE original = ?", (sentence,))
        rows = cur.fetchall()
        conn.close()
        return [r[0] for r in rows] if rows else []
    except Exception as e:
        print("DB ê²€ìƒ‰ ì˜¤ë¥˜:", e)
        return []

def find_all(text, substring, start_from=0):
    out = []
    i = start_from
    L = len(substring)
    if not substring:
        return out
    while True:
        i = text.find(substring, i)
        if i == -1:
            break
        out.append(i)
        i += L
    return out

def chunk_text_with_offsets(text, max_chars=MAX_CHARS_PER_CHUNK):
    chunks = []
    n = len(text)
    i = 0
    while i < n:
        end = min(i + max_chars, n)
        if end < n:
            cut = text.rfind("\n", i, end)
            if cut == -1 or cut <= i + int(max_chars * 0.3):
                cut = end
        else:
            cut = end
        chunks.append((i, text[i:cut]))
        i = cut
    return chunks

_json_array_pattern = re.compile(r"\[\s*{.*?}\s*\]", re.DOTALL)
def extract_json_array(s):
    if not s:
        return []
    s = re.sub(r"^```json\s*|\s*```$", "", s.strip(), flags=re.IGNORECASE | re.DOTALL)
    m = _json_array_pattern.search(s)
    if not m:
        try:
            j = json.loads(s)
            return j if isinstance(j, list) else []
        except:
            return []
    try:
        return json.loads(m.group(0))
    except Exception as e:
        print("JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        return []

def basic_kr_sentence_split(text):
    parts = re.split(r"([\.?!]+|\n+)", text)
    out, buf = [], ""
    for p in parts:
        if p is None:
            continue
        buf += p
        if p.endswith((".", "?", "!", "\n")) or p.strip() == "":
            s = buf.strip()
            if s:
                out.append(s)
            buf = ""
    if buf.strip():
        out.append(buf.strip())
    return out

def add_context(text, start, length, window=8):
    before = text[max(0, start - window): start]
    after  = text[start + length: start + length + window]
    return before, after

def gpt_call(model, messages):
    return client.chat.completions.create(model=model, messages=messages)

# --- ê³µë°±/ë¬¸ì ì •ê·œí™” & ê³µë°±ë¬´ì‹œ í‚¤ì›Œë“œìš© ---
def kr_norm(s: str) -> str:
    s = unicodedata.normalize("NFKC", s or "")
    s = s.replace("%", "í¼ì„¼íŠ¸")
    s = re.sub(r"\s+", " ", s)
    return s

def spacing_agnostic_regex(kw: str) -> str:
    parts = list(kw)
    return r"\s*".join(map(re.escape, parts))

# ================== ì‹¬ì˜ ê·œì¹™ ë¡œë”©/ìŠ¤ìº” ==================
def load_rules(path=RULE_PATH):
    global RULES, RULES_INDEX
    try:
        with open(path, "r", encoding="utf-8") as f:
            RULES = yaml.safe_load(f) or {}
        if not isinstance(RULES, dict):
            RULES = {}
        print(f"âœ… ì‹¬ì˜ ê·œì¹™ ë¡œë“œ ì™„ë£Œ: {path}")
        pack = RULES.get("pack")
        ver = RULES.get("version")
        topics = RULES.get("topics")
        if pack or ver or topics:
            print(f"  - pack={pack}, version={ver}, topics={topics}")
        RULES_INDEX = {}
        for r in (RULES.get("rules") or []):
            rid = (r or {}).get("id")
            if rid:
                RULES_INDEX[str(rid)] = r
        print(f"  - rules indexed: {len(RULES_INDEX)}")
    except Exception as e:
        print("[WARN] ì‹¬ì˜ ê·œì¹™ ë¡œë“œ ì‹¤íŒ¨:", e)
        RULES, RULES_INDEX = {}, {}


load_rules()

# === (ADD) ì‚¬ìœ /ë²•ë ¹ ë§¤í•‘ ìœ í‹¸ (YAML meta ì‚¬ìš©) ====================
def _load_reason_index_from_rules():
    meta = (RULES or {}).get("meta") or {}
    cats = meta.get("reason_categories") or {}
    mapping = []
    for ent in meta.get("rule_category_by_prefix") or []:
        try:
            rx = re.compile(ent.get("pattern", ""), re.IGNORECASE)
            mapping.append((rx, ent.get("category")))
        except re.error:
            pass
    return cats, mapping

REASON_CATS, REASON_MAP = _load_reason_index_from_rules()

def _reason_for_rule_id(rule_id: str):
    rid = rule_id or ""
    for rx, cat in (REASON_MAP or []):
        if rx.search(rid):
            info = (REASON_CATS or {}).get(cat) or {}
            reason = info.get("reason")
            legal  = info.get("legal")
            url    = info.get("legal_url")
            if not reason:
                return None, None
            small = None
            if legal and url:
                small = f"<small style='color:#777'>(ê·¼ê±°: {legal} Â· <a href=\"{url}\" target=\"_blank\">ë²•ë ¹</a>)</small>"
            elif legal:
                small = f"<small style='color:#777'>(ê·¼ê±°: {legal})</small>"
            return f"ì‚¬ìœ : {reason}", small
    return None, None

_rule_id_rx = re.compile(r"\(rule:([^)]+)\)")
def attach_reasons(items):
    """
    ê²°ê³¼ í•­ëª©ì— ì‚¬ìš©ì ì¹œí™”ì  ì‚¬ìœ /ì¶œì²˜ë¥¼ ë¶€ì°©í•˜ê³ ,
    ë‚´ë¶€ rule ID ë…¸ì¶œì„ ì œê±°í•œë‹¤.
    ìš°ì„ ìˆœìœ„:
      1) RULES_INDEX[rule_id]ì˜ rationale / legal_ref
      2) meta(reason_categories/rule_category_by_prefix) í´ë°±
    """
    for it in items:
        rid = it.get("rule_id")
        if not rid:
            m = _rule_id_rx.search(it.get("reason","") or "")
            rid = m.group(1) if m else None

        reason_line = None
        legal_small = None

        # 1) ê·œì¹™ ë³¸ë¬¸ì—ì„œ ì§ì ‘ ì·¨ë“
        rule = RULES_INDEX.get(str(rid)) if rid else None
        if rule:
            rationale = rule.get("rationale") or rule.get("description") or ""
            legal     = rule.get("legal_ref")  or ""   # YAMLì— ì„ íƒì ìœ¼ë¡œ ì¶”ê°€
            if rationale:
                reason_line = rationale
            if legal:
                legal_small = f"<small style='color:#777'>(ì¶œì²˜: {legal})</small>"

        # 2) í´ë°±: meta ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì‚¬ìš©
        if not reason_line:
            rline, small = _reason_for_rule_id(rid or "")
            if rline:
                # rline ì˜ˆ: "ì‚¬ìœ : â€¦" í˜•íƒœ â†’ í†µì¼ ìœ„í•´ ì ‘ë‘ì–´ ì œê±°
                reason_line = rline.replace("ì‚¬ìœ :", "").strip()
            if small:
                legal_small = small

        if reason_line:
            it["reason_line"] = reason_line
        if legal_small:
            it["legal_small"] = legal_small

        # í™”ë©´ ë…¸ì¶œìš© reason ë¬¸ìì—´ì—ì„œ (rule:XXX) ì œê±°
        if it.get("reason"):
            it["reason"] = re.sub(_rule_id_rx, "", it["reason"]).strip()
    return items# =====================================================================

def _iter_rule_patterns(rule):
    patterns = ((rule or {}).get("patterns") or {}).get("any") or []
    for p in patterns:
        if not isinstance(p, dict):
            continue
        if p.get("type") in ("keyword", "regex", "phrase"):
            yield p

def _compile_regex_from_pattern(pat: dict):
    ptype = pat.get("type")
    flags = 0
    if str(pat.get("flags","")).lower().find("i") >= 0 or pat.get("casefold", True):
        flags |= re.IGNORECASE

    if ptype == "keyword":
        val = kr_norm(pat.get("value",""))
        if not val:
            return None, None
        if pat.get("spacing_agnostic", True):
            rx = spacing_agnostic_regex(val)
        else:
            rx = re.escape(val)
        return re.compile(rx, flags), f"kw:{val}"

    if ptype == "regex":
        val = pat.get("value","")
        if not val:
            return None, None
        return re.compile(val, flags), "rx"

    if ptype == "phrase":
        terms = [kr_norm(t) for t in (pat.get("terms") or []) if t]
        if len(terms) < 2:
            return None, None
        max_gap = int(pat.get("max_gap", 6))
        terms_rx = [spacing_agnostic_regex(t) for t in terms]
        rx = terms_rx[0]
        for nxt in terms_rx[1:]:
            rx += rf".{{0,{max_gap}}}" + nxt
        return re.compile(rx, flags), f"ph:{'|'.join(terms)}"
    return None, None

def _rule_excepts(rule):
    ex = ((rule or {}).get("except") or {}).get("any") or []
    out = []
    for r in ex:
        try:
            out.append(re.compile(r, re.IGNORECASE))
        except re.error:
            pass
    return out

def _scan_with_rule(text, rule):
    hits = []
    exceptors = _rule_excepts(rule)
    window = int((rule or {}).get("except_window", 14))
    for p in _iter_rule_patterns(rule):
        rx, _ = _compile_regex_from_pattern(p)
        if not rx:
            continue
        for m in rx.finditer(text):
            s, e = m.start(), m.end()
            seg = text[s:e]
            if exceptors:
                ctx = text[max(0, s - window): min(len(text), e + window)]
                if any(ex.search(ctx) for ex in exceptors):
                    continue
            hits.append((s, e, seg))
    return hits

def rule_scan(text):
    rules = (RULES or {}).get("rules") or []
    items = []
    gid = 0
    for rule in rules:
        rid   = rule.get("id", "")
        topic = rule.get("topic", "")
        sev   = (rule.get("severity") or "warn").lower()
        rationale = rule.get("rationale") or rule.get("description") or ""
        actions   = rule.get("actions") or []
        rule_type = "ì‹¬ì˜ìœ„ë°˜" if sev == "block" else "ì£¼ì˜í‘œí˜„"

        for (s, e, seg) in _scan_with_rule(text, rule):
            before, after = add_context(text, s, e - s)
            sugg = []
            if any(str(a).startswith("suggest:") for a in actions):
                human = "í‘œí˜„ ì™„í™”/ê·¼ê±° ì œì‹œ/ì£¼ì˜ë¬¸ ë³‘ê¸° ê²€í† "
                if "MED" in " ".join(actions):
                    human = "ì˜ë£Œ í‘œí˜„ ì™„í™” ë˜ëŠ” ê°ê´€ ê·¼ê±° ì œì‹œ"
                elif "HFS" in " ".join(actions):
                    human = "ê±´ê¸°ì‹/ì˜ì•½í’ˆ ì˜¤ì¸ ë°©ì§€ ë¬¸êµ¬ë¡œ ìˆ˜ì •"
                elif "GEN_NEED_EVIDENCE" in " ".join(actions):
                    human = "ë¹„êµÂ·ìš°ì›” í‘œí˜„ì€ ì¶œì²˜/ê·¼ê±° ë³‘ê¸°"
                sugg = [human]
            else:
                sugg = ["ë¬¸êµ¬ ì™„í™” ë˜ëŠ” ì‚­ì œ ê²€í† "]

            items.append({
                "id": f"r_{gid}",
                "type": rule_type,
                "original": seg,
                "suggestions": sugg[:3],
                "reason": f"[{topic}] {rationale or 'ê·œì¹™ ë§¤ì¹­'}",
                "rule_id": rid,
                "severity": "high" if sev == "block" else "medium",
                "startIndex": s,
                "endIndex": e,
                "before": before,
                "after": after
            })
            gid += 1

    used = set()
    dedup = []
    for it in sorted(items, key=lambda x: (x["startIndex"], -(x["endIndex"]-x["startIndex"]))):
        k = (it["startIndex"], it["endIndex"], it["type"])
        if k in used:
            continue
        used.add(k)
        dedup.append(it)
    return dedup

# ============== (NEW) ë„ëŒì´í‘œ/ìœ ì‚¬ë¬¸ì¥ íƒì§€ ìœ í‹¸ ==============
_punc_rx = re.compile(r"[^\w\u3131-\u318E\uAC00-\uD7A3]+", re.UNICODE)
_ws_rx = re.compile(r"\s+")

def _norm_for_dup(s: str) -> str:
    s = unicodedata.normalize("NFKC", s or "")
    s = s.lower()
    s = _punc_rx.sub(" ", s)
    s = _ws_rx.sub(" ", s).strip()
    return s

def _char_ngrams(s: str, n=3):
    s = _norm_for_dup(s)
    return {s[i:i+n] for i in range(max(0, len(s)-n+1))} if s else set()

def _jaccard(a: set, b: set) -> float:
    if not a and not b: return 1.0
    if not a or not b:  return 0.0
    inter = len(a & b)
    union = len(a | b)
    return inter / union if union else 0.0

def _sentence_spans(text):
    """ë¬¸ì¥ ë‹¨ìœ„ë¡œ (start, end, raw_sentence) ë°˜í™˜"""
    sentences = basic_kr_sentence_split(text)
    spans = []
    cursor = 0
    for s in sentences:
        idx = text.find(s, cursor)
        if idx == -1:
            idx = text.find(s)
        if idx != -1:
            spans.append((idx, idx+len(s), s))
            cursor = idx + len(s)
    return spans

def _dedup_intra(text, min_len=6, sim_threshold=0.85):
    spans = _sentence_spans(text)
    # 1) exact ë„ëŒì´í‘œ(ì •ê·œí™” í›„ ë™ì¼)
    buckets = defaultdict(list)  # norm -> [(i, start, end, raw)]
    for i, (s, e, raw) in enumerate(spans):
        n = _norm_for_dup(raw)
        if len(n) >= min_len:
            buckets[n].append((i, s, e, raw))

    exact_groups = []
    for n, occ in buckets.items():
        if len(occ) >= 2:
            exact_groups.append({
                "norm": n,
                "occurrences": [
                    {"index": i, "start": s, "end": e, "original": raw} for (i,s,e,raw) in occ
                ]
            })

    # 2) similar(ìì¹´ë“œ: ë¬¸ì 3-gram)
    sims = []
    ngrams = []
    for i, (s, e, raw) in enumerate(spans):
        n = _norm_for_dup(raw)
        if len(n) >= min_len:
            ngrams.append((i, s, e, raw, _char_ngrams(raw, 3)))
    for a in range(len(ngrams)):
        i, s1, e1, r1, g1 = ngrams[a]
        for b in range(a+1, len(ngrams)):
            j, s2, e2, r2, g2 = ngrams[b]
            score = _jaccard(g1, g2)
            if score >= sim_threshold and r1 != r2:
                sims.append({
                    "i": i, "j": j, "score": round(score, 3),
                    "a": {"start": s1, "end": e1, "original": r1},
                    "b": {"start": s2, "end": e2, "original": r2}
                })

    return exact_groups, sims

def _dedup_inter(files, min_len=6, sim_threshold=0.85):
    """
    files: [{"name": str, "text": str}, ...]
    êµì°¨ íŒŒì¼ ê°„ ë™ì¼/ìœ ì‚¬ ë¬¸ì¥ íƒì§€
    """
    # ìˆ˜ì§‘
    recs = []  # (file_idx, name, sent_idx, start, end, raw, norm, ngrams)
    for fi, f in enumerate(files):
        name = f.get("name") or f"file_{fi+1}"
        text = f.get("text") or ""
        spans = _sentence_spans(text)
        for si, (s, e, raw) in enumerate(spans):
            n = _norm_for_dup(raw)
            if len(n) >= min_len:
                recs.append((fi, name, si, s, e, raw, n, _char_ngrams(raw, 3)))

    # exact
    exact_map = defaultdict(list)  # norm -> [occ...]
    for fi, name, si, s, e, raw, n, grams in recs:
        exact_map[n].append({"file": name, "fileIndex": fi, "sentIndex": si,
                             "start": s, "end": e, "original": raw})

    exact = []
    for n, occ in exact_map.items():
        # ì„œë¡œ ë‹¤ë¥¸ íŒŒì¼ì—ì„œ 2ê°œ ì´ìƒì¼ ë•Œë§Œ ì˜ë¯¸
        uniq_files = {o["fileIndex"] for o in occ}
        if len(uniq_files) >= 2:
            exact.append({"norm": n, "occurrences": occ})

    # similar
    sims = []
    for a in range(len(recs)):
        fi1, n1, si1, s1, e1, r1, norm1, g1 = recs[a]
        for b in range(a+1, len(recs)):
            fi2, n2, si2, s2, e2, r2, norm2, g2 = recs[b]
            if fi1 == fi2:  # ê°™ì€ íŒŒì¼ì€ intraì—ì„œ ë‹¤ë£¸
                continue
            score = _jaccard(g1, g2)
            if score >= sim_threshold and r1 != r2:
                sims.append({
                    "score": round(score, 3),
                    "a": {"fileIndex": fi1, "file": n1, "sentIndex": si1, "start": s1, "end": e1, "original": r1},
                    "b": {"fileIndex": fi2, "file": n2, "sentIndex": si2, "start": s2, "end": e2, "original": r2},
                })
    return exact, sims

# ================== Flask ==================
app = Flask(__name__)
CORS(app,
     resources={r"/*": {"origins": "*"}},
     allow_headers=["Content-Type", "Authorization"],
     expose_headers=["Content-Type"],
     supports_credentials=False)

@app.route("/auth/login", methods=["POST"])
def auth_login():
    payload = request.get_json(force=True, silent=True) or {}
    username = (payload.get("username") or "").strip()
    password = payload.get("password") or ""
    u = _get_user(username)
    if not u or not bcrypt.verify(password, u["password_hash"]):
        return jsonify({"error":"Bad credentials"}), 401
    if not _is_paid_and_active(u):
        return jsonify({"error":"Payment required", "code":"PAYMENT"}), 402

    # (ë‹¨ì¼ ë¡œê·¸ì¸ìš© ë²„ì „/í† í°ID ì—…ë°ì´íŠ¸)
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("SELECT token_version FROM users WHERE username=?", (username,))
    row = cur.fetchone()
    cur_ver = int((row[0] if row else 0) or 0)

    new_ver = cur_ver + 1
    new_jti = str(uuid.uuid4())
    cur.execute("UPDATE users SET token_version=?, last_jti=? WHERE username=?", (new_ver, new_jti, username))
    conn.commit()
    conn.close()

    token = jwt.encode({
        "sub": u["username"],
        "role": u["role"],
        "ver": new_ver,     # í† í° ë²„ì „
        "jti": new_jti,     # í† í° ê³ ìœ ID
        "exp": datetime.utcnow() + timedelta(hours=12)
    }, JWT_SECRET, algorithm=JWT_ALG)

    return jsonify({"access_token": token, "token_type": "bearer"})

@app.route("/auth/ping", methods=["GET", "OPTIONS"])
@require_user
def auth_ping():
    if request.method == "OPTIONS":
        return "", 200
    return jsonify({"ok": True})

@app.route("/auth/me", methods=["GET", "OPTIONS"])
@require_user
def auth_me():
    if request.method == "OPTIONS":
        return "", 200
    auth = request.headers.get("Authorization","")
    token = auth.split(" ",1)[1]
    data = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALG])
    u = _get_user(data.get("sub",""))
    return jsonify({
        "username": u["username"],
        "role": u["role"],
        "is_active": u["is_active"],
        "paid_until": u["paid_until"],
        "remaining_days": _remaining_days(u["paid_until"]),
    })

@app.route("/admin/create_user", methods=["POST"])
@require_admin
def admin_create_user():
    body = request.get_json(force=True, silent=True) or {}
    username = (body.get("username") or "").strip()
    password = body.get("password") or ""
    days = int(body.get("days") or 0)

    if not username or not password:
        return jsonify({"error":"username/password required"}), 400

    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    try:
        paid_until = datetime.utcnow() + timedelta(days=days) if days>0 else datetime.utcnow()
        cur.execute(
            "INSERT INTO users (username, password_hash, is_active, paid_until, role) VALUES (?,?,?,?,?)",
            (username, bcrypt.hash(password), 1 if days>0 else 0, paid_until.isoformat(), "user")
        )
        conn.commit()
        return jsonify({"ok":True})
    except sqlite3.IntegrityError:
        return jsonify({"error":"username exists"}), 409
    finally:
        conn.close()

@app.route("/admin/approve", methods=["POST"])
@require_admin
def admin_approve():
    body = request.get_json(force=True, silent=True) or {}
    username = (body.get("username") or "").strip()
    extend_days = int(body.get("extend_days") or 0)
    note = (body.get("note") or "").strip()

    u = _get_user(username)
    if not u:
        return jsonify({"error":"user not found"}), 404

    base = datetime.utcnow()
    try:
        if u.get("paid_until"):
            base = max(base, datetime.fromisoformat(u["paid_until"]))
    except Exception:
        pass

    new_until = base + timedelta(days=max(1, extend_days))

    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute(
        "UPDATE users SET is_active=?, paid_until=?, notes=? WHERE username=?",
        (1, new_until.isoformat(), note, username)
    )
    conn.commit()
    conn.close()
    return jsonify({"ok":True, "paid_until": new_until.isoformat()})

@app.route("/admin/issue_user", methods=["POST"])
@require_admin
def admin_issue_user():
    """
    ê´€ë¦¬ì ì „ìš©: ì‹ ê·œ ë°œê¸‰ ë˜ëŠ” ê¸°ì¡´ ì—°ì¥/ì •ë³´ ì—…ë°ì´íŠ¸ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
    body: { username, password?, days=32, site_url?, role? }
    ì‹ ê·œ: password í•„ìˆ˜, ê¸°ì¡´: ìƒëµ ê°€ëŠ¥
    """
    body = request.get_json(force=True, silent=True) or {}
    username = (body.get("username") or "").strip()
    password = (body.get("password") or "").strip()
    days     = int(body.get("days") or 32)   # ê¸°ë³¸ 32ì¼
    site_url = (body.get("site_url") or "").strip()
    role     = (body.get("role") or "user").strip()
    note     = (body.get("note") or "").strip()

    if not username:
        return jsonify({"error":"username required"}), 400

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("SELECT username, paid_until FROM users WHERE username=?", (username,))
    row = cur.fetchone()

    base = datetime.utcnow()
    if row and row[1]:
        try:
            prev = datetime.fromisoformat(row[1])
            if prev > base:
                base = prev
        except Exception:
            pass
    new_until = base + timedelta(days=max(1, days))

    if row is None:
        if not password:
            return jsonify({"error":"password required for new user"}), 400
        cur.execute(
            "INSERT INTO users (username, password_hash, is_active, paid_until, role, notes, site_url, created_at) VALUES (?,?,?,?,?,?,?,?)",
            (username, bcrypt.hash(password), 1, new_until.isoformat(), role, note, (site_url or None), datetime.utcnow().isoformat())
        )
    else:
        # ê¸°ì¡´ ì‚¬ìš©ì: ì—°ì¥ + ì„ íƒ í•„ë“œ ê°±ì‹ 
        if password:
            cur.execute("UPDATE users SET password_hash=? WHERE username=?", (bcrypt.hash(password), username))
        cur.execute(
            "UPDATE users SET is_active=?, paid_until=?, role=?, notes=?, site_url=? WHERE username=?",
            (1, new_until.isoformat(), role, note, (site_url or None), username)
        )

    conn.commit(); conn.close()
    return jsonify({"ok": True, "username": username, "paid_until": new_until.isoformat(), "remaining_days": _remaining_days(new_until.isoformat())})

@app.route("/admin/set_active", methods=["POST"])
@require_admin
def admin_set_active():
    body = request.get_json(force=True, silent=True) or {}
    username = (body.get("username") or "").strip()
    is_active = 1 if body.get("is_active") else 0
    if not username:
        return jsonify({"error":"username required"}), 400
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("UPDATE users SET is_active=? WHERE username=?", (is_active, username))
    conn.commit(); conn.close()
    return jsonify({"ok": True})

@app.route("/admin/reset_password", methods=["POST"])
@require_admin
def admin_reset_password():
    body = request.get_json(force=True, silent=True) or {}
    username = (body.get("username") or "").strip()
    new_pw = (body.get("new_password") or "").strip()
    if not username or not new_pw:
        return jsonify({"error":"username/new_password required"}), 400
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("UPDATE users SET password_hash=? WHERE username=?", (bcrypt.hash(new_pw), username))
    conn.commit(); conn.close()
    return jsonify({"ok": True})

# --- ê´€ë¦¬ì: ì‚¬ìš©ì ì‚­ì œ(ìê¸° ìì‹ /ìµœìƒìœ„ admin ë³´í˜¸, ì¡´ì¬ì—¬ë¶€ ì²´í¬) ---
@app.route("/admin/delete_user", methods=["POST"])
@require_admin
def admin_delete_user():
    body = request.get_json(silent=True) or {}
    username = (body.get("username") or "").strip()

    if not username:
        return jsonify({"error": "username required"}), 400
    # ìµœìƒìœ„ ê´€ë¦¬ì ë³´í˜¸ (í•„ìš” ì—†ë‹¤ë©´ ì£¼ì„ ì²˜ë¦¬)
    if username == "admin":
        return jsonify({"error": "cannot delete admin"}), 400

    # ë³¸ì¸ ê³„ì • ì‚­ì œ ë°©ì§€
    try:
        auth = request.headers.get("Authorization", "")
        token = auth.split(" ", 1)[1]
        sub = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALG]).get("sub")
        if sub == username:
            return jsonify({"error": "ë³¸ì¸ ê³„ì •ì€ ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 400
    except Exception:
        # í† í° íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìê¸°ì‚­ì œ ë°©ì§€ëŠ” ê±´ë„ˆë›°ë˜, admin ë³´í˜¸ëŠ” ìœ„ì—ì„œ ì´ë¯¸ ì ìš©ë¨
        pass

    # ì‹¤ì œ ì‚­ì œ
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("DELETE FROM users WHERE username = ?", (username,))
    conn.commit()
    deleted = cur.rowcount
    conn.close()

    if deleted == 0:
        return jsonify({"error": "ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì‚¬ìš©ì"}), 404

    return jsonify({"ok": True, "deleted": username})

@app.route("/admin/list_users", methods=["GET"])
@require_admin
def admin_list_users():
    q = (request.args.get("q") or "").strip()
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    if q:
        cur.execute("SELECT username,is_active,paid_until,role,notes,site_url,created_at FROM users WHERE username LIKE ? ORDER BY username", (f"%{q}%",))
    else:
        cur.execute("SELECT username,is_active,paid_until,role,notes,site_url,created_at FROM users ORDER BY username")
    rows = cur.fetchall()
    conn.close()
    out = []
    for u,a,pu,r,nt,site,created in rows:
        out.append({
            "username": u,
            "is_active": bool(a),
            "paid_until": pu,
            "remaining_days": _remaining_days(pu),
            "role": r,
            "note": nt,
            "site_url": site,
            "created_at": created
        })
    return jsonify({"users": out})

# ë¡œì»¬ ë§ì¶¤ë²• ì´ˆê¸°í™”
_init_symspell()

@app.route("/verify", methods=["POST", "OPTIONS"])
@require_user
def verify():
    if request.method == "OPTIONS":
        return "", 200  # preflight OK

    try:
        data = request.get_json(force=True, silent=True) or {}
        text = (data.get("text") or "").strip()
        if not text:
            return jsonify({"error": "No text provided", "results": []}), 400

        all_items = []

        # ì—¬ê¸°ì— GPT ë§ì¶¤ë²•/ë¬¸ë§¥ ê²€ì‚¬ í˜¸ì¶œ ë¡œì§ ì‚½ì…
        # (chunk_text_with_offsets + gpt_call í™œìš©)

        # === GPT ê¸°ë°˜ ë§ì¶¤ë²•/ë¬¸ë§¥ì˜¤ë¥˜ ê²€ì‚¬ ===
        chunks = chunk_text_with_offsets(text)  # (base_offset, chunk_text)
        for base, chunk in chunks:
            prompt = f"""
ë„ˆëŠ” í•œêµ­ì–´ ë¬¸ì¥ êµì • ì „ë¬¸ê°€ë‹¤.
ì•„ë˜ ê¸€ì—ì„œ **ë§ì¶¤ë²•/ë„ì–´ì“°ê¸°/ì–´ë²• ì˜¤ë¥˜(=type: "ë§ì¶¤ë²•")**,
**ë¶€ìì—°ìŠ¤ëŸ½ê±°ë‚˜ ëŠê¸´ ë¬¸ì¥(=type: "ë¬¸ë§¥ì˜¤ë¥˜")**ë§Œ ì°¾ì•„ë¼.
ì‹¬ì˜/ê´‘ê³ ë²•/ì˜ë£Œ ê·œì •(íš¨ê³¼Â·ì¬ë°œë¥ Â·ë³´ì¥ ë“±)ì€ **ì™„ì „íˆ ë¬´ì‹œ**í•œë‹¤.

ë°˜ë“œì‹œ JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ë©°, ê° í•­ëª©ì€ ì•„ë˜ ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¥¸ë‹¤:
{{
  "type": "ë§ì¶¤ë²•" | "ë¬¸ë§¥ì˜¤ë¥˜",
  "original": "ì›ë¬¸ì—ì„œ ê·¸ëŒ€ë¡œ ë³µì‚¬(ê³µë°±/ê¸°í˜¸ë„ ë™ì¼)",
  "reason": "ê°„ë‹¨ ì„¤ëª…",
  "severity": "low" | "medium" | "high",
  "suggestions": ["ëŒ€ì•ˆ1","ëŒ€ì•ˆ2"],   // ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´
  "start": ì •ìˆ˜,   // ì´ ì²­í¬ ë‚´ ì‹œì‘ ì˜¤í”„ì…‹
  "end": ì •ìˆ˜      // ì´ ì²­í¬ ë‚´ ë ì˜¤í”„ì…‹(í¬í•¨X)
}}

ê²€ì‚¬í•  ê¸€:
\"\"\"{chunk}\"\"\"
""".strip()

            resp = gpt_call(MODEL, [{"role": "user", "content": prompt}])
            raw = (resp.choices[0].message.content or "").strip()
            items = extract_json_array(raw)

            used_local = set()
            for it in (items or []):
                origin = (it.get("original") or "").strip()
                if not origin:
                    continue

                # 1) GPTê°€ ì¤€ start/end ì˜¤í”„ì…‹ì„ ìµœìš°ì„  ì‹ ë¢°
                s_rel = it.get("start")
                e_rel = it.get("end")
                locs = []
                if isinstance(s_rel, int) and isinstance(e_rel, int) and 0 <= s_rel < e_rel <= len(chunk):
                    locs = [s_rel]
                else:
                    # 2) ì‹¤íŒ¨ ì‹œ fallback: ë¶€ë¶„ ë¬¸ìì—´ íƒìƒ‰
                    locs = find_all(chunk, origin)

                for local_idx in locs:
                    gidx = base + local_idx
                    if gidx in used_local:
                        continue
                    used_local.add(gidx)

                    before, after = add_context(text, gidx, len(origin))
                    all_items.append({
                        "id": f"v_{len(all_items)}",
                        "type": it.get("type") or "ë§ì¶¤ë²•",
                        "original": origin,
                        "suggestions": (it.get("suggestions") or [])[:3],
                        "reason": it.get("reason") or "",
                        "severity": it.get("severity") or "low",
                        "startIndex": gidx,
                        "endIndex": gidx + len(origin),
                        "before": before,
                        "after": after
                    })
                    break  # ë™ì¼ í•­ëª© ì¤‘ë³µ ë°©ì§€


        # ë¬¸ì¥ ë‹¨ìœ„ íœ´ë¦¬ìŠ¤í‹± ì¶”ê°€ (ë£¨í”„ ë°–ì—ì„œ í•œ ë²ˆë§Œ)
        all_items.extend(find_fragments_by_sentence(text))
        all_items.extend(find_context_issues(text))

        # ì¶œì²˜ íƒœê·¸
        for it in all_items:
            it["source"] = "verify"

        return jsonify({"results": all_items, "aiSummary": None})
    except Exception as e:
        import traceback
        print("âŒ /verify ì˜¤ë¥˜:", e)
        traceback.print_exc()
        return jsonify({"error": str(e), "results": []}), 500

@app.post("/spell/local")
def spell_local():
    """
    ë¡œì»¬ ì² ì(ë§ì¶¤ë²•)ë§Œ ê²€ì‚¬. ë¬¸ë§¥/ì–´ë²•/ì‹¬ì˜ íŒë‹¨ ì—†ìŒ.
    body: { "text": str, "min_len": 3, "max_sug": 3 }
    """
    try:
        data = request.get_json(force=True, silent=True) or {}
        text = (data.get("text") or "")
        if not text.strip() or _sym is None:
            return jsonify({"results": []})

        min_len = int(data.get("min_len") or 3)   # ì§§ì€ í† í° ì œì™¸(ì˜¤íƒâ†“)
        max_sug = int(data.get("max_sug") or 3)   # ì œì•ˆ ìƒìœ„ Nê°œ

        results = []
        for s, e, tok in _token_spans_ko(text):
            if len(tok) < min_len:
                continue
            # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸/ì‚¬ì „ì— ìˆìœ¼ë©´ í†µê³¼
            if tok in _whitelist or _sym.words.get(tok, 0) > 0:
                continue

            suggs = _sym.lookup(tok, Verbosity.TOP, max_edit_distance=2, include_unknown=False)
            if not suggs:
                continue

            cand = [su.term for su in suggs[:max_sug]]
            results.append({
                "type": "ë§ì¶¤ë²•",
                "original": tok,
                "reason": "ì‚¬ì „ì— ì—†ëŠ” ë‹¨ì–´ë¡œ ì¶”ì •",
                "severity": "low",
                "suggestions": cand,
                "startIndex": s,
                "endIndex": e,
                "before": text[max(0, s-24):s],
                "after":  text[e:min(len(text), e+24)],
                "source": "local-spell"
            })

        results.sort(key=lambda x: (x["startIndex"], x["endIndex"]))
        return jsonify({"results": results})
    except Exception as e:
        import traceback; traceback.print_exc()
        return jsonify({"results": [], "error": str(e)}), 500


# ===== ë¬¸ì¥ ë‹¨ìœ„ ë¬¸ë§¥ì˜¤ë¥˜ ìœ í‹¸ =====

SENT_SPLIT_RE = re.compile(r'(?<=[\.!?])\s+')
END_TOKEN_RE = re.compile(r'(ë‹¤|ìš”|ë‹ˆë‹¤|í•©ë‹ˆë‹¤|í–ˆë‹¤|ì˜€ë‹¤|ë©ë‹ˆë‹¤|ë¼ìš”|\.|!|\?)\s*$')

LEADING_CONNECTIVES = (
    "í•˜ì§€ë§Œ", "ê·¸ëŸ¬ë‚˜", "ë°˜ë©´ì—", "ê·¸ëŸ°ë°", "ë‹¤ë§Œ",
    "ë˜í•œ", "ê·¸ë¦¬ê³ ", "ê²Œë‹¤ê°€", "íŠ¹íˆ", "ë˜", "í•œí¸"
)

def split_sentences_with_pos(text: str):
    spans = []
    parts = SENT_SPLIT_RE.split(text)
    cur = 0
    for p in parts:
        if not p.strip():
            cur += len(p)
            continue
        start = text.find(p, cur)
        if start == -1:
            start = text.find(p)
        end = start + len(p)
        spans.append((p, start, end))
        cur = end
    return spans

def find_fragments_by_sentence(text: str):
    items = []
    spans = split_sentences_with_pos(text)
    for s, start, end in spans:
        sent = s.strip()
        if len(sent) < 15:
            continue
        if sent.startswith(("â€œ", "\"", "â€˜", "'")) and sent.endswith(("â€", "\"", "â€™", "'")):
            continue
        if not END_TOKEN_RE.search(sent):
            items.append({
                "id": f"frag_{start}",
                "type": "ë¬¸ë§¥ì˜¤ë¥˜",
                "original": sent,
                "reason": "ë¶ˆì™„ì „ ë¬¸ì¥(ì¢…ê²°ì–´ë¯¸/ë§ˆì¹¨í‘œ ëˆ„ë½) ê°€ëŠ¥",
                "severity": "medium",
                "suggestions": ["ë¬¸ì¥ì„ ë§ˆë¬´ë¦¬í•˜ëŠ” ì¢…ê²°ì–´ë¯¸/ë§ˆì¹¨í‘œ ì¶”ê°€ ê²€í† "],
                "startIndex": start,
                "endIndex": end,
                "before": "", "after": ""
            })
    return items

def find_context_issues(text: str):
    items = []
    spans = split_sentences_with_pos(text)
    for i, (s, start, end) in enumerate(spans):
        sent = s.strip()
        if len(sent) < 10:
            continue
        for conn in LEADING_CONNECTIVES:
            if sent.startswith(conn):
                if i == 0:
                    items.append({
                        "id": f"ctx_first_{start}",
                        "type": "ë¬¸ë§¥ì˜¤ë¥˜",
                        "original": sent[:min(40, len(sent))],
                        "reason": f"ì²« ë¬¸ì¥ì—ì„œ '{conn}' ì‚¬ìš©",
                        "severity": "low",
                        "suggestions": ["ì²« ë¬¸ì¥ì€ ì „í™˜ ì—†ì´ ì£¼ì œë¥¼ ì œì‹œí•˜ëŠ” ê²ƒì´ ìì—°ìŠ¤ëŸ¬ì›€"],
                        "startIndex": start, "endIndex": end,
                        "before": "", "after": ""
                    })
                else:
                    prev = spans[i-1][0].strip()
                    if len(prev) < 10 or not END_TOKEN_RE.search(prev):
                        items.append({
                            "id": f"ctx_link_{start}",
                            "type": "ë¬¸ë§¥ì˜¤ë¥˜",
                            "original": sent[:min(40, len(sent))],
                            "reason": f"ì• ë¬¸ì¥ì´ ì•½í•œ ìƒíƒœì—ì„œ '{conn}' ì‹œì‘",
                            "severity": "low",
                            "suggestions": ["ì• ë¬¸ì¥ì„ ë³´ê°•í•˜ê±°ë‚˜ ì—°ê²°ì–´ë¥¼ ìƒëµ/ë³€ê²½"],
                            "startIndex": start, "endIndex": end,
                            "before": "", "after": ""
                        })
                break
    return items


# ============== (NEW) ë„ëŒì´í‘œ/ìœ ì‚¬ ë¼ìš°íŠ¸ ==============
@app.route("/dedup_intra", methods=["POST"])
@require_user
def dedup_intra():
    """
    ë³¸ë¬¸ í•œ ê±´ ë‚´ ë„ëŒì´í‘œ(ì •í™•íˆ ê°™ì€ ë¬¸ì¥) + ìœ ì‚¬ ë¬¸ì¥(3-gram ìì¹´ë“œ) íƒì§€
    body: { "text": str, "min_len": 6, "sim_threshold": 0.85 }
    """
    try:
        data = request.get_json(force=True, silent=True) or {}
        text = (data.get("text") or "")
        if not text.strip():
            return jsonify({"error": "No text provided"}), 400
        min_len = int(data.get("min_len", 6))
        sim_th  = float(data.get("sim_threshold", 0.85))
        exact, sims = _dedup_intra(text, min_len=min_len, sim_threshold=sim_th)
        return jsonify({"exact_groups": exact, "similar_pairs": sims})
    except Exception as e:
        import traceback
        print("âŒ /dedup_intra ì˜¤ë¥˜:", e)
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

@app.route("/dedup_inter", methods=["POST"])
@require_user
def dedup_inter():
    """
    ì—¬ëŸ¬ íŒŒì¼ ê°„ ë„ëŒì´í‘œ/ìœ ì‚¬ ë¬¸ì¥ íƒì§€
    body: { "files": [{"name": str, "text": str}, ...], "min_len": 6, "sim_threshold": 0.85 }
    """
    try:
        data = request.get_json(force=True, silent=True) or {}
        files = data.get("files") or []
        if not files:
            return jsonify({"error": "No files provided"}), 400
        min_len = int(data.get("min_len", 6))
        sim_th  = float(data.get("sim_threshold", 0.85))
        exact, sims = _dedup_inter(files, min_len=min_len, sim_threshold=sim_th)
        return jsonify({"exact_groups": exact, "similar_pairs": sims})
    except Exception as e:
        import traceback
        print("âŒ /dedup_inter ì˜¤ë¥˜:", e)
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

@app.route("/policy_verify", methods=["POST", "OPTIONS"])
@require_user
def policy_verify():
    if request.method == "OPTIONS":
        return "", 200

    try:
        data = request.get_json(force=True, silent=True) or {}
        text = (data.get("text") or "").strip()
        if not text:
            return jsonify({"error": "No text provided", "results": []}), 400

        # ì‹¬ì˜ ê·œì¹™ ê²€ì‚¬
        items = rule_scan(text)
        items = attach_reasons(items)

        # ì¶œì²˜ íƒœê·¸
        for it in items:
            it["source"] = "policy"

        return jsonify({"results": items})
    except Exception as e:
        import traceback
        print("âŒ /policy_verify ì˜¤ë¥˜:", e)
        traceback.print_exc()
        return jsonify({"error": str(e), "results": []}), 500

@app.route("/health", methods=["GET"])
def health():
    return jsonify({
        "ok": True,
        "routes": [
            "/auth/login","/auth/ping","/auth/me",
            "/admin/issue_user","/admin/set_active","/admin/reset_password","/admin/list_users","/admin/delete_user",
            "/verify","/policy_verify","/dedup_intra","/dedup_inter","/spell/local","/health"
        ]
    })

if __name__ == "__main__":
    port = int(os.getenv("PORT", "5000"))
    app.run(host="0.0.0.0", port=port, debug=False)
