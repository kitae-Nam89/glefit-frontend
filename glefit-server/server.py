# -*- coding: utf-8 -*-
import os, re, json, time, sqlite3, unicodedata
from dotenv import load_dotenv
from flask import Flask, request, jsonify
from flask_cors import CORS

# [ADD] Auth imports
from datetime import datetime, timedelta
from functools import wraps
import jwt
from passlib.hash import pbkdf2_sha256 as bcrypt


from openai import OpenAI
import yaml
from collections import defaultdict
# --- [LOCAL SPELLCHECK] begin ---
import os, re
from symspellpy import SymSpell, Verbosity
import uuid

_HANGUL_RE = re.compile(r"[ê°€-í£]+")
DATA_DIR = "data"
KO_WORDS_PATH = os.path.join(DATA_DIR, "ko_words.txt")   # "ë‹¨ì–´<TAB>ë¹ˆë„"
WHITE_PATH    = os.path.join(DATA_DIR, "whitelist.txt")  # ì¤„ë‹¹ 1ê°œ ë‹¨ì–´

_sym = None
_whitelist = set()

def _init_symspell():
    import os
    os.makedirs(DATA_DIR, exist_ok=True)
    global _sym, _whitelist
    _sym = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)

    if os.path.exists(KO_WORDS_PATH):
        _sym.load_dictionary(KO_WORDS_PATH, term_index=0, count_index=1,
                             separator="\t", encoding="utf-8")

    custom_path = os.path.join(DATA_DIR, "custom_words.txt")
    if os.path.exists(custom_path):
        _sym.load_dictionary(custom_path, term_index=0, count_index=1,
                             separator="\t", encoding="utf-8")

    _whitelist = set()
    if os.path.exists(WHITE_PATH):
        for enc in ("utf-8","utf-8-sig","cp949","euc-kr"):
            try:
                with open(WHITE_PATH,"r",encoding=enc) as f:
                    _whitelist = {ln.strip() for ln in f if ln.strip()}
                break
            except UnicodeDecodeError:
                continue

    print(f"ğŸ”¤ SymSpell ready: words={len(_sym.words)}, whitelist={len(_whitelist)}")

def _token_spans_ko(text: str):
    """í•œê¸€ ì—°ì†êµ¬ê°„ì„ í† í°ìœ¼ë¡œ ë½‘ì•„ (start, end, token)"""
    for m in _HANGUL_RE.finditer(text or ""):
        yield m.start(), m.end(), m.group()
# --- [LOCAL SPELLCHECK] end ---


# ================== ê¸°ë³¸ ì„¤ì • ==================
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (.env í™•ì¸)")

client = OpenAI(api_key=OPENAI_API_KEY, timeout=30)

MODEL = "gpt-4o"
import os, shutil

# ë””í´íŠ¸ëŠ” ë¡œì»¬ íŒŒì¼, í™˜ê²½ë³€ìˆ˜(DB_PATH)ë¡œ ë®ì–´ì“°ê¸°
DB_PATH = os.getenv("DB_PATH", "rewrite.db")
print(f"[DB] Using DB_PATH={DB_PATH}")  # â† ë¶€íŒ… ë¡œê·¸ í™•ì¸ìš©

# (ì„ íƒ) ë§ˆì´ê·¸ë ˆì´ì…˜ ë„ìš°ë¯¸: /app/rewrite.db â†’ /data/rewrite.db ë¡œ ìµœì´ˆ 1íšŒ ë³µì‚¬
try:
    app_db = os.path.join(os.path.dirname(__file__), "rewrite.db")
    if os.getenv("DB_PATH") and os.getenv("DB_PATH") != "rewrite.db":
        os.makedirs(os.path.dirname(os.getenv("DB_PATH")), exist_ok=True)
        if os.path.exists(app_db) and not os.path.exists(os.getenv("DB_PATH")):
            shutil.copy2(app_db, os.getenv("DB_PATH"))
except Exception:
    pass
MAX_CHARS_PER_CHUNK = 4000

# [ADD] JWT config
JWT_SECRET = os.getenv("JWT_SECRET", "CHANGE_ME_TO_RANDOM_SECRET")
JWT_ALG = "HS256"
# [ADD] ensure users table
def ensure_users_table():
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS users (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        username TEXT UNIQUE NOT NULL,
        password_hash TEXT NOT NULL,
        is_active INTEGER DEFAULT 0,
        paid_until TEXT,
        role TEXT DEFAULT 'user',
        notes TEXT
    )
    """)
    conn.commit()
    conn.close()

ensure_users_table()

def migrate_users_table():
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()

    # ë¡œê·¸ì¸/ì„¸ì…˜ ê´€ë¦¬ ë° í¸ì˜ í•„ë“œ ì¶”ê°€ (ì´ë¯¸ ìˆìœ¼ë©´ ë„˜ì–´ê°)
    try: cur.execute("ALTER TABLE users ADD COLUMN token_version INTEGER DEFAULT 0")
    except Exception: pass
    try: cur.execute("ALTER TABLE users ADD COLUMN last_jti TEXT")
    except Exception: pass
    try: cur.execute("ALTER TABLE users ADD COLUMN allow_concurrent INTEGER DEFAULT 0")
    except Exception: pass
    try: cur.execute("ALTER TABLE users ADD COLUMN site_url TEXT")
    except Exception: pass
    try: cur.execute("ALTER TABLE users ADD COLUMN created_at TEXT")
    except Exception: pass

    # â˜… ì‹ ê·œ: ê²Œì‹œê¸€ ì‘ì„± ì •ì§€ í”Œë˜ê·¸
    try: cur.execute("ALTER TABLE users ADD COLUMN posting_blocked INTEGER DEFAULT 0")
    except Exception: pass
    # (ì„ íƒ) ì¸ë±ìŠ¤
    try: cur.execute("CREATE INDEX IF NOT EXISTS idx_users_posting_blocked ON users(posting_blocked)")
    except Exception: pass

    conn.commit()
    conn.close()


# === (BOOT SEED) ì„œë²„ ê¸°ë™ ì‹œ ê´€ë¦¬ì ê³„ì • ë³´ì¥ ===
def _boot_seed_admin():
    try:
        import sqlite3, os
        from datetime import datetime, timedelta
        # passlib í•´ì‹œë¥¼ ì „ì—­ì—ì„œ: from passlib.hash import pbkdf2_sha256 as bcrypt

        admin_user = (os.getenv("ADMIN_USER") or "").strip()
        admin_pass = (os.getenv("ADMIN_PASS") or "").strip()
        admin_days = int(os.getenv("ADMIN_DAYS") or 0)
        if not admin_user or not admin_pass or admin_days <= 0:
            return

        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()

        # ìµœì†Œ ìŠ¤í‚¤ë§ˆ ë³´ì¥ (í…Œì´ë¸”/ì¸ë±ìŠ¤ë§Œ)
        cur.executescript("""
        CREATE TABLE IF NOT EXISTS users (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            username TEXT UNIQUE NOT NULL,
            password_hash TEXT NOT NULL,
            is_active INTEGER DEFAULT 1,
            paid_until TEXT,
            role TEXT DEFAULT 'user',
            notes TEXT
        );
        CREATE UNIQUE INDEX IF NOT EXISTS idx_users_username ON users(username);
        """)

        paid_until = (datetime.utcnow() + timedelta(days=admin_days)).isoformat()
        cur.execute("""
        INSERT INTO users (username, password_hash, is_active, paid_until, role, notes)
        VALUES (?, ?, 1, ?, 'admin', 'seed admin')
        ON CONFLICT(username) DO UPDATE SET
          password_hash = excluded.password_hash,
          is_active     = 1,
          paid_until    = excluded.paid_until,
          role          = 'admin',
          notes         = 'seed admin'
        """, (admin_user, bcrypt.hash(admin_pass), paid_until))

        conn.commit()
        conn.close()
        print(f"[boot-seed] admin ready: {admin_user} (until {paid_until})")

    except Exception as e:
        print("[boot-seed] skip/error:", e)

# [ADD] ìš´ì˜/í†µê³„/ìºì‹œìš© í…Œì´ë¸”
def migrate_ops_tables():
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS usage_logs (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        username TEXT,
        action TEXT,           -- verify|policy|dedup_intra|dedup_inter|spell_local|login
        files_count INTEGER,
        created_at TEXT
    )""")
    cur.execute("""
    CREATE TABLE IF NOT EXISTS error_logs (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        username TEXT,
        path TEXT,
        status INTEGER,
        message TEXT,
        created_at TEXT
    )""")
    cur.execute("""
    CREATE TABLE IF NOT EXISTS agreements (
        username TEXT PRIMARY KEY,
        agreed_at TEXT
    )""")

    cur.execute("""
    CREATE TABLE IF NOT EXISTS visit_logs (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        username TEXT,            -- ë¡œê·¸ì¸ ì „/í›„ ëª¨ë‘ ê¸°ë¡(ì—†ìœ¼ë©´ ë¹ˆë¬¸ì)
        path TEXT,                -- í”„ë¡ íŠ¸ê°€ ë³´ë‚´ëŠ” í˜„ì¬ ê²½ë¡œ/ìŠ¤í¬ë¦° ëª…
        ip TEXT,
        user_agent TEXT,
        created_at TEXT
    )""")

    # --- [ADD] board posts & limits ---
    cur.execute("""
    CREATE TABLE IF NOT EXISTS board_posts (
        id TEXT PRIMARY KEY,
        username TEXT,
        text TEXT,
        pinned INTEGER DEFAULT 0,
        ts INTEGER
    )
    """)
    cur.execute("""
    CREATE TABLE IF NOT EXISTS board_limits (
        username TEXT PRIMARY KEY,
        daily_limit INTEGER DEFAULT 2
    )
    """)


    conn.commit()
    conn.close()

# === INSERT near line ~217 (after migrate_ops_tables, before "ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰") ===
def migrate_board_tables():
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS board_posts (
        id TEXT PRIMARY KEY,
        username TEXT,
        text TEXT,
        pinned INTEGER DEFAULT 0,
        ts INTEGER
    )""")
    cur.execute("""
    CREATE TABLE IF NOT EXISTS board_limits (
        username TEXT PRIMARY KEY,
        daily_limit INTEGER DEFAULT 2
    )""")

    # --- NEW: hidden ì»¬ëŸ¼(ì†Œí”„íŠ¸ ì‚­ì œ/ìˆ¨ê¹€) ë³´ê°• ---
    cur.execute("PRAGMA table_info(board_posts)")
    cols = [r[1] for r in cur.fetchall()]
    if "hidden" not in cols:
        cur.execute("ALTER TABLE board_posts ADD COLUMN hidden INTEGER DEFAULT 0")

    conn.commit(); conn.close()



def log_visit(username, path):
    try:
        ip  = request.headers.get("CF-Connecting-IP") or request.remote_addr or ""
        ua  = request.headers.get("User-Agent") or ""
        conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
        cur.execute(
            "INSERT INTO visit_logs (username, path, ip, user_agent, created_at) VALUES (?,?,?,?,?)",
            (username or "", path or "", ip[:120], ua[:300], datetime.utcnow().isoformat())
        )
        conn.commit(); conn.close()
    except Exception:
        pass

# ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
migrate_users_table()
migrate_ops_tables()
migrate_board_tables()
_boot_seed_admin()

# [ADD] user helpers & guards
def _get_user(username: str):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("SELECT id, username, password_hash, is_active, paid_until, role FROM users WHERE username = ?", (username,))
    row = cur.fetchone()
    conn.close()
    if not row:
        return None
    return {
        "id": row[0], "username": row[1], "password_hash": row[2],
        "is_active": bool(row[3]),
        "paid_until": row[4],
        "role": row[5] or "user",
    }

# === [ADD] Non-admin text size limit ===============================
MAX_TEXT_BYTES_NON_ADMIN = 100 * 1024  # 100KB

def _utf8_len(s: str) -> int:
    if not s:
        return 0
    return len(s.encode("utf-8", "ignore"))

def _is_admin_current() -> bool:
    try:
        uname = _username_from_req()
        u = _get_user(uname) if uname else None
        return (u or {}).get("role") == "admin"
    except Exception:
        return False

def enforce_size_limit_or_400(texts_or_iterable):
    """
    - ê´€ë¦¬ìë©´ ë¬´ì œí•œ í†µê³¼
    - ë¹„ê´€ë¦¬ì(ì¼ë°˜/ì²´í—˜íŒ)ëŠ” 'í•­ëª©ë‹¹' 100KB ì´ˆê³¼ ì‹œ 400 ë°˜í™˜
    - texts_or_iterable: str | list[str] | list[{'text':str}, ...]
    """
    if _is_admin_current():
        return  # admin unlimited

    # normalize
    if isinstance(texts_or_iterable, str):
        payloads = [texts_or_iterable]
    else:
        payloads = []
        for item in (texts_or_iterable or []):
            if isinstance(item, str):
                payloads.append(item)
            elif isinstance(item, dict) and "text" in item:
                payloads.append(item.get("text") or "")
            else:
                payloads.append(str(item or ""))

    for idx, s in enumerate(payloads):
        if _utf8_len(s) > MAX_TEXT_BYTES_NON_ADMIN:
            return jsonify({
                "ok": False,
                "error": "TEXT_TOO_LARGE",
                "message": f"ì¼ë°˜/ì²´í—˜íŒì€ í•­ëª©ë‹¹ 100KB(102400 bytes)ê¹Œì§€ë§Œ í—ˆìš©ë©ë‹ˆë‹¤. (#{idx+1})",
                "limit_bytes": MAX_TEXT_BYTES_NON_ADMIN
            }), 400
    return
# ===================================================================

def _remaining_days(paid_until: str) -> int:
    if not paid_until:
        return 0
    try:
        delta = datetime.fromisoformat(paid_until) - datetime.utcnow()
        return max(0, delta.days)
    except Exception:
        return 0

# [ADD] ì‚¬ìš©ëŸ‰/ì—ëŸ¬ ë¡œê¹… í—¬í¼
def log_usage(username, action, files_count=0):
    try:
        conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
        cur.execute("INSERT INTO usage_logs (username, action, files_count, created_at) VALUES (?,?,?,?)",
                    (username or "", action or "", int(files_count or 0), datetime.utcnow().isoformat()))
        conn.commit(); conn.close()
    except Exception:
        pass

def log_error(username, path, status, message):
    try:
        conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
        cur.execute("INSERT INTO error_logs (username, path, status, message, created_at) VALUES (?,?,?,?,?)",
                    (username or "", path or "", int(status or 0), str(message)[:500], datetime.utcnow().isoformat()))
        conn.commit(); conn.close()
    except Exception:
        pass

def _username_from_req():
    try:
        auth = request.headers.get("Authorization","")
        tok = auth.split(" ",1)[1]
        data = jwt.decode(tok, JWT_SECRET, algorithms=[JWT_ALG])
        return data.get("sub") or ""
    except Exception:
        return ""

def _is_paid_and_active(u: dict) -> bool:
    if not u or not u.get("is_active"):
        return False
    try:
        pu = u.get("paid_until")
        if not pu:
            return False
        return datetime.utcnow() <= datetime.fromisoformat(pu)
    except Exception:
        return False

def _origin_allowed(user_site_url: str) -> bool:
    if not user_site_url:
        return True  # ì£¼ì†Œ ì œí•œ ì•ˆ ê±´ ê³„ì •
    origin = (request.headers.get("Origin") or "").lower()
    referer = (request.headers.get("Referer") or "").lower()
    target = user_site_url.lower()
    return (target in origin) or (target in referer)

def require_user(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        if request.method == "OPTIONS":
            return "", 200

        auth = request.headers.get("Authorization","").strip()
        if not auth.startswith("Bearer "):
            return jsonify({"error":"Unauthorized"}), 401
        token = auth.split(" ",1)[1]

        try:
            data = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALG])
        except Exception:
            return jsonify({"error":"Invalid token"}), 401

        username = data.get("sub","")
        tok_ver  = int(data.get("ver", 0) or 0)
        tok_jti  = data.get("jti","") or ""

                # DBì—ì„œ ìµœì‹  ìƒíƒœ(í™œì„±/ê¸°ê°„/ì‚¬ì´íŠ¸/ë²„ì „/JTI/ë™ì‹œì ‘ì†) í™•ì¸
        conn = sqlite3.connect(DB_PATH)
        cur  = conn.cursor()
        cur.execute(
            "SELECT is_active, paid_until, site_url, token_version, last_jti, allow_concurrent "
            "FROM users WHERE username=?",
            (username,)
        )
        row = cur.fetchone()
        conn.close()

        if not row:
            return jsonify({"error":"Unauthorized"}), 401

        is_active, paid_until, site_url, db_ver, db_jti, allow_concurrent = (
            row[0], row[1], (row[2] or ""), int(row[3] or 0), (row[4] or ""), bool(row[5])
        )

        # ê²°ì œ/ê¸°ê°„/í™œì„± ì²´í¬
        try:
            if not is_active or not paid_until or datetime.utcnow() > datetime.fromisoformat(paid_until):
                return jsonify({"error":"Payment required or expired"}), 402
        except Exception:
            return jsonify({"error":"Payment required or expired"}), 402

        # ë‹¨ì¼ ë¡œê·¸ì¸ ê°•ì œ: ë™ì‹œì ‘ì† í—ˆìš©ì´ ì•„ë‹ ë•Œë§Œ ë²„ì „/JTI ê²€ì¦
        if not allow_concurrent:
            if tok_ver != db_ver or (db_jti and tok_jti != db_jti):
                return jsonify({"error":"Session invalidated. Please log in again.", "code":"SESSION"}), 401

        # ë„ë©”ì¸ ì œí•œ(ì˜µì…˜)
        if site_url:
            origin  = (request.headers.get("Origin") or "").lower()
            referer = (request.headers.get("Referer") or "").lower()
            if site_url.lower() not in origin and site_url.lower() not in referer:
                return jsonify({"error":"Origin not allowed"}), 403

        return fn(*args, **kwargs)
    return wrapper

def require_admin(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        auth = request.headers.get("Authorization","").strip()
        if not auth.startswith("Bearer "):
            return jsonify({"error":"Unauthorized"}), 401
        token = auth.split(" ",1)[1]

        try:
            data = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALG])
        except Exception:
            return jsonify({"error":"Invalid token"}), 401

        username = data.get("sub","")
        tok_ver  = int(data.get("ver", 0) or 0)
        tok_jti  = data.get("jti","") or ""

        conn = sqlite3.connect(DB_PATH)
        cur  = conn.cursor()
        cur.execute(
            "SELECT role, is_active, paid_until, token_version, last_jti, allow_concurrent "
            "FROM users WHERE username=?",
            (username,)
        )
        row = cur.fetchone()
        conn.close()

        if not row:
            return jsonify({"error":"Unauthorized"}), 401

        role, is_active, paid_until, db_ver, db_jti, allow_concurrent = (
            (row[0] or "user"), row[1], row[2], int(row[3] or 0), (row[4] or ""), bool(row[5])
        )

        # ê²°ì œ/ê¸°ê°„/í™œì„± ì²´í¬
        try:
            if not is_active or not paid_until or datetime.utcnow() > datetime.fromisoformat(paid_until):
                return jsonify({"error":"Payment required or expired"}), 402
        except Exception:
            return jsonify({"error":"Payment required or expired"}), 402

        # ë‹¨ì¼ ë¡œê·¸ì¸ ê°•ì œ â€” í—ˆìš© ê³„ì •ì€ ì˜ˆì™¸
        if not allow_concurrent:
            if tok_ver != db_ver or (db_jti and tok_jti != db_jti):
                return jsonify({"error":"Session invalidated. Please log in again.", "code":"SESSION"}), 401

        if role != "admin":
            return jsonify({"error":"Admin only"}), 403

        return fn(*args, **kwargs)
    return wrapper


RULE_PATH = os.getenv("RULE_PATH", "kr-medhealth.yaml")
RULES = {}   # {"rules":[{...}], ...}
RULES_INDEX = {}  # {rule_id: rule_obj}

# === INSERT @ line 467 (right after require_admin ends) ===
def verify_board_auth(payload):
    """
    payload: {"username": "...", "password": "..."}
    - users í…Œì´ë¸”ì˜ ìê²© í™•ì¸
    - ë°˜í™˜: (ok, username, is_admin)
    """
    try:
        u = (payload.get("username") or "").strip()
        p = payload.get("password") or ""
        user = _get_user(u)
        if not user or not bcrypt.verify(p, user["password_hash"]):
            return False, "", False
        # ê²°ì œ/í™œì„± ìœ íš¨
        if not _is_paid_and_active(user):
            return False, "", False
        is_admin = (user.get("role") == "admin")
        return True, user["username"], is_admin
    except Exception:
        return False, "", False

# ================== ìœ í‹¸ ==================

# === username ê·œì¹™: ì†Œë¬¸ì ì˜ë¬¸/ìˆ«ì/._- 3~32ì ===
USERNAME_RE = re.compile(r"^[a-z0-9._-]{3,32}$")

def normalize_username(u: str) -> str:
    # ê³µë°± ì œê±° + ì†Œë¬¸ì í†µì¼
    return (u or "").strip().lower()

def validate_username(u: str):
    if not USERNAME_RE.match(u or ""):
        raise ValueError("username must be 3-32 chars: a-z, 0-9, dot, underscore, hyphen only")

def search_db(sentence):
    try:
        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()
        cur.execute("SELECT alternative FROM sentences WHERE original = ?", (sentence,))
        rows = cur.fetchall()
        conn.close()
        return [r[0] for r in rows] if rows else []
    except Exception as e:
        print("DB ê²€ìƒ‰ ì˜¤ë¥˜:", e)
        return []

def find_all(text, substring, start_from=0):
    out = []
    i = start_from
    L = len(substring)
    if not substring:
        return out
    while True:
        i = text.find(substring, i)
        if i == -1:
            break
        out.append(i)
        i += L
    return out

def chunk_text_with_offsets(text, max_chars=MAX_CHARS_PER_CHUNK):
    chunks = []
    n = len(text)
    i = 0
    while i < n:
        end = min(i + max_chars, n)
        if end < n:
            cut = text.rfind("\n", i, end)
            if cut == -1 or cut <= i + int(max_chars * 0.3):
                cut = end
        else:
            cut = end
        chunks.append((i, text[i:cut]))
        i = cut
    return chunks

_json_array_pattern = re.compile(r"\[\s*{.*?}\s*\]", re.DOTALL)
def extract_json_array(s):
    if not s:
        return []
    s = re.sub(r"^```json\s*|\s*```$", "", s.strip(), flags=re.IGNORECASE | re.DOTALL)
    m = _json_array_pattern.search(s)
    if not m:
        try:
            j = json.loads(s)
            return j if isinstance(j, list) else []
        except:
            return []
    try:
        return json.loads(m.group(0))
    except Exception as e:
        print("JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        return []

def basic_kr_sentence_split(text):
    parts = re.split(r"([\.?!]+|\n+)", text)
    out, buf = [], ""
    for p in parts:
        if p is None:
            continue
        buf += p
        if p.endswith((".", "?", "!", "\n")) or p.strip() == "":
            s = buf.strip()
            if s:
                out.append(s)
            buf = ""
    if buf.strip():
        out.append(buf.strip())
    return out

def add_context(text, start, length, window=8):
    before = text[max(0, start - window): start]
    after  = text[start + length: start + length + window]
    return before, after

def gpt_call(model, messages):
    return client.chat.completions.create(model=model, messages=messages)

# --- ê³µë°±/ë¬¸ì ì •ê·œí™” & ê³µë°±ë¬´ì‹œ í‚¤ì›Œë“œìš© ---
def kr_norm(s: str) -> str:
    s = unicodedata.normalize("NFKC", s or "")
    s = s.replace("%", "í¼ì„¼íŠ¸")
    s = re.sub(r"\s+", " ", s)
    return s

def spacing_agnostic_regex(kw: str) -> str:
    parts = list(kw)
    return r"\s*".join(map(re.escape, parts))

# --- [ADD] í•„ìˆ˜ í‚¤ì›Œë“œ ìœ„ì¹˜ ì°¾ê¸°(ê³µë°± ë¬´ì‹œ + ëŒ€ì†Œë¬¸ì/ì „ê° í˜¸í™˜) ---
def _looks_like_regex(kw: str) -> bool:
    # (), [], {}, +, ?, *, |, . ê°™ì€ ë©”íƒ€ë¬¸ìê°€ ìˆì„ ë•Œë§Œ ì •ê·œì‹ìœ¼ë¡œ ì·¨ê¸‰
    return bool(re.search(r"[.^$*+?{}\[\]|()\\]", kw or ""))

def _find_positions_ko(hay: str, kw: str):
    hits = []
    if not hay or not kw:
        return hits

    if _looks_like_regex(kw):
        rx = re.compile(kw, re.IGNORECASE)
    else:
        # ì¼ë°˜ ë¬¸ìì—´ â†’ ê³µë°±/ê¸°í˜¸ ë¬´ì‹œ íŒ¨í„´ìœ¼ë¡œ ë³€í™˜
        rx = re.compile(spacing_agnostic_regex(kr_norm(kw)), re.IGNORECASE)

    for m in rx.finditer(hay):
        hits.append({"start": m.start(), "end": m.end()})
    return hits


def _guide_keyword_windows(text: str, template: str,
                           window_size: int = 80,
                           min_core_hits: int = 2,
                           max_terms: int = 5):
    """
    í…œí”Œë¦¿ ë¬¸ì¥ì—ì„œ í•µì‹¬ ë‹¨ì–´ë¥¼ ëª‡ ê°œ ë½‘ì•„ì„œ(core_terms),
    ì›ë¬¸ì—ì„œ window_size ê¸€ì ì•ˆì— ì„œë¡œ ë‹¤ë¥¸ í•µì‹¬ ë‹¨ì–´ê°€
    min_core_hits ê°œ ì´ìƒ ê°™ì´ ë“±ì¥í•˜ëŠ” êµ¬ê°„ì„ í›„ë³´ë¡œ ì°¾ëŠ”ë‹¤.

    ë°˜í™˜: [{start, end, sentence, score, core_hits, core_terms}, ...]
    """
    text = text or ""
    template = (template or "").strip()
    if not text or not template:
        return []

    window_size = max(30, int(window_size or 80))
    min_core_hits = max(1, int(min_core_hits or 2))

    # í…œí”Œë¦¿ì—ì„œ í•µì‹¬ ë‹¨ì–´ ì¶”ì¶œ (ì´ë¯¸ server.py ì— core_terms í•¨ìˆ˜ ìˆìŒ)
    terms = core_terms(template, max_terms=max_terms)
    if not terms:
        return []

    # ê° í•µì‹¬ ë‹¨ì–´ì˜ ì¶œí˜„ ìœ„ì¹˜ ìˆ˜ì§‘
    hits = []
    for t in terms:
        for h in _find_positions_ko(text, t):
            hits.append((h["start"], t))
    if not hits:
        return []

    hits.sort(key=lambda x: x[0])

    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ "ì„œë¡œ ë‹¤ë¥¸ í•µì‹¬ì–´" ê°œìˆ˜ ì„¸ê¸°
    from collections import defaultdict
    left = 0
    counts = defaultdict(int)
    distinct = set()
    n = len(hits)
    candidates = []
    seen_spans = set()

    for right in range(n):
        pos_r, term_r = hits[right]
        counts[term_r] += 1
        distinct.add(term_r)

        # í˜„ì¬ ìœˆë„ìš° í­ì´ window_size ë¥¼ ë„˜ìœ¼ë©´ ì™¼ìª½ ì¤„ì´ê¸°
        while left <= right and pos_r - hits[left][0] > window_size:
            pos_l, term_l = hits[left]
            counts[term_l] -= 1
            if counts[term_l] <= 0:
                distinct.discard(term_l)
            left += 1

        # í•µì‹¬ì–´ ì¢…ë¥˜ê°€ min_core_hits ê°œ ì´ìƒì´ë©´ í›„ë³´
        if len(distinct) >= min_core_hits:
            start = hits[left][0]
            end = min(start + window_size, len(text))
            span = (start, end)
            if span in seen_spans:
                continue
            seen_spans.add(span)
            seg = text[start:end]
            candidates.append({
                "start": start,
                "end": end,
                "sentence": seg,
                "score": float(len(distinct)),   # ì ìˆ˜ = ì„œë¡œ ë‹¤ë¥¸ í•µì‹¬ì–´ ê°œìˆ˜
                "core_hits": len(distinct),
                "core_terms": sorted(distinct),
            })

    # í•µì‹¬ì–´ ê°œìˆ˜(desc) â†’ ê¸¸ì´ ì§§ì€ ìˆœ â†’ ì‹œì‘ ìœ„ì¹˜ ìˆœ
    candidates.sort(key=lambda c: (-c["core_hits"], c["end"] - c["start"], c["start"]))
    return candidates


# ================== ì‹¬ì˜ ê·œì¹™ ë¡œë”©/ìŠ¤ìº” ==================
def load_rules(path=RULE_PATH):
    global RULES, RULES_INDEX
    try:
        with open(path, "r", encoding="utf-8") as f:
            RULES = yaml.safe_load(f) or {}
        if not isinstance(RULES, dict):
            RULES = {}
        print(f"âœ… ì‹¬ì˜ ê·œì¹™ ë¡œë“œ ì™„ë£Œ: {path}")
        pack = RULES.get("pack")
        ver = RULES.get("version")
        topics = RULES.get("topics")
        if pack or ver or topics:
            print(f"  - pack={pack}, version={ver}, topics={topics}")
        RULES_INDEX = {}
        for r in (RULES.get("rules") or []):
            rid = (r or {}).get("id")
            if rid:
                RULES_INDEX[str(rid)] = r
        print(f"  - rules indexed: {len(RULES_INDEX)}")
    except Exception as e:
        print("[WARN] ì‹¬ì˜ ê·œì¹™ ë¡œë“œ ì‹¤íŒ¨:", e)
        RULES, RULES_INDEX = {}, {}


load_rules()

# === (ADD) ì‚¬ìœ /ë²•ë ¹ ë§¤í•‘ ìœ í‹¸ (YAML meta ì‚¬ìš©) ====================
def _load_reason_index_from_rules():
    meta = (RULES or {}).get("meta") or {}
    cats = meta.get("reason_categories") or {}
    mapping = []
    for ent in meta.get("rule_category_by_prefix") or []:
        try:
            rx = re.compile(ent.get("pattern", ""), re.IGNORECASE)
            mapping.append((rx, ent.get("category")))
        except re.error:
            pass
    return cats, mapping

REASON_CATS, REASON_MAP = _load_reason_index_from_rules()

def _reason_for_rule_id(rule_id: str):
    rid = rule_id or ""
    for rx, cat in (REASON_MAP or []):
        if rx.search(rid):
            info = (REASON_CATS or {}).get(cat) or {}
            reason = info.get("reason")
            legal  = info.get("legal")
            url    = info.get("legal_url")
            if not reason:
                return None, None
            small = None
            if legal and url:
                small = f"<small style='color:#777'>(ê·¼ê±°: {legal} Â· <a href=\"{url}\" target=\"_blank\">ë²•ë ¹</a>)</small>"
            elif legal:
                small = f"<small style='color:#777'>(ê·¼ê±°: {legal})</small>"
            return f"ì‚¬ìœ : {reason}", small
    return None, None

_rule_id_rx = re.compile(r"\(rule:([^)]+)\)")
def attach_reasons(items):
    """
    ê²°ê³¼ í•­ëª©ì— ì‚¬ìš©ì ì¹œí™”ì  ì‚¬ìœ /ì¶œì²˜ë¥¼ ë¶€ì°©í•˜ê³ ,
    ë‚´ë¶€ rule ID ë…¸ì¶œì„ ì œê±°í•œë‹¤.
    ìš°ì„ ìˆœìœ„:
      1) RULES_INDEX[rule_id]ì˜ rationale / legal_ref
      2) meta(reason_categories/rule_category_by_prefix) í´ë°±
    """
    for it in items:
        rid = it.get("rule_id")
        if not rid:
            m = _rule_id_rx.search(it.get("reason","") or "")
            rid = m.group(1) if m else None

        reason_line = None
        legal_small = None

        # 1) ê·œì¹™ ë³¸ë¬¸ì—ì„œ ì§ì ‘ ì·¨ë“
        rule = RULES_INDEX.get(str(rid)) if rid else None
        if rule:
            rationale = rule.get("rationale") or rule.get("description") or ""
            legal     = rule.get("legal_ref")  or ""   # YAMLì— ì„ íƒì ìœ¼ë¡œ ì¶”ê°€
            if rationale:
                reason_line = rationale
            if legal:
                legal_small = f"<small style='color:#777'>(ì¶œì²˜: {legal})</small>"

        # 2) í´ë°±: meta ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì‚¬ìš©
        if not reason_line:
            rline, small = _reason_for_rule_id(rid or "")
            if rline:
                # rline ì˜ˆ: "ì‚¬ìœ : â€¦" í˜•íƒœ â†’ í†µì¼ ìœ„í•´ ì ‘ë‘ì–´ ì œê±°
                reason_line = rline.replace("ì‚¬ìœ :", "").strip()
            if small:
                legal_small = small

        if reason_line:
            it["reason_line"] = reason_line
        if legal_small:
            it["legal_small"] = legal_small

        # í™”ë©´ ë…¸ì¶œìš© reason ë¬¸ìì—´ì—ì„œ (rule:XXX) ì œê±°
        if it.get("reason"):
            it["reason"] = re.sub(_rule_id_rx, "", it["reason"]).strip()
    return items# =====================================================================

def _iter_rule_patterns(rule):
    patterns = ((rule or {}).get("patterns") or {}).get("any") or []
    for p in patterns:
        if not isinstance(p, dict):
            continue
        if p.get("type") in ("keyword", "regex", "phrase"):
            yield p

def _compile_regex_from_pattern(pat: dict):
    ptype = pat.get("type")
    flags = 0
    if str(pat.get("flags","")).lower().find("i") >= 0 or pat.get("casefold", True):
        flags |= re.IGNORECASE

    if ptype == "keyword":
        val = kr_norm(pat.get("value",""))
        if not val:
            return None, None
        if pat.get("spacing_agnostic", True):
            rx = spacing_agnostic_regex(val)
        else:
            rx = re.escape(val)
        return re.compile(rx, flags), f"kw:{val}"

    if ptype == "regex":
        val = pat.get("value","")
        if not val:
            return None, None
        return re.compile(val, flags), "rx"

    if ptype == "phrase":
        terms = [kr_norm(t) for t in (pat.get("terms") or []) if t]
        if len(terms) < 2:
            return None, None
        max_gap = int(pat.get("max_gap", 6))
        terms_rx = [spacing_agnostic_regex(t) for t in terms]
        rx = terms_rx[0]
        for nxt in terms_rx[1:]:
            rx += rf".{{0,{max_gap}}}" + nxt
        return re.compile(rx, flags), f"ph:{'|'.join(terms)}"
    return None, None

def _rule_excepts(rule):
    ex = ((rule or {}).get("except") or {}).get("any") or []
    out = []
    for r in ex:
        try:
            out.append(re.compile(r, re.IGNORECASE))
        except re.error:
            pass
    return out

def _scan_with_rule(text, rule):
    hits = []
    exceptors = _rule_excepts(rule)
    window = int((rule or {}).get("except_window", 14))
    for p in _iter_rule_patterns(rule):
        rx, _ = _compile_regex_from_pattern(p)
        if not rx:
            continue
        for m in rx.finditer(text):
            s, e = m.start(), m.end()
            seg = text[s:e]
            if exceptors:
                ctx = text[max(0, s - window): min(len(text), e + window)]
                if any(ex.search(ctx) for ex in exceptors):
                    continue
            hits.append((s, e, seg))
    return hits

def rule_scan(text):
    rules = (RULES or {}).get("rules") or []
    items = []
    gid = 0
    for rule in rules:
        rid   = rule.get("id", "")
        topic = rule.get("topic", "")
        sev   = (rule.get("severity") or "warn").lower()
        rationale = rule.get("rationale") or rule.get("description") or ""
        actions   = rule.get("actions") or []
        rule_type = "ì‹¬ì˜ìœ„ë°˜" if sev == "block" else "ì£¼ì˜í‘œí˜„"

        for (s, e, seg) in _scan_with_rule(text, rule):
            before, after = add_context(text, s, e - s)
            sugg = []
            if any(str(a).startswith("suggest:") for a in actions):
                human = "í‘œí˜„ ì™„í™”/ê·¼ê±° ì œì‹œ/ì£¼ì˜ë¬¸ ë³‘ê¸° ê²€í† "
                if "MED" in " ".join(actions):
                    human = "ì˜ë£Œ í‘œí˜„ ì™„í™” ë˜ëŠ” ê°ê´€ ê·¼ê±° ì œì‹œ"
                elif "HFS" in " ".join(actions):
                    human = "ê±´ê¸°ì‹/ì˜ì•½í’ˆ ì˜¤ì¸ ë°©ì§€ ë¬¸êµ¬ë¡œ ìˆ˜ì •"
                elif "GEN_NEED_EVIDENCE" in " ".join(actions):
                    human = "ë¹„êµÂ·ìš°ì›” í‘œí˜„ì€ ì¶œì²˜/ê·¼ê±° ë³‘ê¸°"
                sugg = [human]
            else:
                sugg = ["ë¬¸êµ¬ ì™„í™” ë˜ëŠ” ì‚­ì œ ê²€í† "]

            items.append({
                "id": f"r_{gid}",
                "type": rule_type,
                "original": seg,
                "suggestions": sugg[:3],
                "reason": f"[{topic}] {rationale or 'ê·œì¹™ ë§¤ì¹­'}",
                "rule_id": rid,
                "severity": "high" if sev == "block" else "medium",
                "startIndex": s,
                "endIndex": e,
                "before": before,
                "after": after
            })
            gid += 1

    used = set()
    dedup = []
    for it in sorted(items, key=lambda x: (x["startIndex"], -(x["endIndex"]-x["startIndex"]))):
        k = (it["startIndex"], it["endIndex"], it["type"])
        if k in used:
            continue
        used.add(k)
        dedup.append(it)
    return dedup

# === [ADD] ì™„ê³¡ ë©˜íŠ¸ í¬ë§·í„° =========================================
def _hedged_message(kind: str, score=None, threshold=None):
    """
    kind: "present" | "borderline" | "absent" | "forbid"
    ì¼ê´€ëœ í†¤ ìœ ì§€(ë‹¨ì • ëŒ€ì‹  ì™„ê³¡).
    """
    if kind == "forbid":
        return "ê¸ˆì§€ì–´ë¡œ ë¶„ë¥˜ëœ í‘œí˜„ì´ í¬í•¨ë˜ì—ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
    if kind == "present":
        return "í¬í•¨ë˜ì—ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."  # (ìœ ì‚¬ë„/í‚¤ì›Œë“œ ì¶©ì¡±)
    if kind == "borderline":
        return "ìœ ì‚¬í•˜ê±°ë‚˜ ì¼ë¶€ í¬í•¨ë˜ì–´ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
    return "ëª…í™•í•œ ì¼ì¹˜ê°€ í™•ì¸ë˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."
# ===================================================================

# === [ADD] ê¸ˆì§€ì–´ íŒŒì‹±/ê²€ì‚¬ =========================================
_FORBID_HEAD_RX = re.compile(r"^\s*ê¸ˆì§€ì–´\s*[:\-]\s*(.+)$", re.IGNORECASE)

def _parse_forbid_lines(lines):
    """
    lines: list[str]  (í•„ìˆ˜ê°€ì´ë“œ ì…ë ¥ë€ì˜ ê° ì¤„)
    ì§€ì› í˜•íƒœ:
      - "ê¸ˆì§€ì–´: ë‹¨ì–´1,ë‹¨ì–´2,ë‹¨ì–´3"
      - "ê¸ˆì§€ì–´- ë‹¨ì–´1 ë‹¨ì–´2" (ê³µë°± êµ¬ë¶„ë„ í—ˆìš©)
    ë°˜í™˜: ê¸ˆì§€ì–´ ë¦¬ìŠ¤íŠ¸(list[str])
    """
    out = []
    for ln in (lines or []):
        m = _FORBID_HEAD_RX.match(ln or "")
        if not m:
            continue
        payload = kr_norm(m.group(1))
        # ì‰¼í‘œ ê¸°ì¤€ 1ì°¨ ë¶„ë¦¬ â†’ ì—†ìœ¼ë©´ ê³µë°± ë¶„ë¦¬
        if "," in payload:
            toks = [t.strip() for t in payload.split(",")]
        else:
            toks = [t.strip() for t in re.split(r"\s+", payload)]
        out.extend([t for t in toks if t])
    # ì¤‘ë³µ ì œê±°
    uniq = []
    seen = set()
    for t in out:
        if t not in seen:
            uniq.append(t); seen.add(t)
    return uniq

def _find_forbidden_hits(text: str, forbid_terms: list[str]):
    """
    spacing-agnostic(ê¸€ì ì‚¬ì´ ì„ì˜ ê³µë°± í—ˆìš©) + ëŒ€ì†Œë¬¸ì/ì „ê° í˜¸í™˜.
    ë°˜í™˜: [{"term":..., "start":..., "end":..., "seg":...}, ...]
    """
    text = text or ""
    hits = []
    for term in (forbid_terms or []):
        rx = re.compile(spacing_agnostic_regex(term), re.IGNORECASE)
        for m in rx.finditer(text):
            s, e = m.start(), m.end()
            hits.append({"term": term, "start": s, "end": e, "seg": text[s:e]})
    return hits
# ===================================================================


# ============== (NEW) ë„ëŒì´í‘œ/ìœ ì‚¬ë¬¸ì¥ íƒì§€ ìœ í‹¸ ==============
_punc_rx = re.compile(r"[^\w\u3131-\u318E\uAC00-\uD7A3]+", re.UNICODE)
_ws_rx = re.compile(r"\s+")


def _norm_for_dup(s: str) -> str:
    s = unicodedata.normalize("NFKC", s or "")
    s = s.lower()
    s = _punc_rx.sub(" ", s)
    s = _ws_rx.sub(" ", s).strip()
    return s


def _char_ngrams(s: str, n: int = 3) -> set[str]:
    """ë‹¨ì¼ ê¸¸ì´ n ì— ëŒ€í•œ ë¬¸ì n-gram ì§‘í•©"""
    s = _norm_for_dup(s)
    return {s[i:i + n] for i in range(max(0, len(s) - n + 1))} if s else set()


def _char_ngrams_multi(s: str, lens=(2, 3, 4)) -> set[str]:
    """
    ì—¬ëŸ¬ ê¸¸ì´ n(2,3,4 ë“±)ì— ëŒ€í•œ ë¬¸ì n-gram ì§‘í•©ì„ í•œ ë²ˆì— ë§Œë“ ë‹¤.
    guide_verify_local / ë„ëŒì´í‘œÂ·ìœ ì‚¬ë¬¸ì¥ íƒì§€ì—ì„œ í…œí”Œë¦¿ ê¸¸ì´ë³„ ìœ ì‚¬ë„ ê³„ì‚°ì— ì‚¬ìš©.
    """
    s = _norm_for_dup(s or "")
    out: set[str] = set()
    for n in lens:
        if not isinstance(n, int) or n <= 0:
            continue
        L = len(s)
        if L < n:
            continue
        for i in range(0, L - n + 1):
            out.add(s[i:i + n])
    return out


def _jaccard(a: set, b: set) -> float:
    if not a and not b:
        return 1.0
    if not a or not b:
        return 0.0
    inter = len(a & b)
    union = len(a | b)
    return inter / union if union else 0.0


def _sentence_spans(text: str):
    """ë¬¸ì¥ ë‹¨ìœ„ë¡œ (start, end, raw_sentence) ë°˜í™˜"""
    sentences = basic_kr_sentence_split(text)
    spans: list[tuple[int, int, str]] = []
    cursor = 0
    for s in sentences:
        idx = text.find(s, cursor)
        if idx == -1:
            idx = text.find(s)
        if idx != -1:
            spans.append((idx, idx + len(s), s))
            cursor = idx + len(s)
    return spans

# === [ADD] í•„ìˆ˜ê°€ì´ë“œ(ìœ ì‚¬ë„) ìœ í‹¸ ===================================
def _best_matches_for_template(text: str, template: str, threshold: float = 0.88):
    """
    ë¬¸ì¥ ë‹¨ìœ„ë¡œ í…œí”Œë¦¿ê³¼ 3-gram ìì¹´ë“œ ìœ ì‚¬ë„ ë¹„êµ.
    ë°˜í™˜: dict(present, count, best_score, best_span, matches[...])
    """
    tgrams = _char_ngrams_multi(template or "", (2,3,4))
    spans = _sentence_spans(text or "")
    matches = []
    best = None
    for (s, e, sent) in spans:
        score = _jaccard(tgrams, _char_ngrams_multi(sent, (2,3,4)))
        if score >= max(threshold - 0.06, threshold):  # ë¬¸ì¥ ìŠ¤ìº”ì€ ì‚´ì§ ëŠìŠ¨
            rec = {"start": s, "end": e, "sentence": sent, "score": round(score, 3)}
            matches.append(rec)
            if (not best) or rec["score"] > best["score"]:
                best = rec
    matches.sort(key=lambda x: -x["score"])
    return {
        "present": len(matches) > 0,
        "count": len(matches),
        "best_score": (best or {}).get("score"),
        "best_span": best,
        "matches": matches[:10]
    }

def _scan_by_rolling_window(text, template, threshold, size_lo=0.6, size_hi=1.6):
    T = template or ""
    S = text or ""
    # ìœ ì‚¬ë„ ì „ìš© ì •ê·œí™”ë¡œ ë¹„êµ(ì›ë¬¸ì€ í•˜ì´ë¼ì´íŠ¸ìš©ìœ¼ë¡œ ê·¸ëŒ€ë¡œ ìœ ì§€)
    Tn = _ko_sim_norm(T)
    Sn = _ko_sim_norm(S)
    if not Tn or not Sn:
        return []
    tpl_len = max(1, len(Tn))
    min_len = max(8, int(tpl_len * size_lo))
    max_len = max(min_len, int(tpl_len * size_hi))
    tpl_grams = _char_ngrams_multi(Tn, (2,3,4))

    hits = []
    step1 = max(4, int(tpl_len * 0.20))  # ë” ì´˜ì´˜
    step2 = max(4, int(tpl_len * 0.12))
    n = len(Sn)
    for i in range(0, n, step1):
        for L in range(min_len, min(max_len, n - i) + 1, step2):
            segN = Sn[i:i+L]
            if not segN: continue
            sc = _jaccard(tpl_grams, _char_ngrams_multi(segN, (2,3,4)))
            if sc >= threshold:
                # ì›ë¬¸ ì¢Œí‘œë¡œ ê·¼ì‚¬ ì—­ë§¤í•‘
                # (ì •ê·œí™” ì „ ì›ë¬¸ Sì—ì„œ ê°™ì€ ë²”ìœ„ë¥¼ ì‚¬ìš©)
                raw = S[i:i+L]
                hits.append({"start": i, "end": i+L, "sentence": raw, "score": round(sc, 3)})
    # ìƒìœ„ ë¹„ì¤‘ë³µ 10ê°œë§Œ ìœ ì§€
    hits.sort(key=lambda x: -x["score"])
    keep, used = [], []
    for h in hits:
        if not any(not (h["end"] <= u["start"] or h["start"] >= u["end"]) for u in used):
            keep.append(h); used.append(h)
        if len(keep) >= 10: break
    return keep

# --- [ADD] í•„ìˆ˜ê°€ì´ë“œ ë¬¸ë‹¨ í›„ë³´ íƒì§€ ìœ í‹¸ ---

_PAR_BREAK_RX = re.compile(r"\n\s*\n+")

def _paragraph_spans(text: str):
    spans = []
    if not text:
        return spans
    n = len(text)
    last = 0
    for m in _PAR_BREAK_RX.finditer(text):
        s = last
        e = m.start()
        seg = text[s:e]
        if seg.strip():
            spans.append((s, e, seg))
        last = m.end()
    if last < n:
        seg = text[last:]
        if seg.strip():
            spans.append((last, n, seg))
    return spans


def _extract_core_terms(tpl: str, max_terms: int = 5):
    from string import digits
    norm = kr_norm(tpl)
    toks = tokenize(norm)
    core = []
    for t in toks:
        if len(t) < 2:
            continue
        if all(ch in digits for ch in t):
            continue
        if t in core:
            continue
        core.append(t)
        if len(core) >= max_terms:
            break
    return core


def _guide_paragraph_candidates(
    text: str,
    templates: list[str],
    need_terms: int = 2,
    window_size: int = 80,
    step: int = 40,
):
    """
    í•„ìˆ˜ê°€ì´ë“œ í…œí”Œë¦¿ë³„ë¡œ, ì›ê³ ì—ì„œ window_size ê¸€ì ì•ˆì—
    í•µì‹¬ ë‹¨ì–´ê°€ need_termsê°œ ì´ìƒ ê°™ì´ ë“±ì¥í•˜ëŠ” êµ¬ê°„ì„ í›„ë³´ë¡œ ì¡ëŠ”ë‹¤.

    - ë¬¸ë‹¨/ë¬¸ì¥ ê²½ê³„ ë¬´ì‹œ, ê³ ì • ê¸¸ì´ ë¡¤ë§ ìœˆë„ìš° ê¸°ë°˜
    - ë°˜í™˜: {template: [ {start,end,hit_count,hit_terms,text}, ... ], ...}
    """
    text = text or ""
    n = len(text)
    result: dict[str, list[dict]] = {}
    if n == 0 or not templates:
        return result

    # ë„ˆë¬´ ì‘ì€ ê°’ ë°©ì§€
    window_size = max(40, int(window_size or 80))
    step = max(20, int(step or (window_size // 2)))

    for tpl in templates:
        core = _extract_core_terms(tpl)
        if len(core) < need_terms:
            # í•µì‹¬ ë‹¨ì–´ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ìŠ¤í‚µ
            continue

        cand_map: dict[tuple[int, int], dict] = {}

        # 0 ~ ëê¹Œì§€ window_size ê¸€ì ê¸°ì¤€ìœ¼ë¡œ ìŠ¬ë¼ì´ë”©
        for start in range(0, n, step):
            end = min(start + window_size, n)
            seg = text[start:end]
            if not seg.strip():
                continue

            hit_terms = []
            for term in core:
                if re.search(spacing_agnostic_regex(term), seg, flags=re.IGNORECASE):
                    hit_terms.append(term)

            if len(hit_terms) >= need_terms:
                # ê²€ìˆ˜ìê°€ ë³´ê¸° í¸í•˜ê²Œ, ê°™ì€ ì¤„ ê¸°ì¤€ìœ¼ë¡œ ì•½ê°„ í™•ì¥
                ctx_start = text.rfind("\n", 0, start)
                if ctx_start == -1:
                    ctx_start = start
                else:
                    ctx_start += 1  # ê°œí–‰ ë°”ë¡œ ë’¤ë¶€í„°

                ctx_end = text.find("\n", end)
                if ctx_end == -1:
                    ctx_end = end

                key = (ctx_start, ctx_end)
                prev = cand_map.get(key)
                if (not prev) or (len(hit_terms) > prev["hit_count"]):
                    cand_map[key] = {
                        "start": ctx_start,
                        "end": ctx_end,
                        "hit_count": len(hit_terms),
                        "hit_terms": hit_terms,
                        "text": text[ctx_start:ctx_end],
                    }

        if cand_map:
            # hit_count ë§ì€ ìˆœ + ìœ„ì¹˜ìˆœ ì •ë ¬
            result[tpl] = sorted(
                cand_map.values(),
                key=lambda x: (-x["hit_count"], x["start"]),
            )

    return result


def _band_message(score: float, threshold: float) -> str:
    if score >= max(threshold + 0.04, 0.92):
        return "í¬í•¨ë˜ì—ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
    if score >= threshold:
        return "ìœ ì‚¬í•œ ë¬¸êµ¬ê°€ ê°ì§€ë©ë‹ˆë‹¤."
    if score >= max(0.82, threshold - 0.06):
        return "ë¶€ë¶„ì ìœ¼ë¡œ ìœ ì‚¬í•˜ì—¬ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
    return "ëª…í™•í•œ ì¼ì¹˜ê°€ í™•ì¸ë˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."
# ====================================================================


def _dedup_intra(text, min_len=6, sim_threshold=0.85):
    spans = _sentence_spans(text)
    # 1) exact ë„ëŒì´í‘œ(ì •ê·œí™” í›„ ë™ì¼)
    buckets = defaultdict(list)  # norm -> [(i, start, end, raw)]
    for i, (s, e, raw) in enumerate(spans):
        n = _norm_for_dup(raw)
        if len(n) >= min_len:
            buckets[n].append((i, s, e, raw))

    exact_groups = []
    for n, occ in buckets.items():
        if len(occ) >= 2:
            exact_groups.append({
                "norm": n,
                "occurrences": [
                    {"index": i, "start": s, "end": e, "original": raw} for (i,s,e,raw) in occ
                ]
            })

    # 2) similar(ìì¹´ë“œ: ë¬¸ì 3-gram)
    sims = []
    ngrams = []
    for i, (s, e, raw) in enumerate(spans):
        n = _norm_for_dup(raw)
        if len(n) >= min_len:
            ngrams.append((i, s, e, raw, _char_ngrams(raw, 3)))
    for a in range(len(ngrams)):
        i, s1, e1, r1, g1 = ngrams[a]
        for b in range(a+1, len(ngrams)):
            j, s2, e2, r2, g2 = ngrams[b]
            score = _jaccard(g1, g2)
            if score >= sim_threshold and r1 != r2:
                sims.append({
                    "i": i, "j": j, "score": round(score, 3),
                    "a": {"start": s1, "end": e1, "original": r1},
                    "b": {"start": s2, "end": e2, "original": r2}
                })

    return exact_groups, sims

def _dedup_inter(files, min_len=6, sim_threshold=0.85):
    """
    files: [{"name": str, "text": str}, ...]
    êµì°¨ íŒŒì¼ ê°„ ë™ì¼/ìœ ì‚¬ ë¬¸ì¥ íƒì§€
    """
    # ìˆ˜ì§‘
    recs = []  # (file_idx, name, sent_idx, start, end, raw, norm, ngrams)
    for fi, f in enumerate(files):
        name = f.get("name") or f"file_{fi+1}"
        text = f.get("text") or ""
        spans = _sentence_spans(text)
        for si, (s, e, raw) in enumerate(spans):
            n = _norm_for_dup(raw)
            if len(n) >= min_len:
                recs.append((fi, name, si, s, e, raw, n, _char_ngrams(raw, 3)))

    # exact
    exact_map = defaultdict(list)  # norm -> [occ...]
    for fi, name, si, s, e, raw, n, grams in recs:
        exact_map[n].append({"file": name, "fileIndex": fi, "sentIndex": si,
                             "start": s, "end": e, "original": raw})

    exact = []
    for n, occ in exact_map.items():
        # ì„œë¡œ ë‹¤ë¥¸ íŒŒì¼ì—ì„œ 2ê°œ ì´ìƒì¼ ë•Œë§Œ ì˜ë¯¸
        uniq_files = {o["fileIndex"] for o in occ}
        if len(uniq_files) >= 2:
            exact.append({"norm": n, "occurrences": occ})

    # similar
    sims = []
    for a in range(len(recs)):
        fi1, n1, si1, s1, e1, r1, norm1, g1 = recs[a]
        for b in range(a+1, len(recs)):
            fi2, n2, si2, s2, e2, r2, norm2, g2 = recs[b]
            if fi1 == fi2:  # ê°™ì€ íŒŒì¼ì€ intraì—ì„œ ë‹¤ë£¸
                continue
            score = _jaccard(g1, g2)
            if score >= sim_threshold and r1 != r2:
                sims.append({
                    "score": round(score, 3),
                    "a": {"fileIndex": fi1, "file": n1, "sentIndex": si1, "start": s1, "end": e1, "original": r1},
                    "b": {"fileIndex": fi2, "file": n2, "sentIndex": si2, "start": s2, "end": e2, "original": r2},
                })
    return exact, sims

# === [ADD] í•„ìˆ˜ë‚´ìš©(í…œí”Œë¦¿) ìœ ì‚¬ë„: ì¤‘ë³µì—”ì§„(_dedup_intra) ì¬ì‚¬ìš© =========
def _guide_match_by_dedup_engine(text: str, templates: list[str],
                                 min_len: int = 6, sim_threshold: float = 0.85):
    """
    templates: í•„ìˆ˜ë‚´ìš© ë¼ì¸ë“¤(ë¹ˆ ì¤„/ì£¼ì„ ì œì™¸)
    - ë¬¸ì¥ ë‹¨ìœ„ + 3-gram ìì¹´ë“œ(ì¤‘ë³µì—”ì§„ê³¼ ë™ì¼)ë¡œ ìŠ¤ìº”
    - ê²°ê³¼ëŠ” í…œí”Œë¦¿ë³„ best hitë§Œ ë°˜í™˜
    """
    spans = _sentence_spans(text or "")
    # í…ìŠ¤íŠ¸ ìª½ ngram ë¯¸ë¦¬ ê³„ì‚° (ì†ë„)
    sent_grams = []
    for (s, e, raw) in spans:
        n = _norm_for_dup(raw)
        if len(n) >= min_len:
            sent_grams.append((s, e, raw, _char_ngrams(raw, 3)))

    out = []
    for tpl in (templates or []):
        tpl = (tpl or "").strip()
        if not tpl: 
            continue
        tgrams = _char_ngrams(tpl, 3)  # ì¤‘ë³µì—”ì§„ê³¼ ë™ì¼ ê¸°ì¤€
        best = None
        for (s, e, raw, g) in sent_grams:
            sc = _jaccard(tgrams, g)
            if sc >= sim_threshold:
                rec = {"start": s, "end": e, "sentence": raw, "score": round(sc, 3)}
                if (not best) or rec["score"] > best["score"]:
                    best = rec
        out.append({
            "template": tpl,
            "present": bool(best),
            "best": best,
        })
    return out
# ==========================================================================


# === [ADD] token-level cosine (unigram+bigram) =========================
_WORD_RE = re.compile(r"[ê°€-í£a-z0-9]+", re.IGNORECASE)
_STOP = {"ì€","ëŠ”","ì´","ê°€","ì„","ë¥¼","ì—","ì˜","ë„","ì™€","ê³¼","ë°","ìœ¼ë¡œ","ì—ì„œ","ë¶€í„°","ê¹Œì§€","í•˜ê³ ","ê·¸ë¦¬ê³ ","ë˜ëŠ”","ìˆ˜","ê²ƒ","ë“±","ì…ë‹ˆë‹¤","í•©ë‹ˆë‹¤","ìˆìŠµë‹ˆë‹¤"}

def _ko_word_norm(s: str) -> list[str]:
    """ê°€ë²¼ìš´ êµ­ë¬¸ í† í° ì •ê·œí™”(ì†Œë¬¸ì, ë¶ˆìš©ì–´ ì œê±°, í”í•œ ì–´ë¯¸ ì†Œê±°)"""
    if not s: return []
    t = kr_norm(s).lower()
    toks = _WORD_RE.findall(t)
    out = []
    for w in toks:
        if w in _STOP: 
            continue
        # ë¼ì´íŠ¸ ìŠ¤í…Œë° (ê³¼í•˜ì§€ ì•Šê²Œ ìì£¼ ë‚˜ì˜¤ëŠ” ì–´ë¯¸ë§Œ)
        for suf in ("ìŠµë‹ˆë‹¤","í•©ë‹ˆë‹¤","ì˜€ë‹¤","ì´ë‹¤","í–ˆë‹¤","ìˆëŠ”","ë°›ì„","í•˜ëŠ”","í•´ì•¼","í•´ì„œ"):
            if w.endswith(suf) and len(w) > len(suf)+1:
                w = w[:-len(suf)]
                break
        if len(w) >= 2:
            out.append(w)
    return out

def _bow_vec(tokens: list[str]) -> dict[str, float]:
    """unigram + bigram count ë²¡í„°"""
    v: dict[str, float] = {}
    for i, w in enumerate(tokens):
        v[w] = v.get(w, 0.0) + 1.0
        if i+1 < len(tokens):
            bg = w + " " + tokens[i+1]
            v[bg] = v.get(bg, 0.0) + 1.0
    return v

def _cosine(a: dict[str, float], b: dict[str, float]) -> float:
    if not a or not b: 
        return 0.0
    dot = 0.0
    for k, va in a.items():
        vb = b.get(k)
        if vb: dot += va * vb
    na = math.sqrt(sum(x*x for x in a.values()))
    nb = math.sqrt(sum(x*x for x in b.values()))
    if na == 0.0 or nb == 0.0:
        return 0.0
    return dot / (na * nb)
# ======================================================================


# ==================== Flask ====================
from flask import Flask, request, jsonify
from flask_cors import CORS
import re

app = Flask(__name__)

# HEADëŠ” ë¼ìš°íŒ… ë§¤ì¹­ì„ í†µê³¼í•´ì•¼ í•˜ë¯€ë¡œ ìºì¹˜ì˜¬ ë¼ìš°íŠ¸ê°€ í•„ìš”
@app.route("/", defaults={"path": ""}, methods=["HEAD"])
@app.route("/<path:path>", methods=["HEAD"])
def __head_ok(path):
    return ("", 200, {"Content-Type": "text/plain; charset=utf-8"})

@app.route("/healthz", methods=["GET", "HEAD"])
def __healthz():
    if request.method == "HEAD":
        return ("", 200, {"Content-Type": "text/plain; charset=utf-8"})
    return jsonify({"ok": True})


# 1) HEAD í—¬ìŠ¤ì²´í¬/í”„ë¡ì‹œ ì•ˆì „ ê°€ë“œ (ëª¨ë“  ê²½ë¡œ ê³µí†µ)
@app.before_request
def _head_guard():
    if request.method == "HEAD":
        return ("", 200, {"Content-Type": "text/plain; charset=utf-8"})

# 2) CORS (í”„ë¦¬ë·°/í„°ë„/ë¡œì»¬ í—ˆìš©)
ALLOWED_ORIGINS = [
    "https://glefit-frontend.vercel.app",
    re.compile(r"https://.*\.vercel\.app"),
    re.compile(r"https://.*\.trycloudflare\.com"),
    "http://localhost:3000",
]
CORS(
    app,
    resources={r"/*": {"origins": ALLOWED_ORIGINS}},
    supports_credentials=True,
    allow_headers=["*"],
    expose_headers=["*"],
)

# 3) ë£¨íŠ¸ & í—¬ìŠ¤ â€” ë‹¨ì¼ ì •ì˜ë§Œ ìœ ì§€
@app.route("/", methods=["GET", "HEAD"])
def root():
    # HEADëŠ” ìœ„ before_requestì—ì„œ ì´ë¯¸ 200 ì²˜ë¦¬ë¨ â†’ ì—¬ê¸°ì„œëŠ” GETë§Œ ë„ë‹¬
    return jsonify({"ok": True, "service": "glefit-server"}), 200

@app.route("/health", methods=["GET", "HEAD"])
def health():
    if request.method == "HEAD":
        return ("", 200, {"Content-Type": "text/plain; charset=utf-8"})
    return jsonify({"ok": True, "routes": [
        "/","/health",
        "/auth/login","/auth/ping","/auth/me",
        "/admin/issue_user","/admin/set_active","/admin/reset_password",
        "/admin/list_users","/admin/delete_user",
        "/verify","/policy_verify","/dedup_intra","/dedup_inter","/spell/local",
        "/guide_forbid_check","/guide_keyword_count","/guide_verify_local","/guide_verify_dedup"
    ]})

@app.post("/guide_forbid_check")
@require_user
def guide_forbid_check():
    """
    body: {
      "text": str,                    # ì›ê³ 
      "guide_lines": [str] | str      # í•„ìˆ˜ê°€ì´ë“œ ì…ë ¥ë€(ë¼ì¸ ë°°ì—´ ë˜ëŠ” ê°œí–‰ë¬¸ì í¬í•¨ ë¬¸ìì—´)
    }
    - ì˜ˆ) guide_lines ì•ˆì— "ê¸ˆì§€ì–´: ë¹„ë§Œì¹˜ë£Œ, ì „ì•¡ë³´ì¥" ë˜ëŠ” "ê¸ˆì§€ì–´- ê³ íš¨ëŠ¥ ì´ˆíŠ¹ê°€" ë“±
    """
    try:
        data = request.get_json(force=True, silent=True) or {}
        text = (data.get("text") or "")
        lines = data.get("guide_lines")
        if isinstance(lines, str):
            guide_lines = [ln.strip() for ln in lines.splitlines()]
        else:
            guide_lines = [str(x or "").strip() for x in (lines or [])]

        # ì¼ë°˜/ì²´í—˜ 100KB ê°€ë“œ
        limit = enforce_size_limit_or_400(text)
        if limit: return limit

        forbid_terms = _parse_forbid_lines(guide_lines)
        hits = _find_forbidden_hits(text, forbid_terms)

        # ì™„ê³¡ ë©˜íŠ¸
        message = _hedged_message("absent")
        if hits:
            message = _hedged_message("forbid")

        # í•˜ì´ë¼ì´íŠ¸/íŒ¨ë„ë¡œ ë°”ë¡œ ì“¸ ìˆ˜ ìˆê²Œ ê°€ê³µ
        items = []
        gid = 0
        for h in hits[:200]:
            items.append({
                "id": f"forbid_{gid}",
                "type": "ê¸ˆì§€ì–´",
                "original": h["seg"],
                "reason": f"[ê¸ˆì§€ì–´] '{h['term']}'",
                "severity": "high",
                "startIndex": h["start"],
                "endIndex": h["end"],
                "suggestions": ["ë¬¸êµ¬ ì™„í™” ë˜ëŠ” ì‚­ì œ ê²€í† "]
            })
            gid += 1

        return jsonify({
            "ok": True,
            "message": message,           # ë‹¨ì • ëŒ€ì‹  ì™„ê³¡
            "terms": forbid_terms,
            "count": len(hits),
            "items": items
        })
    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500

@app.route("/auth/login", methods=["POST"])
def auth_login():
    payload = request.get_json(force=True, silent=True) or {}
    username = (payload.get("username") or "").strip()
    password = payload.get("password") or ""
    u = _get_user(username)
    if not u or not bcrypt.verify(password, u["password_hash"]):
        return jsonify({"error":"Bad credentials"}), 401
    if not _is_paid_and_active(u):
        return jsonify({"error":"Payment required", "code":"PAYMENT"}), 402

        # (ë‹¨ì¼ ë¡œê·¸ì¸ìš© ë²„ì „/í† í°ID ì—…ë°ì´íŠ¸) â€” ë™ì‹œì ‘ì† í—ˆìš© ê³„ì •ì€ ì˜ˆì™¸
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("SELECT token_version, allow_concurrent FROM users WHERE username=?", (username,))
    row = cur.fetchone()
    cur_ver = int((row[0] if row else 0) or 0)
    allow_concurrent = bool(row[1]) if row and row[1] is not None else False

    if allow_concurrent:
        new_ver = cur_ver
        new_jti = ""
    else:
        new_ver = cur_ver + 1
        new_jti = str(uuid.uuid4())
        cur.execute(
            "UPDATE users SET token_version=?, last_jti=? WHERE username=?",
            (new_ver, new_jti, username)
        )
        conn.commit()
    conn.close()

    token = jwt.encode({
        "sub": u["username"],
        "role": u["role"],
        "ver": new_ver,     # í† í° ë²„ì „
        "jti": new_jti,     # í† í° ê³ ìœ ID
        "exp": datetime.utcnow() + timedelta(hours=12)
    }, JWT_SECRET, algorithm=JWT_ALG)

    log_usage(username, "login", 0)

    return jsonify({"access_token": token, "token_type": "bearer"})

@app.route("/auth/ping", methods=["GET", "OPTIONS"])
@require_user
def auth_ping():
    if request.method == "OPTIONS":
        return "", 200
    return jsonify({"ok": True})

@app.route("/auth/agree_refund", methods=["POST"])
@require_user
def auth_agree_refund():
    username = _username_from_req()
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("INSERT OR REPLACE INTO agreements (username, agreed_at) VALUES (?,?)",
                (username, datetime.utcnow().isoformat()))
    conn.commit(); conn.close()
    return jsonify({"ok": True})

@app.post("/track/visit")
def track_visit():
    try:
        body = request.get_json(force=True, silent=True) or {}
        path = (body.get("path") or "/").strip()
        # í† í°ì´ ìˆìœ¼ë©´ ìœ ì €ëª… ì¶”ì¶œ, ì—†ìœ¼ë©´ ê³µë°± ì²˜ë¦¬
        username = _username_from_req()
        log_visit(username, path)
        return jsonify({"ok": True})
    except Exception:
        return jsonify({"ok": False}), 200

@app.route("/auth/me", methods=["GET", "OPTIONS"])
@require_user
def auth_me():
    if request.method == "OPTIONS":
        return "", 200
    auth = request.headers.get("Authorization","")
    token = auth.split(" ",1)[1]
    data = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALG])
    u = _get_user(data.get("sub",""))
    return jsonify({
        "username": u["username"],
        "role": u["role"],
        "is_active": u["is_active"],
        "paid_until": u["paid_until"],
        "remaining_days": _remaining_days(u["paid_until"]),
    })

@app.route("/admin/create_user", methods=["POST"])
@require_admin
def admin_create_user():
    body = request.get_json(force=True, silent=True) or {}
    username = normalize_username(body.get("username") or "")
    password = body.get("password") or ""
    days = int(body.get("days") or 0)

    try:
        validate_username(username)
    except ValueError as e:
        return jsonify({"error": str(e)}), 400
    if not password:
        return jsonify({"error":"username/password required"}), 400

    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    try:
        paid_until = datetime.utcnow() + timedelta(days=days) if days>0 else datetime.utcnow()
        cur.execute(
            "INSERT INTO users (username, password_hash, is_active, paid_until, role) VALUES (?,?,?,?,?)",
            (username, bcrypt.hash(password), 1 if days>0 else 0, paid_until.isoformat(), "user")
        )
        conn.commit()
        return jsonify({"ok":True})
    except sqlite3.IntegrityError:
        return jsonify({"error":"username exists"}), 409
    finally:
        conn.close()

@app.route("/admin/approve", methods=["POST"])
@require_admin
def admin_approve():
    body = request.get_json(force=True, silent=True) or {}
    username = (body.get("username") or "").strip()
    extend_days = int(body.get("extend_days") or 0)
    note = (body.get("note") or "").strip()

    u = _get_user(username)
    if not u:
        return jsonify({"error":"user not found"}), 404

    base = datetime.utcnow()
    try:
        if u.get("paid_until"):
            base = max(base, datetime.fromisoformat(u["paid_until"]))
    except Exception:
        pass

    new_until = base + timedelta(days=max(1, extend_days))

    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute(
        "UPDATE users SET is_active=?, paid_until=?, notes=? WHERE username=?",
        (1, new_until.isoformat(), note, username)
    )
    conn.commit()
    conn.close()
    return jsonify({"ok":True, "paid_until": new_until.isoformat()})

@app.route("/admin/issue_user", methods=["POST"])
@require_admin
def admin_issue_user():
    """
    ê´€ë¦¬ì ì „ìš©: ì‹ ê·œ ë°œê¸‰ ë˜ëŠ” ê¸°ì¡´ ì—°ì¥/ì •ë³´ ì—…ë°ì´íŠ¸ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
    body: { username, password?, days=32, site_url?, role? }
    ì‹ ê·œ: password í•„ìˆ˜, ê¸°ì¡´: ìƒëµ ê°€ëŠ¥
    """
    body = request.get_json(force=True, silent=True) or {}
    username = normalize_username(body.get("username") or "")
    password = (body.get("password") or "").strip()
    days     = int(body.get("days") or 32)   # ê¸°ë³¸ 32ì¼
    site_url = (body.get("site_url") or "").strip()
    role     = (body.get("role") or "user").strip()
    note     = (body.get("note") or "").strip()

    try:
        validate_username(username)
    except ValueError as e:
        return jsonify({"error": str(e)}), 400
    if not username:
        return jsonify({"error":"username required"}), 400

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("SELECT username, paid_until FROM users WHERE username=?", (username,))
    row = cur.fetchone()

    base = datetime.utcnow()
    if row and row[1]:
        try:
            prev = datetime.fromisoformat(row[1])
            if prev > base:
                base = prev
        except Exception:
            pass
    new_until = base + timedelta(days=max(1, days))

    if row is None:
        if not password:
            return jsonify({"error":"password required for new user"}), 400
        cur.execute(
            "INSERT INTO users (username, password_hash, is_active, paid_until, role, notes, site_url, created_at) VALUES (?,?,?,?,?,?,?,?)",
            (username, bcrypt.hash(password), 1, new_until.isoformat(), role, note, (site_url or None), datetime.utcnow().isoformat())
        )
    else:
        # ê¸°ì¡´ ì‚¬ìš©ì: ì—°ì¥ + ì„ íƒ í•„ë“œ ê°±ì‹ 
        if password:
            cur.execute("UPDATE users SET password_hash=? WHERE username=?", (bcrypt.hash(password), username))
        cur.execute(
            "UPDATE users SET is_active=?, paid_until=?, role=?, notes=?, site_url=? WHERE username=?",
            (1, new_until.isoformat(), role, note, (site_url or None), username)
        )

    conn.commit(); conn.close()
    return jsonify({"ok": True, "username": username, "paid_until": new_until.isoformat(), "remaining_days": _remaining_days(new_until.isoformat())})

@app.route("/admin/set_active", methods=["POST"])
@require_admin
def admin_set_active():
    body = request.get_json(force=True, silent=True) or {}
    username = (body.get("username") or "").strip()
    is_active = 1 if body.get("is_active") else 0
    if not username:
        return jsonify({"error":"username required"}), 400
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("UPDATE users SET is_active=? WHERE username=?", (is_active, username))
    conn.commit(); conn.close()
    return jsonify({"ok": True})

@app.route("/admin/set_allow_concurrent", methods=["POST"])
@require_admin
def admin_set_allow_concurrent():
    body = request.get_json(force=True, silent=True) or {}
    username = (body.get("username") or "").strip()
    allow = 1 if body.get("allow") else 0
    if not username:
        return jsonify({"error": "username required"}), 400

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    if allow:
        # í—ˆìš©: ê·¸ëŒ€ë¡œ í”Œë˜ê·¸ë§Œ ì¼œê¸°
        cur.execute(
            "UPDATE users SET allow_concurrent=? WHERE username=?",
            (allow, username)
        )
    else:
        # í•´ì œ: ê¸°ì¡´ ì„¸ì…˜ ë¬´íš¨í™”ë¥¼ ìœ„í•´ ë²„ì „++ ë° ìƒˆë¡œìš´ jti ì„¸íŒ…
        import uuid
        new_jti = str(uuid.uuid4())
        cur.execute(
            "UPDATE users SET allow_concurrent=?, token_version=token_version+1, last_jti=? WHERE username=?",
            (allow, new_jti, username)
        )
    conn.commit(); conn.close()
    return jsonify({"ok": True, "username": username, "allow_concurrent": bool(allow)})

@app.route("/admin/reset_password", methods=["POST"])
@require_admin
def admin_reset_password():
    body = request.get_json(force=True, silent=True) or {}
    username = (body.get("username") or "").strip()
    new_pw = (body.get("new_password") or "").strip()
    if not username or not new_pw:
        return jsonify({"error":"username/new_password required"}), 400
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("UPDATE users SET password_hash=? WHERE username=?", (bcrypt.hash(new_pw), username))
    conn.commit(); conn.close()
    return jsonify({"ok": True})

# --- ê´€ë¦¬ì: ì‚¬ìš©ì ì‚­ì œ(ìê¸° ìì‹ /ìµœìƒìœ„ admin ë³´í˜¸, ì¡´ì¬ì—¬ë¶€ ì²´í¬) ---
@app.route("/admin/delete_user", methods=["POST"])
@require_admin
def admin_delete_user():
    body = request.get_json(silent=True) or {}
    username = (body.get("username") or "").strip()

    if not username:
        return jsonify({"error": "username required"}), 400
    # ìµœìƒìœ„ ê´€ë¦¬ì ë³´í˜¸ (í•„ìš” ì—†ë‹¤ë©´ ì£¼ì„ ì²˜ë¦¬)
    if username == "admin":
        return jsonify({"error": "cannot delete admin"}), 400

    # ë³¸ì¸ ê³„ì • ì‚­ì œ ë°©ì§€
    try:
        auth = request.headers.get("Authorization", "")
        token = auth.split(" ", 1)[1]
        sub = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALG]).get("sub")
        if sub == username:
            return jsonify({"error": "ë³¸ì¸ ê³„ì •ì€ ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 400
    except Exception:
        # í† í° íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìê¸°ì‚­ì œ ë°©ì§€ëŠ” ê±´ë„ˆë›°ë˜, admin ë³´í˜¸ëŠ” ìœ„ì—ì„œ ì´ë¯¸ ì ìš©ë¨
        pass

    # ì‹¤ì œ ì‚­ì œ
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("DELETE FROM users WHERE username = ?", (username,))
    conn.commit()
    deleted = cur.rowcount
    conn.close()

    if deleted == 0:
        return jsonify({"error": "ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì‚¬ìš©ì"}), 404

    return jsonify({"ok": True, "deleted": username})

@app.route("/admin/list_users", methods=["GET"])
@require_admin
def admin_list_users():
    q = (request.args.get("q") or "").strip()
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    if q:
        like = f"%{q}%"
        cur.execute(
            """
            SELECT username,is_active,paid_until,role,notes,site_url,created_at,allow_concurrent
            FROM users
            WHERE username LIKE ? OR IFNULL(notes,'') LIKE ? OR IFNULL(site_url,'') LIKE ?
            ORDER BY
              CASE WHEN paid_until IS NULL THEN 1 ELSE 0 END,   -- ë§Œë£Œì¼ ì—†ëŠ” ê³„ì •ì€ ë’¤ë¡œ
              datetime(paid_until) ASC,                         -- ë§Œë£Œ ì„ë°•ìˆœ
              username ASC
            """,
            (like, like, like)
        )
    else:
        cur.execute(
            """
            SELECT username,is_active,paid_until,role,notes,site_url,created_at,allow_concurrent
            FROM users
            ORDER BY
              CASE WHEN paid_until IS NULL THEN 1 ELSE 0 END,
              datetime(paid_until) ASC,
              username ASC
            """
        )
    rows = cur.fetchall()
    conn.close()

    out = []
    for u,a,pu,r,nt,site,created,ac in rows:
        out.append({
            "username": u,
            "is_active": bool(a),
            "paid_until": pu,
            "remaining_days": _remaining_days(pu),
            "role": r,
            "note": nt,
            "site_url": site,
            "created_at": created,
            "allow_concurrent": bool(ac),
        })
    return jsonify({"users": out})

# === [ADD] ë¶€ë¶„ì¼ì¹˜ ì‚¬ìš©ì ê²€ìƒ‰ (ê²Œì‹œê¸€ì´ ì—†ì–´ë„ ê²€ìƒ‰) ===
@app.get("/admin/board_user_search")
@require_admin
def admin_board_user_search():
    q = (request.args.get("q") or "").strip()
    if not q:
        return jsonify({"ok": True, "items": []})

    # LIKE ì•ˆì „ ì´ìŠ¤ì¼€ì´í”„
    esc = q.replace("\\", "\\\\").replace("%", "\\%").replace("_", "\\_")
    like = f"%{esc}%"

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("""
        WITH users_union AS (
          SELECT DISTINCT username FROM users
          UNION
          SELECT DISTINCT username FROM board_posts
        )
        SELECT uu.username,
               COALESCE((SELECT daily_limit
                         FROM board_limits bl
                         WHERE bl.username = uu.username), 2) AS daily_limit
        FROM users_union uu
        WHERE uu.username LIKE ? ESCAPE '\\'
        ORDER BY uu.username
        LIMIT 50
    """, (like,))
    rows = cur.fetchall()
    conn.close()

    items = [{"username": r[0], "blocked": (int(r[1] or 2) <= 0), "daily_limit": int(r[1] or 2)} for r in rows]
    return jsonify({"ok": True, "items": items})

# === board posts: ìµœëŒ€ 200ê°œ ìœ ì§€ ===
MAX_BOARD_POSTS = 200

def trim_board_to_max():
    """
    hidden=0(ë…¸ì¶œ ëŒ€ìƒ) ê²Œì‹œê¸€ì„ MAX_BOARD_POSTS ê°œê¹Œì§€ë§Œ ìœ ì§€.
    1) ë¹„ê³ ì •(pinned=0)ì—ì„œ ì˜¤ë˜ëœ ìˆœìœ¼ë¡œ ë¨¼ì € ì‚­ì œ
    2) ê·¸ë˜ë„ ì´ˆê³¼ë©´ ì „ì²´ì—ì„œ ì˜¤ë˜ëœ ìˆœìœ¼ë¡œ ì¶”ê°€ ì‚­ì œ
    """
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()

    # í˜„ì¬ ë…¸ì¶œ ê°œìˆ˜
    cur.execute("SELECT COUNT(*) FROM board_posts WHERE hidden=0")
    total = int(cur.fetchone()[0] or 0)
    excess = total - MAX_BOARD_POSTS
    if excess > 0:
        # 1) ë¹„ê³ ì • ë¨¼ì € ì •ë¦¬
        cur.execute("""
            SELECT id FROM board_posts
            WHERE hidden=0 AND pinned=0
            ORDER BY ts ASC
            LIMIT ?
        """, (excess,))
        ids = [r[0] for r in cur.fetchall()]
        if ids:
            cur.executemany("DELETE FROM board_posts WHERE id=?", [(i,) for i in ids])
            conn.commit()

        # ë‹¤ì‹œ ê³„ì‚°
        cur.execute("SELECT COUNT(*) FROM board_posts WHERE hidden=0")
        total = int(cur.fetchone()[0] or 0)
        excess = total - MAX_BOARD_POSTS

        # 2) ê·¸ë˜ë„ ë‚¨ìœ¼ë©´ ì „ì²´ì—ì„œ ì˜¤ë˜ëœ ìˆœ ì‚­ì œ
        if excess > 0:
            cur.execute("""
                SELECT id FROM board_posts
                WHERE hidden=0
                ORDER BY ts ASC
                LIMIT ?
            """, (excess,))
            ids2 = [r[0] for r in cur.fetchall()]
            if ids2:
                cur.executemany("DELETE FROM board_posts WHERE id=?", [(i,) for i in ids2])
                conn.commit()

    conn.close()

# ===== ê´€ë¦¬ì: í•œ ì¤„ í™ë³´ ê²Œì‹œíŒ =====
@app.get("/admin/board_list")
@require_admin
def admin_board_list():
    args = request.args
    username = (args.get("username") or "").strip()
    keyword  = (args.get("q") or "").strip()
    pinned_only = args.get("pinned_only") in ("1","true","True")
    include_hidden = args.get("include_hidden") in ("1","true","True")

    conn = sqlite3.connect(DB_PATH); conn.row_factory = sqlite3.Row
    cur = conn.cursor()

    where = []
    params = []

    if username:
        where.append("p.username = ?")
        params.append(username)
    if keyword:
        where.append("p.text LIKE ?")
        params.append(f"%{keyword}%")
    if not include_hidden:
        where.append("p.hidden = 0")
    if pinned_only:
        where.append("p.pinned = 1")

    where_sql = (" WHERE " + " AND ".join(where)) if where else ""
    sql = f"""
    SELECT p.id, p.username, p.text, p.pinned, p.ts, p.hidden,
           COALESCE(u.posting_blocked,0) AS user_blocked
      FROM board_posts p
      LEFT JOIN users u ON u.username = p.username
      {where_sql}
      ORDER BY p.pinned DESC, p.ts DESC
      LIMIT ?
    """
    cur.execute(sql, params + [MAX_BOARD_POSTS])
    rows = cur.fetchall()
    conn.close()

    def to_iso(ts):
        try:
            return datetime.utcfromtimestamp(int(ts)).isoformat()+"Z"
        except Exception:
            return None

    posts = []
    for r in rows:
        posts.append({
            "id": r["id"],
            "username": r["username"],
            "content": r["text"],
            "pinned": bool(r["pinned"]),
            "created_at": to_iso(r["ts"]),
            "user_blocked": bool(r["user_blocked"]),
            "hidden": int(r["hidden"] or 0),
        })
    return jsonify({"posts": posts})

@app.post("/admin/board_update")
@require_admin
def admin_board_update():
    body = request.get_json(force=True, silent=True) or {}
    pid = (body.get("id") or "").strip()
    content = (body.get("content") or "").strip()
    if not pid: return jsonify({"error":"id required"}), 400
    if not content: return jsonify({"error":"content required"}), 400

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("UPDATE board_posts SET text=? WHERE id=?", (content, pid))
    conn.commit(); conn.close()
    return jsonify({"ok": True})

@app.post("/admin/board_delete")
@require_admin
def admin_board_delete():
    body = request.get_json(force=True, silent=True) or {}
    pid = (body.get("id") or "").strip()
    if not pid: return jsonify({"error":"id required"}), 400

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    # ì†Œí”„íŠ¸ ì‚­ì œ: hidden=1
    cur.execute("UPDATE board_posts SET hidden=1 WHERE id=?", (pid,))
    conn.commit(); conn.close()
    return jsonify({"ok": True})

@app.post("/admin/board_pin")
@require_admin
def admin_board_pin():
    body = request.get_json(force=True, silent=True) or {}
    pid = (body.get("id") or "").strip()
    pinned = 1 if body.get("pinned") in (True, "1", "true", "True") else 0
    if not pid: return jsonify({"error":"id required"}), 400

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("UPDATE board_posts SET pinned=? WHERE id=?", (pinned, pid))
    conn.commit(); conn.close()
    return jsonify({"ok": True})

@app.post("/admin/board_block_user")
@require_admin
def admin_board_block_user():
    body = request.get_json(force=True, silent=True) or {}
    username = (body.get("username") or "").strip()
    blocked = 1 if body.get("blocked") in (True, "1", "true", "True") else 0
    if not username: return jsonify({"error":"username required"}), 400

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("UPDATE users SET posting_blocked=? WHERE username=?", (blocked, username))
    conn.commit(); conn.close()
    return jsonify({"ok": True})

@app.route("/board/create", methods=["POST"])
@require_user
def create_board_post():
    # í˜„ì¬ íŒŒì¼ì—ëŠ” g.userë¥¼ ì„¸íŒ…í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ í† í°ì—ì„œ ì¶”ì¶œ
    username = _username_from_req()
    if not username:
        return jsonify({"error": "Unauthorized"}), 401

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()

    # ì‘ì„±ì •ì§€ ì—¬ë¶€ í™•ì¸
    r = cur.execute(
        "SELECT IFNULL(posting_blocked,0) FROM users WHERE username=?",
        (username,)
    ).fetchone()
    if r and int(r[0]) == 1:
        conn.close()
        return jsonify({"error": "ì‘ì„±ì •ì§€ ì‚¬ìš©ìì…ë‹ˆë‹¤"}), 403

    payload = request.get_json(force=True, silent=True) or {}
    content = (payload.get("content") or "").strip()   # â† .trim() â†’ .strip()
    if not content:
        conn.close()
        return jsonify({"error": "ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤"}), 400

    # board_posts ìŠ¤í‚¤ë§ˆ: (id, username, text, pinned, hidden, ts)
    cur.execute(
        "INSERT INTO board_posts (id, username, text, pinned, hidden, ts) "
        "VALUES (?, ?, ?, 0, 0, strftime('%s','now'))",
        (str(uuid.uuid4()), username, content)
    )
    conn.commit()

    # â–¶ ìƒˆ ê¸€ ì¶”ê°€ ì§í›„ ì´ˆê³¼ë¶„ ì •ë¦¬
    try:
        trim_board_to_max()
    except Exception:
        pass

    conn.close()
    return jsonify({"ok": True})

# ë¡œì»¬ ë§ì¶¤ë²• ì´ˆê¸°í™”
_init_symspell()

@app.route("/verify", methods=["POST", "OPTIONS"])
@require_user
def verify():
    if request.method == "OPTIONS":
        return "", 200  # preflight OK

    try:
        data = request.get_json(force=True, silent=True) or {}
        text = (data.get("text") or "").strip()
        if not text:
            return jsonify({"error": "No text provided", "results": []}), 400

        # [ADD] non-admin size guard (í•­ëª©ë‹¹ 100KB)
        limit_resp = enforce_size_limit_or_400(text)
        if limit_resp:
            return limit_resp

        all_items = []

        # ì—¬ê¸°ì— GPT ë§ì¶¤ë²•/ë¬¸ë§¥ ê²€ì‚¬ í˜¸ì¶œ ë¡œì§ ì‚½ì…
        # (chunk_text_with_offsets + gpt_call í™œìš©)

        # === GPT ê¸°ë°˜ ë§ì¶¤ë²•/ë¬¸ë§¥ì˜¤ë¥˜ ê²€ì‚¬ ===
        chunks = chunk_text_with_offsets(text)  # (base_offset, chunk_text)
        for base, chunk in chunks:
            prompt = f"""
ë„ˆëŠ” í•œêµ­ì–´ ë¬¸ì¥ êµì • ì „ë¬¸ê°€ë‹¤.
ì•„ë˜ ê¸€ì—ì„œ **ë§ì¶¤ë²•/ë„ì–´ì“°ê¸°/ì–´ë²• ì˜¤ë¥˜(=type: "ë§ì¶¤ë²•")**,
**ë¶€ìì—°ìŠ¤ëŸ½ê±°ë‚˜ ëŠê¸´ ë¬¸ì¥(=type: "ë¬¸ë§¥ì˜¤ë¥˜")**ë§Œ ì°¾ì•„ë¼.
ì‹¬ì˜/ê´‘ê³ ë²•/ì˜ë£Œ ê·œì •(íš¨ê³¼Â·ì¬ë°œë¥ Â·ë³´ì¥ ë“±)ì€ **ì™„ì „íˆ ë¬´ì‹œ**í•œë‹¤.

ë°˜ë“œì‹œ JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ë©°, ê° í•­ëª©ì€ ì•„ë˜ ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¥¸ë‹¤:
{{
  "type": "ë§ì¶¤ë²•" | "ë¬¸ë§¥ì˜¤ë¥˜",
  "original": "ì›ë¬¸ì—ì„œ ê·¸ëŒ€ë¡œ ë³µì‚¬(ê³µë°±/ê¸°í˜¸ë„ ë™ì¼)",
  "reason": "ê°„ë‹¨ ì„¤ëª…",
  "severity": "low" | "medium" | "high",
  "suggestions": ["ëŒ€ì•ˆ1","ëŒ€ì•ˆ2"],   // ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´
  "start": ì •ìˆ˜,   // ì´ ì²­í¬ ë‚´ ì‹œì‘ ì˜¤í”„ì…‹
  "end": ì •ìˆ˜      // ì´ ì²­í¬ ë‚´ ë ì˜¤í”„ì…‹(í¬í•¨X)
}}

ê²€ì‚¬í•  ê¸€:
\"\"\"{chunk}\"\"\"
""".strip()

            resp = gpt_call(MODEL, [{"role": "user", "content": prompt}])
            raw = (resp.choices[0].message.content or "").strip()
            items = extract_json_array(raw)

            used_local = set()
            for it in (items or []):
                origin = (it.get("original") or "").strip()
                if not origin:
                    continue

                # 1) GPTê°€ ì¤€ start/end ì˜¤í”„ì…‹ì„ ìµœìš°ì„  ì‹ ë¢°
                s_rel = it.get("start")
                e_rel = it.get("end")
                locs = []
                if isinstance(s_rel, int) and isinstance(e_rel, int) and 0 <= s_rel < e_rel <= len(chunk):
                    locs = [s_rel]
                else:
                    # 2) ì‹¤íŒ¨ ì‹œ fallback: ë¶€ë¶„ ë¬¸ìì—´ íƒìƒ‰
                    locs = find_all(chunk, origin)

                for local_idx in locs:
                    gidx = base + local_idx
                    if gidx in used_local:
                        continue
                    used_local.add(gidx)

                    before, after = add_context(text, gidx, len(origin))
                    all_items.append({
                        "id": f"v_{len(all_items)}",
                        "type": it.get("type") or "ë§ì¶¤ë²•",
                        "original": origin,
                        "suggestions": (it.get("suggestions") or [])[:3],
                        "reason": it.get("reason") or "",
                        "severity": it.get("severity") or "low",
                        "startIndex": gidx,
                        "endIndex": gidx + len(origin),
                        "before": before,
                        "after": after
                    })
                    break  # ë™ì¼ í•­ëª© ì¤‘ë³µ ë°©ì§€


        # ë¬¸ì¥ ë‹¨ìœ„ íœ´ë¦¬ìŠ¤í‹± ì¶”ê°€ (ë£¨í”„ ë°–ì—ì„œ í•œ ë²ˆë§Œ)
        all_items.extend(find_fragments_by_sentence(text))
        all_items.extend(find_context_issues(text))

        # ì¶œì²˜ íƒœê·¸
        for it in all_items:
            it["source"] = "verify"

        return jsonify({"results": all_items, "aiSummary": None})
    except Exception as e:
        import traceback
        print("âŒ /verify ì˜¤ë¥˜:", e)
        traceback.print_exc()
        return jsonify({"error": str(e), "results": []}), 500

@app.post("/spell/local")
def spell_local():
    """
    ë¡œì»¬ ì² ì(ë§ì¶¤ë²•)ë§Œ ê²€ì‚¬. ë¬¸ë§¥/ì–´ë²•/ì‹¬ì˜ íŒë‹¨ ì—†ìŒ.
    body: { "text": str, "min_len": 3, "max_sug": 3 }
    """
    try:
        data = request.get_json(force=True, silent=True) or {}
        text = (data.get("text") or "")

        # [ADD] non-admin size guard (í•­ëª©ë‹¹ 100KB)
        limit_resp = enforce_size_limit_or_400(text)
        if limit_resp:
            return limit_resp

        if not text.strip() or _sym is None:
            return jsonify({"results": []})

        min_len = int(data.get("min_len") or 3)   # ì§§ì€ í† í° ì œì™¸(ì˜¤íƒ‘â†“)
        max_sug = int(data.get("max_sug") or 3)   # ì œì•ˆ ìƒìœ„ Nê°œ

        results = []
        for s, e, tok in _token_spans_ko(text):
            if len(tok) < min_len:
                continue
            # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸/ì‚¬ì „ì— ìˆìœ¼ë©´ í†µê³¼
            if tok in _whitelist or _sym.words.get(tok, 0) > 0:
                continue

            suggs = _sym.lookup(tok, Verbosity.TOP, max_edit_distance=2, include_unknown=False)
            if not suggs:
                continue

            suggs = _sym.lookup(tok, Verbosity.TOP, max_edit_distance=2, include_unknown=False)
            if not suggs:
                continue

            cand = [su.term for su in suggs[:max_sug]]
            results.append({
                "type": "ë§ì¶¤ë²•",
                "original": tok,
                "reason": "ì‚¬ì „ì— ì—†ëŠ” ë‹¨ì–´ë¡œ ì¶”ì •",
                "severity": "low",
                "suggestions": cand,
                "startIndex": s,
                "endIndex": e,
                "before": text[max(0, s-24):s],
                "after":  text[e:min(len(text), e+24)],
                "source": "local-spell"
            })

        results.sort(key=lambda x: (x["startIndex"], x["endIndex"]))
        return jsonify({"results": results})
    except Exception as e:
        import traceback; traceback.print_exc()
        return jsonify({"results": [], "error": str(e)}), 500

@app.post("/guide_keyword_count")
@require_user
def guide_keyword_count():
    """
    í‚¤ì›Œë“œ ë¹ˆë„/ìœ„ì¹˜ ê²€ì‚¬ (+ ìœ ì‚¬ë„ ëª¨ë“œ ì§€ì›)
    body: {
      "title": str,
      "text": str,
      "keywords": [str],
      "require": {"titleMin": int, "bodyMin": int, "totalMin": int},
      "fuzzy": bool,          # trueë©´ ìœ ì‚¬ë„ ëª¨ë“œ
      "threshold": float      # ê¸°ë³¸ 0.82 ê¶Œì¥ (0.80~0.85 ë²”ìœ„)
    }
    """
    data = request.get_json(force=True, silent=True) or {}
    title = (data.get("title") or "").strip()
    text  = (data.get("text")  or "").strip()
    fuzzy = bool(data.get("fuzzy"))
    threshold = float(data.get("threshold") or 0.5)

    # ë¹„ê´€ë¦¬ì 100KB ê°€ë“œ
    limit = enforce_size_limit_or_400(text)
    if limit:
        return limit

    keywords = data.get("keywords") or []
    require  = data.get("require") or {}
    title_need = int(require.get("titleMin") or 0)
    body_need  = int(require.get("bodyMin")  or 0)
    total_need = int(require.get("totalMin") or 0)

    # ---------- ìœ í‹¸: ìœ ì‚¬ë„/ì •í™•ì¼ì¹˜ ----------
    import re

    def _norm(s: str) -> str:
        # ê³µë°±/ë¬¸ì¥ë¶€í˜¸ ì œê±° + ì†Œë¬¸ì (ìœ ì‚¬ë„ ê³„ì‚°ìš©)
        return re.sub(r"[\s\W_]+", "", (s or "").lower())

    def _ngrams(s: str, n: int = 3):
        s = _norm(s)
        return {s[i:i+n] for i in range(max(0, len(s) - n + 1))} or ({s} if s else set())

    def _jaccard(a: set, b: set) -> float:
        if not a and not b: return 1.0
        if not a or not b:  return 0.0
        inter = len(a & b); union = len(a | b)
        return inter / (union or 1)

    def find_positions_exact(hay: str, kw: str):
        # ì •í™•ì¼ì¹˜(í˜„ì¬ ë™ì‘ê³¼ ë™ì¼)
        hits, pos = [], 0
        hay_l, kw_l = (hay or "").lower(), (kw or "").lower()
        if not kw_l: return hits
        while True:
            i = hay_l.find(kw_l, pos)
            if i == -1: break
            hits.append({"start": i, "end": i + len(kw)})
            pos = i + len(kw)
        return hits

    def find_positions_fuzzy(hay: str, kw: str, thr: float = 0.82, pad: int = 8):
        """
        3-gram Jaccard ìœ ì‚¬ë„.
        ê³µë°±/ì¡°ì‚¬/ì–´ë¯¸ ë³€í™”, 'ì•ˆì „í•˜ê²Œ ê·€ê°€í•˜ì‹œê¸¸' ê°™ì€ ë³€í˜•ì„ í¬ìš©.
        - ìœˆë„ìš°: len(kw)+pad
        """
        hits = []
        if not hay or not kw: return hits
        kw_ngr = _ngrams(kw)
        win = max(len(kw) + pad, 10)

        i, L = 0, len(hay)
        while i < L:
            seg = hay[i:i+win]
            score = _jaccard(_ngrams(seg), kw_ngr)
            if score >= thr:
                hits.append({"start": i, "end": i + len(seg), "score": round(score, 3)})
                # ê²¹ì¹¨ ê³¼ë‹¤ ë°©ì§€: í‚¤ì›Œë“œ ê¸¸ì´ì˜ ì ˆë°˜ë§Œí¼ ì í”„
                i += max(1, len(kw)//2)
            else:
                i += 1
        return hits
    # -----------------------------------------

    results = []
    for kw in keywords:
        # ë¬¸ì¥í˜•(ê³µë°± í¬í•¨Â·ë‘ ë‹¨ì–´ ì´ìƒ)ì€ ìë™ í¼ì§€ë¡œ, ì„ê³„ê°’ ì‚´ì§ ë‚®ì¶¤
        is_sentence = (" " in kw.strip())
        thr = (threshold if fuzzy else (0.75 if is_sentence else 0.82))

        tpos = find_positions_fuzzy(title, kw, thr) if (fuzzy or is_sentence) else find_positions_exact(title, kw)
        bpos = find_positions_fuzzy(text,  kw, thr) if (fuzzy or is_sentence) else find_positions_exact(text,  kw)
        tot  = len(tpos) + len(bpos)

        ok = True
        if title_need: ok = ok and (len(tpos) >= title_need)
        if body_need:  ok = ok and (len(bpos) >= body_need)
        if total_need: ok = ok and (tot >= total_need)

        results.append({
            "keyword": kw,
            "titleCount": len(tpos),
            "bodyCount":  len(bpos),
            "total":      tot,
            "titlePositions": tpos,
            "bodyPositions":  bpos,
            "ok": ok
        })

    all_ok = all(r["ok"] for r in results) if results else True
    return jsonify({"ok": True, "all_ok": all_ok, "results": results})

@app.post("/guide_verify_dedup")
@require_user
def guide_verify_dedup():
    """
    ë¬¸ì¥ í…œí”Œë¦¿ 'ì •ë°€ ëª¨ë“œ' (ìœ ì‚¬ë„ ì œê±° ë²„ì „)
    - í•˜ì´ë¸Œë¦¬ë“œ ìœ ì‚¬ë„ ëŒ€ì‹ 
      'í•µì‹¬ì–´ ì¡°í•©(2ê°œ ì´ìƒ)'ë§Œìœ¼ë¡œ í¬í•¨ ì—¬ë¶€ íŒë‹¨.
    - guide_verify_local ê³¼ ë™ì¼í•˜ê²Œ window ì•ˆì—ì„œ
      ì„œë¡œ ë‹¤ë¥¸ í•µì‹¬ì–´ê°€ coreNeed ê°œ ì´ìƒ ê°™ì´ ë“±ì¥í•˜ë©´ OKë¡œ ì²˜ë¦¬.
    body ì˜ˆì‹œ:
    {
      "text": str,
      "templates": [str],
      "threshold": float = 0.78,   # í•˜ìœ„ í˜¸í™˜ìš©(ì§€ê¸ˆì€ ì˜ë¯¸ ê±°ì˜ ì—†ìŒ)
      "coreNeed": int   = 2,       # í•µì‹¬ì–´ ìµœì†Œ ê°œìˆ˜ ( = min_core_hits )
      "window_size": int = 80      # ì˜µì…˜, ê¸°ë³¸ 80
    }
    """
    data = request.get_json(force=True, silent=True) or {}

    raw_text = data.get("text") or ""
    # ì •ê·œí™” ì•ˆ í•˜ê³  ì›ë¬¸ ê¸°ì¤€ìœ¼ë¡œë§Œ ê²€ì‚¬ (í•˜ì´ë¼ì´íŠ¸ ì¢Œí‘œ ìœ ì§€)
    text = raw_text

    # Editor.js ì—ì„œëŠ” required_guides ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë³´ë‚´ë¯€ë¡œ
    # templates / required_guides ë‘˜ ë‹¤ ì§€ì›
    raw_templates = data.get("templates") or data.get("required_guides") or []
    templates = [
           (t or "").strip()
           for t in raw_templates
           if isinstance(t, str) and (t or "").strip()
    ]

    # ê¸°ì¡´ í•„ë“œ ì¬í™œìš©
    thr = float(data.get("threshold") or 0.78)      # ì‘ë‹µì—ë§Œ ê·¸ëŒ€ë¡œ ëŒë ¤ì¤Œ
    core_need = int(data.get("coreNeed") or 2)      # = min_core_hits
    window_size = int(data.get("window_size") or 80)

    # ë¹„ê´€ë¦¬ì 100KB ê°€ë“œ
    limit = enforce_size_limit_or_400(text)
    if limit:
        return limit

    hits = []
    for tpl in templates:
        cores = core_terms(tpl)  # í…œí”Œë¦¿ì—ì„œ í•µì‹¬ì–´ ì¶”ì¶œ

        # í•µì‹¬ì–´ ì¡°í•© ê¸°ë°˜ í›„ë³´ êµ¬ê°„ ì°¾ê¸°
        candidates = _guide_keyword_windows(
            text,
            tpl,
            window_size=window_size,
            min_core_hits=core_need,
        )

        if candidates:
            best = candidates[0]  # hit_count ê°€ì¥ í° êµ¬ê°„
            core_hit = best["hit_count"]
            start = best["start"]
            end = best["end"]
            snippet = best["text"]
            ok = core_hit >= min(core_need, len(cores))

            # scoreëŠ” 'í•µì‹¬ì–´ ì¶©ì¡± ë¹„ìœ¨'ë¡œ ì¬ì •ì˜ (0~1)
            score = core_hit / max(1, len(cores))
        else:
            core_hit = 0
            start = -1
            end = -1
            snippet = ""
            ok = False
            score = 0.0

        hits.append({
            "template": tpl,
            "score": round(score, 3),      # ìœ ì‚¬ë„ ëŒ€ì‹  'í•µì‹¬ì–´ ë¹„ìœ¨'
            "coreNeed": core_need,
            "coreHit": core_hit,
            "start": start,
            "end": end,
            "snippet": snippet,
            "ok": bool(ok),
            "cores": cores,
        })

    all_ok = all(h["ok"] for h in hits) if hits else True

    # thresholdëŠ” í•˜ìœ„ í˜¸í™˜ ë•Œë¬¸ì— ê·¸ëŒ€ë¡œ ë°˜í™˜ë§Œ í•¨
    return jsonify({
        "ok": True,
        "all_ok": all_ok,
        "hits": hits,
        "threshold": thr,
        "mode": "keyword_combo"   # ë””ë²„ê·¸ìš© í”Œë˜ê·¸(í”„ë¡ íŠ¸ì—ì„œ ë³´ê³  êµ¬ë¶„ ê°€ëŠ¥)
    })


# ==== [ADD] Hybrid Similarity Utils (KO) ====
import re
from difflib import SequenceMatcher
try:
    # ìˆìœ¼ë©´ ìë™ ì‚¬ìš©(ì„±ëŠ¥/ì •í™•ë„â†‘)
    from rapidfuzz import fuzz as _rf_fuzz
except Exception:
    _rf_fuzz = None

_KO_STOP = {"ë°","ê·¸ë¦¬ê³ ","ë˜ëŠ”","ê·¸","ì´","ì €","ê²ƒ","ì—ì„œ","ìœ¼ë¡œ","í•˜ë‹¤","í•©ë‹ˆë‹¤","ë°”ëë‹ˆë‹¤","í•´ì£¼ì„¸ìš”","í•˜ì‹œê¸¸","í•˜ì„¸ìš”","ì…ë‹ˆë‹¤","í•˜ëŠ”","í•˜ê¸°","í•˜ì—¬","í•˜ë©°","ë˜","ë°"}
_rx_token = re.compile(r"[ê°€-í£A-Za-z0-9]+")

def _ko_sim_norm(s: str) -> str:
    """
    guide_verify_local / ë¡¤ë§ ìœˆë„ìš° ê¸°ë°˜ ë¬¸ì¥ ìœ ì‚¬ë„ì—ì„œ ì‚¬ìš©í•˜ëŠ”
    í•œêµ­ì–´ ë¬¸ì¥ ì •ê·œí™” í•¨ìˆ˜.
    í˜„ì¬ëŠ” ë„ëŒì´í‘œ/ìœ ì‚¬ë¬¸ì¥ íƒì§€ìš© _norm_for_dup ê³¼ ë™ì¼ ê·œì¹™ì„ ì‚¬ìš©í•œë‹¤.
    """
    return _norm_for_dup(s or "")


# ---- [NEW] KoSimCSE ì˜ë¯¸ ìœ ì‚¬ë„ (ì˜µì…˜) ----
try:
    from sentence_transformers import SentenceTransformer
    import numpy as np

    # í•œêµ­ì–´ìš© KoSimCSE ëª¨ë¸ (ë¡œì»¬ ë‹¤ìš´ë¡œë“œ í›„ ìºì‹œ ì‚¬ìš©)
    _KOSIM_MODEL = SentenceTransformer("BM-K/KoSimCSE-roberta-multitask")
    print("ğŸ” KoSimCSE model loaded for guide_verify_local")
except Exception as _e:
    _KOSIM_MODEL = None
    print("âš ï¸ KoSimCSE not available, fallback to 3-gram only:", _e)

def _semantic_sim_scores(candidates: list[str], template: str) -> list[float]:
    """
    KoSimCSE ê¸°ë°˜ ì˜ë¯¸ ìœ ì‚¬ë„ (0~1).
    - ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì „ë¶€ 0.0 ë°˜í™˜ â†’ ê¸°ì¡´ 3-gramë§Œ ì‚¬ìš©.
    - candidates: ì‹¤ì œ ì›ê³  ìª½ ë¬¸ì¥/ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
    - template: í•„ìˆ˜ê°€ì´ë“œ í…œí”Œë¦¿ ë¬¸ì¥
    """
    if not _KOSIM_MODEL or not candidates:
        return [0.0] * len(candidates)

    # normalize_embeddings=True â†’ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ê°€ ë‹¨ìˆœ ë‚´ì ìœ¼ë¡œ ê³„ì‚°ë¨
    embs = _KOSIM_MODEL.encode([template] + candidates, normalize_embeddings=True)
    q = embs[0]
    others = embs[1:]
    # dot product = cosine similarity
    sims = (others * q).sum(axis=1).tolist()

    # ì•ˆì „í•˜ê²Œ [0, 1]ë¡œ í´ë¨í”„
    out = []
    for s in sims:
        try:
            v = float(s)
        except Exception:
            v = 0.0
        if v < 0.0: v = 0.0
        if v > 1.0: v = 1.0
        out.append(v)
    return out
# ---- [KoSimCSE block ë] ----

def kr_norm(s: str) -> str:
    # ê°„ë‹¨ ì •ê·œí™”(ê³µë°± ì •ë¦¬ + ì „ê°/íŠ¹ìˆ˜ ì œê±° ìœ ì‚¬)
    s = (s or "").strip()
    s = re.sub(r"\s+", " ", s)
    return s

def spacing_agnostic_regex(kw: str) -> str:
    # 'ì•ˆì „ ê·€ê°€' -> 'ì•ˆì „[\s\W_]*ê·€ê°€'
    toks = re.split(r"\s+", kw.strip())
    return r"[\s\W_]*".join(map(re.escape, toks))

def tokenize(s: str):
    return [t for t in _rx_token.findall(s)]

def _strip_ko_josa_ending(tok: str) -> str:
    """í•œêµ­ì–´ í† í°ì˜ ëì— ë¶™ì€ ì¡°ì‚¬/ì–´ë¯¸ë¥¼ ë‹¨ìˆœ ê·œì¹™ìœ¼ë¡œ ì œê±°í•œë‹¤.
    - ëŒ€ë¦¬ìš´ì „ì„ / ëŒ€ë¦¬ìš´ì „ì€ / ëŒ€ë¦¬ìš´ì „ì´ -> ëŒ€ë¦¬ìš´ì „
    - ìŒì£¼ê°€ / ìŒì£¼ë¥¼ -> ìŒì£¼
    ë„ˆë¬´ ê³¼í•˜ê²Œ ìë¥´ì§€ ì•Šë„ë¡, ìµœì†Œ 2ê¸€ì ì´ìƒë§Œ ë‚¨ê¸´ë‹¤.
    """
    if not tok:
        return tok
    # í•œê¸€ì´ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë‘”ë‹¤ (ì˜ë¬¸/ìˆ«ì ë“±)
    if not re.search(r"[ê°€-í£]", tok):
        return tok

    base = tok

    # 1) ì—¬ëŸ¬ ê¸€ìë¡œ ëœ ì–´ë¯¸/ì„œìˆ í˜•ì„ ë¨¼ì € ì œê±°
    multi_suffixes = [
        "ì…ë‹ˆë‹¤",
        "í•©ë‹ˆë‹¤",
        "ì˜€ìŠµë‹ˆë‹¤",
        "í–ˆìŠµë‹ˆë‹¤",
        "ë˜ì—ˆìŠµë‹ˆë‹¤",
        "ëìŠµë‹ˆë‹¤",
        "í•´ìš”",
        "ë¼ìš”",
        "ë˜ì–´ìš”",
        "í–ˆì–´ìš”",
        "ì˜€ì–´ìš”",
    ]
    for suf in multi_suffixes:
        if base.endswith(suf) and len(base) > len(suf) + 1:
            base = base[: -len(suf)]
            break

    # 2) í•œ ê¸€ì ì§œë¦¬ ì¡°ì‚¬ë“¤(ì€,ëŠ”,ì´,ê°€,ì„,ë¥¼,ë„,ë§Œ,ê¹Œ,ì™€,ê³¼,ì—,ë¡œ ë“±)ì„
    #    ë„ˆë¬´ ì¤„ì´ì§€ ì•ŠëŠ” ì„ ì—ì„œ ëì—ì„œë¶€í„° ì˜ë¼ë‚¸ë‹¤.
    while len(base) > 1 and base[-1] in "ì€ëŠ”ì´ê°€ì„ë¥¼ë„ë§Œë¿ì¡°ê¹Œì™€ê³¼ì—ë¡œ":
        base = base[:-1]

    return base


def core_terms(s: str, max_terms: int = 5):
    # 1ì°¨ í† í°í™” + ë¶ˆìš©ì–´ ì œê±°
    raw = [t for t in tokenize(s) if t not in _KO_STOP]
    normalized = []

    for t in raw:
        # ì¡°ì‚¬/ì–´ë¯¸ ì œê±°
        base = _strip_ko_josa_ending(t)
        # ë„ˆë¬´ ì§§ì€ ê±´ ë²„ë¦¼ (í•œ ê¸€ì ì¡°ì‚¬ë§Œ ë‚¨ì€ ê²½ìš° ë“±)
        if len(base) < 2:
            continue
        normalized.append(base)

    # í˜¹ì‹œ ëª¨ë‘ ì˜ë ¤ë‚˜ê°”ë‹¤ë©´, ì›ë³¸ í† í°ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    toks = normalized or raw

    # ê¸¸ì´/í¬ì†Œì„± ê¸°ì¤€ ìƒìœ„ ì¶”ì¶œ
    toks.sort(key=lambda x: (-len(x), x))
    return toks[:max_terms] or toks

def token_jaccard(a: str, b: str) -> float:
    A = set(tokenize(a)); B = set(tokenize(b))
    if not A and not B: return 1.0
    if not A or not B:  return 0.0
    return len(A & B) / len(A | B)

def char_ratio(a: str, b: str) -> float:
    if _rf_fuzz is not None:
        # ê³µë°±/ìˆœì„œ ë³€í™”ì— ê°•í•¨
        return _rf_fuzz.token_set_ratio(a, b) / 100.0
    # fallback: difflib
    return SequenceMatcher(None, a, b).ratio()

def hybrid_score(a: str, b: str) -> float:
    a1, b1 = kr_norm(a), kr_norm(b)
    tj = token_jaccard(a1, b1)
    cr = char_ratio(a1, b1)
    # ë‹¨ì–´ì™€ ë¬¸ì ìœ ì‚¬ë„ì˜ ê°€ì¤‘ í‰ê· (ì‹¤ì „ ê²€ì¦ì¹˜)
    return 0.55 * cr + 0.45 * tj

def contains_core_terms(text: str, terms, need: int) -> int:
    hits = 0
    for t in terms:
        if re.search(spacing_agnostic_regex(t), text, flags=re.IGNORECASE):
            hits += 1
    return hits if hits >= need else hits

def slide_best(text: str, template: str, pad: int = 16):
    """
    í…œí”Œë¦¿ ê¸¸ì´Â±pad ìœˆë„ìš°ë¡œ ìŠ¬ë¼ì´ë“œí•˜ë©° ìµœê³  êµ¬ê°„ íƒìƒ‰
    """
    text = text or ""
    template = template or ""
    L = len(text)
    win = max(len(template) + pad, 20)
    best = {"score": 0.0, "start": -1, "end": -1, "snippet": ""}
    i = 0
    step = max(1, len(template)//3 or 1)
    while i < L:
        seg = text[i:i+win]
        s = hybrid_score(seg, template)
        if s > best["score"]:
            best = {"score": s, "start": i, "end": i+len(seg), "snippet": seg[:180]}
        i += step
    return best
# ==== [/ADD] ====


@app.post("/guide_verify_local")
@require_user
def guide_verify_local():
    """
    í•„ìˆ˜ê°€ì´ë“œ ê²€ì‚¬ (ìœ ì‚¬ë„ ëª¨ë¸ ì œê±°, í•µì‹¬ì–´ ì¡°í•© ê¸°ë°˜)
    - í…œí”Œë¦¿ ë¬¸ì¥ì—ì„œ í•µì‹¬ ë‹¨ì–´ë¥¼ ì¶”ì¶œí•˜ê³ 
    - ì›ë¬¸ì—ì„œ window_size ê¸€ì ì•ˆì— ì„œë¡œ ë‹¤ë¥¸ í•µì‹¬ ë‹¨ì–´ê°€
      min_core_hitsê°œ ì´ìƒ ê°™ì´ ë“±ì¥í•˜ëŠ” êµ¬ê°„ì„ ì°¾ëŠ”ë‹¤.

    body ì˜ˆì‹œ:
    {
      "text": "ì›ê³  ì „ì²´ í…ìŠ¤íŠ¸",
      "templates": ["í•„ìˆ˜ê°€ì´ë“œ ë¬¸ì¥1", "í•„ìˆ˜ê°€ì´ë“œ ë¬¸ì¥2", ...],
      "window_size": 80,      # ì˜µì…˜, ê¸°ë³¸ 80
      "min_core_hits": 2      # ì˜µì…˜, ê¸°ë³¸ 2
    }
    """
    try:
        data = request.get_json(force=True, silent=True) or {}
        text = (data.get("text") or "")
        limit = enforce_size_limit_or_400(text)
        if limit:
            return limit

        # 1) ê¸°ë³¸: templates í•„ë“œ ì‚¬ìš©
        raw_templates = data.get("templates")

        # 2) Editor.js runRequiredCheck ì—ì„œ ì“°ëŠ” required_guidesë„ ì§€ì›
        if not raw_templates:
            raw_templates = data.get("required_guides") or []

        templates = []
        for t in raw_templates:
            # í˜¹ì‹œ dict í˜•íƒœë¡œ ì˜¬ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ë°©ì–´ ì½”ë“œ
            if isinstance(t, dict):
                t = t.get("text") or ""
            if not isinstance(t, str):
                t = str(t)
            t = (t or "").strip()
            if t:
                templates.append(t)


        # ê¸°ë³¸ê°’: 80ì ìœˆë„ìš°, í•µì‹¬ì–´ 2ê°œ ì´ìƒ
        window_size = int(data.get("window_size") or 80)
        min_core_hits = int(data.get("min_core_hits") or 2)

        results = []

        for tpl in templates:
            # í•µì‹¬ì–´ ì¡°í•© ê¸°ë°˜ í›„ë³´ êµ¬ê°„ ì°¾ê¸°
            candidates = _guide_keyword_windows(
                text,
                tpl,
                window_size=window_size,
                min_core_hits=min_core_hits,
            )

            if candidates:
                # ê°€ì¥ ì¢‹ì€ í›„ë³´ í•˜ë‚˜ë¥¼ ëŒ€í‘œë¡œ ì‚¼ìŒ
                best = candidates[0]
                present = True
                msg = f"í•µì‹¬ ë‹¨ì–´ê°€ {best['core_hits']}ê°œ ì´ìƒ ê°™ì€ êµ¬ê°„ì— í•¨ê»˜ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            else:
                best = None
                present = False
                msg = "ì›ê³ ì—ì„œ í•´ë‹¹ í•„ìˆ˜ê°€ì´ë“œì˜ í•µì‹¬ ë‹¨ì–´ê°€ í•¨ê»˜ í¬í•¨ëœ êµ¬ê°„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

            # Editor.js ê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ matches ë°°ì—´ êµ¬ì„±
            matches = []
            for c in candidates:
                matches.append({
                    "start": c["start"],
                    "end": c["end"],
                    "score": c["score"],
                    "sentence": c["sentence"],
                    "core_hits": c["core_hits"],
                    "core_terms": c["core_terms"],
                    "kind": "keyword_window",
                })

            results.append({
                "template": tpl,
                "best_score": (best["score"] if best else None),
                "present": present,
                "message": msg,
                "matches": matches,
            })

        overall_present = any(r["present"] for r in results)

        try:
            log_usage(_username_from_req(), "guide_local_keywords", len(templates))
        except Exception:
            pass

        # Editor.js ì˜ runRequiredCheck ì—ì„œ ì‚¬ìš©í•˜ëŠ” í‰íƒ„í™”ëœ í›„ë³´ ë¦¬ìŠ¤íŠ¸
        paragraph_candidates = []
        for idx, r in enumerate(results, start=1):
            tpl = r.get("template", "")
            for m in r.get("matches") or []:
                paragraph_candidates.append({
                    "template": tpl,
                    "template_index": idx,          # 1ë¶€í„° ì‹œì‘ (í•„ìˆ˜ê°€ì´ë“œ ì¤„ ë²ˆí˜¸)
                    "start": m.get("start", 0),
                    "end": m.get("end", 0),
                    "sentence": m.get("sentence", ""),
                    "score": m.get("score", 0.0),
                    "core_hits": m.get("core_hits", 0),
                    "core_terms": m.get("core_terms", []),
                    "best_score": r.get("best_score"),
                    "kind": m.get("kind", "keyword_window"),
                })

        return jsonify({
            "ok": True,
            "overall_present": overall_present,
            "results": results,
            "paragraph_candidates": paragraph_candidates,
        })

    except Exception as e:
        log_error(_username_from_req(), "/guide_verify_local", 500, str(e))
        return jsonify(
            {"ok": False, "error": "SERVER_ERROR", "message": str(e)}
        ), 500


# ===== ë¬¸ì¥ ë‹¨ìœ„ ë¬¸ë§¥ì˜¤ë¥˜ ìœ í‹¸ =====

SENT_SPLIT_RE = re.compile(r'(?<=[\.!?])\s+')
END_TOKEN_RE = re.compile(r'(ë‹¤|ìš”|ë‹ˆë‹¤|í•©ë‹ˆë‹¤|í–ˆë‹¤|ì˜€ë‹¤|ë©ë‹ˆë‹¤|ë¼ìš”|\.|!|\?)\s*$')

LEADING_CONNECTIVES = (
    "í•˜ì§€ë§Œ", "ê·¸ëŸ¬ë‚˜", "ë°˜ë©´ì—", "ê·¸ëŸ°ë°", "ë‹¤ë§Œ",
    "ë˜í•œ", "ê·¸ë¦¬ê³ ", "ê²Œë‹¤ê°€", "íŠ¹íˆ", "ë˜", "í•œí¸"
)

def split_sentences_with_pos(text: str):
    spans = []
    parts = SENT_SPLIT_RE.split(text)
    cur = 0
    for p in parts:
        if not p.strip():
            cur += len(p)
            continue
        start = text.find(p, cur)
        if start == -1:
            start = text.find(p)
        end = start + len(p)
        spans.append((p, start, end))
        cur = end
    return spans

def find_fragments_by_sentence(text: str):
    items = []
    spans = split_sentences_with_pos(text)
    for s, start, end in spans:
        sent = s.strip()
        if len(sent) < 15:
            continue
        if sent.startswith(("â€œ", "\"", "â€˜", "'")) and sent.endswith(("â€", "\"", "â€™", "'")):
            continue
        if not END_TOKEN_RE.search(sent):
            items.append({
                "id": f"frag_{start}",
                "type": "ë¬¸ë§¥ì˜¤ë¥˜",
                "original": sent,
                "reason": "ë¶ˆì™„ì „ ë¬¸ì¥(ì¢…ê²°ì–´ë¯¸/ë§ˆì¹¨í‘œ ëˆ„ë½) ê°€ëŠ¥",
                "severity": "medium",
                "suggestions": ["ë¬¸ì¥ì„ ë§ˆë¬´ë¦¬í•˜ëŠ” ì¢…ê²°ì–´ë¯¸/ë§ˆì¹¨í‘œ ì¶”ê°€ ê²€í† "],
                "startIndex": start,
                "endIndex": end,
                "before": "", "after": ""
            })
    return items

def find_context_issues(text: str):
    items = []
    spans = split_sentences_with_pos(text)
    for i, (s, start, end) in enumerate(spans):
        sent = s.strip()
        if len(sent) < 10:
            continue
        for conn in LEADING_CONNECTIVES:
            if sent.startswith(conn):
                if i == 0:
                    items.append({
                        "id": f"ctx_first_{start}",
                        "type": "ë¬¸ë§¥ì˜¤ë¥˜",
                        "original": sent[:min(40, len(sent))],
                        "reason": f"ì²« ë¬¸ì¥ì—ì„œ '{conn}' ì‚¬ìš©",
                        "severity": "low",
                        "suggestions": ["ì²« ë¬¸ì¥ì€ ì „í™˜ ì—†ì´ ì£¼ì œë¥¼ ì œì‹œí•˜ëŠ” ê²ƒì´ ìì—°ìŠ¤ëŸ¬ì›€"],
                        "startIndex": start, "endIndex": end,
                        "before": "", "after": ""
                    })
                else:
                    prev = spans[i-1][0].strip()
                    if len(prev) < 10 or not END_TOKEN_RE.search(prev):
                        items.append({
                            "id": f"ctx_link_{start}",
                            "type": "ë¬¸ë§¥ì˜¤ë¥˜",
                            "original": sent[:min(40, len(sent))],
                            "reason": f"ì• ë¬¸ì¥ì´ ì•½í•œ ìƒíƒœì—ì„œ '{conn}' ì‹œì‘",
                            "severity": "low",
                            "suggestions": ["ì• ë¬¸ì¥ì„ ë³´ê°•í•˜ê±°ë‚˜ ì—°ê²°ì–´ë¥¼ ìƒëµ/ë³€ê²½"],
                            "startIndex": start, "endIndex": end,
                            "before": "", "after": ""
                        })
                break
    return items


# ============== (NEW) ë„ëŒì´í‘œ/ìœ ì‚¬ ë¼ìš°íŠ¸ ==============
@app.route("/dedup_intra", methods=["POST"])
@require_user
def dedup_intra():
    """
    ë³¸ë¬¸ í•œ ê±´ ë‚´ ë„ëŒì´í‘œ(ì •í™•íˆ ê°™ì€ ë¬¸ì¥) + ìœ ì‚¬ ë¬¸ì¥(3-gram ìì¹´ë“œ) íƒì§€
    body: { "text": str, "min_len": 6, "sim_threshold": 0.85 }
    """
    try:
        data = request.get_json(force=True, silent=True) or {}
        text = (data.get("text") or "")
        if not text.strip():
            return jsonify({"error": "No text provided"}), 400

        # [ADD] non-admin size guard (í•­ëª©ë‹¹ 100KB)
        limit_resp = enforce_size_limit_or_400(text)
        if limit_resp:
            return limit_resp

        min_len = int(data.get("min_len", 6))
        sim_th  = float(data.get("sim_threshold", 0.85))
        exact, sims = _dedup_intra(text, min_len=min_len, sim_threshold=sim_th)
        return jsonify({"exact_groups": exact, "similar_pairs": sims})
    except Exception as e:
        import traceback
        print("âœ˜ /dedup_intra ì˜¤ë¥˜:", e)
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@app.route("/dedup_inter", methods=["POST"])
@require_user
def dedup_inter():
    """
    ì—¬ëŸ¬ íŒŒì¼ ê°„ ë„ëŒì´í‘œ/ìœ ì‚¬ ë¬¸ì¥ íƒì§€
    body: { "files": [{"name": str, "text": str}, ...], "min_len": 6, "sim_threshold": 0.85 }
    """
    try:
        data = request.get_json(force=True, silent=True) or {}
        files = data.get("files") or []
        if not files:
            return jsonify({"error": "No files provided"}), 400

        # [ADD] non-admin size guard (ê° í•­ëª© text 100KB)
        limit_resp = enforce_size_limit_or_400(files)
        if limit_resp:
            return limit_resp

        min_len = int(data.get("min_len", 6))
        sim_th  = float(data.get("sim_threshold", 0.85))

        exact, sims = _dedup_inter(files, min_len=min_len, sim_threshold=sim_th)

        # (ì„ íƒ) ì‚¬ìš©ëŸ‰ ë¡œê¹…: í—¬í¼ê°€ ìˆìœ¼ë©´ ìœ ì§€, ì—†ìœ¼ë©´ ë¬´ì‹œ
        try:
            log_usage(_username_from_req(), "dedup_inter", len(files))
        except Exception:
            pass

        return jsonify({"exact_groups": exact, "similar_pairs": sims})

    except Exception as e:
        import traceback
        print("âœ˜ /dedup_inter ì˜¤ë¥˜:", e)
        traceback.print_exc()
        # (ì„ íƒ) ì—ëŸ¬ ë¡œê¹…
        try:
            log_error(_username_from_req(), "/dedup_inter", 500, str(e))
        except Exception:
            pass
        return jsonify({"error": str(e)}), 500


@app.route("/policy_verify", methods=["POST", "OPTIONS"])
@require_user
def policy_verify():
    if request.method == "OPTIONS":
        return "", 200

    try:
        data = request.get_json(force=True, silent=True) or {}
        text = (data.get("text") or "").strip()
        if not text:
            return jsonify({"error": "No text provided"}), 400

        # [ADD] non-admin size guard (í•­ëª©ë‹¹ 100KB)
        limit_resp = enforce_size_limit_or_400(text)
        if limit_resp:
            return limit_resp

        # ì‹¬ì˜ ê·œì¹™ ê²€ì‚¬
        items = rule_scan(text)
        items = attach_reasons(items)

        # ì¶œì²˜ íƒœê·¸
        for it in items:
            it["source"] = "policy"

        # (ì„ íƒ) ì‚¬ìš©ëŸ‰ ë¡œê¹…
        try:
            log_usage(_username_from_req(), "policy", 1)
        except Exception:
            pass

        return jsonify({"results": items})

    except Exception as e:
        import traceback
        print("âœ˜ /policy_verify ì˜¤ë¥˜:", e)
        traceback.print_exc()
        # (ì„ íƒ) ì—ëŸ¬ ë¡œê¹…
        try:
            log_error(_username_from_req(), "/policy_verify", 500, str(e))
        except Exception:
            pass
        return jsonify({"error": str(e), "results": []}), 500


@app.after_request
def _after(resp):
    try:
        if resp.status_code >= 400:
            log_error(_username_from_req(), request.path, resp.status_code, getattr(resp, "data", b"")[:120])
    except Exception:
        pass
    return resp

from werkzeug.exceptions import HTTPException

@app.errorhandler(HTTPException)
def _http_error(e):
    # 404/401/405 ê°™ì€ ì •ìƒ HTTP ì˜¤ë¥˜ëŠ” ì›ë˜ ìƒíƒœì½”ë“œë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜
    return e

@app.errorhandler(Exception)
def _on_error(e):
    # 404/401/405 ê°™ì€ HTTP ì˜ˆì™¸ëŠ” ì›ë˜ ìƒíƒœì½”ë“œ ê·¸ëŒ€ë¡œ ë°˜í™˜í•´ì•¼ í•¨
    if isinstance(e, HTTPException):
        return e  # â˜… ë°˜ë“œì‹œ return e !!!
    # ê·¸ ì™¸ ì§„ì§œ ì—ëŸ¬ë§Œ 500 ì²˜ë¦¬
    return jsonify({"error": "internal"}), 500



# === 4) ê´€ë¦¬ì: ê¸°ê°„ ì¡°ì • API ===
# ìœ„ì¹˜: (â‘  /admin/approve ì•„ë˜) ë˜ëŠ” (â‘¡ if __name__ == "__main__": ë°”ë¡œ ìœ„)

@app.route("/admin/adjust_days", methods=["POST"])
@require_admin
def admin_adjust_days():
    """
    body: { "username": "trial@glefit", "days": -1 }  # ìŒìˆ˜/ì–‘ìˆ˜ ëª¨ë‘ í—ˆìš©
    """
    body = request.get_json(force=True, silent=True) or {}
    username   = (body.get("username") or "").strip()
    delta_days = int(body.get("days") or 0)
    if not username or delta_days == 0:
        return jsonify({"error": "username/days required"}), 400

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("SELECT paid_until FROM users WHERE username=?", (username,))
    row = cur.fetchone()
    if not row:
        conn.close(); return jsonify({"error":"user not found"}), 404

    now = datetime.utcnow()
    try:
        base = datetime.fromisoformat(row[0]) if row[0] else now
    except Exception:
        base = now

    new_until = base + timedelta(days=delta_days)
    cur.execute(
        "UPDATE users SET paid_until=?, is_active=? WHERE username=?",
        (new_until.isoformat(), 1 if new_until > now else 0, username)
    )
    conn.commit(); conn.close()
    return jsonify({"ok": True, "paid_until": new_until.isoformat()})

@app.get("/admin/usage_summary")
@require_admin
def admin_usage_summary():
    """
    ë°˜í™˜:
    {
      "usage":[ {username, verify, policy, dedup_inter, dedup_intra, files}, ... ],
      "errors":[ {username, errors, last}, ... ],
      "agreements":[ {username, agreed_at}, ... ]
    }
    """
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()

    # usage_logs ì§‘ê³„
    cur.execute("""
      SELECT username,
             SUM(CASE WHEN action='verify' THEN 1 ELSE 0 END) AS verify,
             SUM(CASE WHEN action='policy' THEN 1 ELSE 0 END) AS policy,
             SUM(CASE WHEN action='dedup_inter' THEN 1 ELSE 0 END) AS dedup_inter,
             SUM(CASE WHEN action='dedup_intra' THEN 1 ELSE 0 END) AS dedup_intra,
             SUM(files_count) AS files
      FROM usage_logs
      GROUP BY username
      ORDER BY username
    """)
    usage = []
    for row in cur.fetchall():
        usage.append({
            "username": row[0] or "",
            "verify": row[1] or 0,
            "policy": row[2] or 0,
            "dedup_inter": row[3] or 0,
            "dedup_intra": row[4] or 0,
            "files": row[5] or 0
        })

    # error_logs ì§‘ê³„(ìœ ì €ë³„ ê°œìˆ˜ + ë§ˆì§€ë§‰ ì‹œê°)
    cur.execute("""
      SELECT username, COUNT(*),
             MAX(created_at)
      FROM error_logs
      GROUP BY username
    """)
    errors = []
    for row in cur.fetchall():
        errors.append({
            "username": row[0] or "",
            "errors": row[1] or 0,
            "last": row[2] or ""
        })

    # ë™ì˜ ëª©ë¡
    cur.execute("SELECT username, agreed_at FROM agreements ORDER BY agreed_at DESC")
    agreements = [{"username": r[0], "agreed_at": r[1]} for r in cur.fetchall()]

    conn.close()
    return jsonify({"usage": usage, "errors": errors, "agreements": agreements})

@app.get("/admin/traffic_summary")
@require_admin
def admin_traffic_summary():
    """
    ì¿¼ë¦¬:
      granularity=day|week|month (ê¸°ë³¸: day)
      start=YYYY-MM-DD ISO(UTC)  ì˜ˆ: 2025-10-01
      end=YYYY-MM-DD   (í¬í•¨)
    ë°˜í™˜:
      { "series":[ { "bucket":"2025-10-21", "visits":n, "logins":m, "active_users":k }, ... ],
        "totals": { "visits":X, "logins":Y, "unique_users":Z } }
    """
    gran = (request.args.get("granularity") or "day").lower()
    start = (request.args.get("start") or "").strip()
    end   = (request.args.get("end") or "").strip()

    # ê¸°ë³¸ ê¸°ê°„: ìµœê·¼ 30ì¼
    today = datetime.utcnow().date()
    if not start:
        start_date = today - timedelta(days=29)
    else:
        start_date = datetime.fromisoformat(start).date()
    if not end:
        end_date = today
    else:
        end_date = datetime.fromisoformat(end).date()

    # SQLite strftime íŒ¨í„´
    if gran == "month":
        fmt = "%Y-%m"
    elif gran == "week":
        # ISO week-year-weeknum
        fmt = "%Y-W%W"
    else:
        fmt = "%Y-%m-%d"

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()

    # visits: visit_logs ê¸°ì¤€
    cur.execute(f"""
      SELECT strftime('{fmt}', created_at), COUNT(*)
      FROM visit_logs
      WHERE date(created_at) BETWEEN date(?) AND date(?)
      GROUP BY 1
      ORDER BY 1
    """, (start_date.isoformat(), end_date.isoformat()))
    visit_rows = dict(cur.fetchall() or [])

    # logins: usage_logs(action='login')
    cur.execute(f"""
      SELECT strftime('{fmt}', created_at), COUNT(*)
      FROM usage_logs
      WHERE action='login'
        AND date(created_at) BETWEEN date(?) AND date(?)
      GROUP BY 1
      ORDER BY 1
    """, (start_date.isoformat(), end_date.isoformat()))
    login_rows = dict(cur.fetchall() or [])

    # active users(í•´ë‹¹ ê¸°ê°„ ë‚´ ë¡œê·¸ì¸í–ˆë˜ ìœ ë‹ˆí¬)
    cur.execute("""
      SELECT username
      FROM usage_logs
      WHERE action='login'
        AND date(created_at) BETWEEN date(?) AND date(?)
    """, (start_date.isoformat(), end_date.isoformat()))
    uniq = set([r[0] for r in (cur.fetchall() or []) if r and r[0]])

    # ë²„í‚· ìƒì„±
    series = []
    cur_d = start_date
    while cur_d <= end_date:
        if fmt == "%Y-%m":
            bucket = cur_d.strftime("%Y-%m")
            # ì›” ë§ê¹Œì§€ ì í”„
            next_d = (cur_d.replace(day=1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)
            cur_d = (cur_d.replace(day=1) + timedelta(days=32)).replace(day=1)
        elif fmt == "%Y-W%W":
            bucket = cur_d.strftime("%Y-W%W")
            next_d = cur_d + timedelta(days=6)
            cur_d = cur_d + timedelta(days=7)
        else:
            bucket = cur_d.strftime("%Y-%m-%d")
            next_d = cur_d
            cur_d = cur_d + timedelta(days=1)

        series.append({
            "bucket": bucket,
            "visits": int(visit_rows.get(bucket, 0) or 0),
            "logins": int(login_rows.get(bucket, 0) or 0),
            "active_users": len(uniq) if fmt != "%Y-%m-%d" else None  # ì¼ë³„ active_usersëŠ” ë³´í†µ ë³„ë„ ì‚°ì¶œ
        })

    totals = {
        "visits": sum(v["visits"] for v in series),
        "logins": sum(v["logins"] for v in series),
        "unique_users": len(uniq),
    }
    conn.close()
    return jsonify({"series": series, "totals": totals})


@app.route("/admin/set_days_from_now", methods=["POST"])
@require_admin
def admin_set_days_from_now():
    """
    body: { "username": "trial@glefit", "days": 7 }  # 0 í—ˆìš©(ì¦‰ì‹œ ë§Œë£Œ)
    """
    body = request.get_json(force=True, silent=True) or {}
    username = (body.get("username") or "").strip()
    days     = int(body.get("days") or 0)
    if not username:
        return jsonify({"error":"username required"}), 400

    now = datetime.utcnow()
    new_until = now + timedelta(days=max(0, days))

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute(
        "UPDATE users SET paid_until=?, is_active=? WHERE username=?",
        (new_until.isoformat(), 1 if days > 0 else 0, username)
    )
    conn.commit(); conn.close()
    return jsonify({"ok": True, "paid_until": new_until.isoformat()})

# === [ADD] BOARD API (list/add/edit/delete/pin/admin_delete_all) ===
from flask import Flask

def _default_daily_limit(username):
    # board_limits í…Œì´ë¸”ì—ì„œ per-user limitì„ ì½ê³ , ì—†ìœ¼ë©´ 2 ë¦¬í„´
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("SELECT daily_limit FROM board_limits WHERE username=?", (username,))
    row = cur.fetchone()
    conn.close()
    return int(row[0]) if row and row[0] is not None else 2

def _count_today_posts(username):
    day_start = int(datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0).timestamp() * 1000)
    day_end   = int(datetime.utcnow().replace(hour=23, minute=59, second=59, microsecond=999000).timestamp() * 1000)
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("""
        SELECT COUNT(*) FROM board_posts
        WHERE username=? AND ts BETWEEN ? AND ? AND (hidden IS NULL OR hidden=0)
    """, (username, day_start, day_end))
    n = cur.fetchone()[0]
    conn.close()
    return int(n or 0)

# === INSERT BLOCK between line 1935 and 1936 ===
from uuid import uuid4

DEFAULT_DAILY = 2

def _board_daily_limit(username):
    try:
        conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
        cur.execute("SELECT daily_limit FROM board_limits WHERE username=?", (username,))
        row = cur.fetchone(); conn.close()
        if row and row[0] is not None:
            return int(row[0]) or DEFAULT_DAILY
    except Exception:
        pass
    return DEFAULT_DAILY

def _count_posts_today(username):
    try:
        start = int(datetime.utcnow().replace(hour=0,minute=0,second=0,microsecond=0).timestamp()*1000)
        end   = int(datetime.utcnow().replace(hour=23,minute=59,second=59,microsecond=999999).timestamp()*1000)
        conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
        cur.execute("SELECT COUNT(1) FROM board_posts WHERE username=? AND ts BETWEEN ? AND ?",
                    (username, start, end))
        c = cur.fetchone()[0]; conn.close()
        return int(c or 0)
    except Exception:
        return 0

@app.get("/board/posts")
def board_posts_list():
    """ì½ê¸° ì „ìš©: ìµœê·¼ 100ê±´, pinned ìš°ì„ """
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("""
        SELECT id, username, text, pinned, ts
        FROM board_posts
        ORDER BY pinned DESC, ts DESC
        LIMIT 100
    """)
    rows = cur.fetchall(); conn.close()
    posts = [{"id":r[0], "user":r[1], "text":r[2], "pinned":bool(r[3]), "ts":int(r[4])} for r in rows]
    return jsonify({"posts": posts})

@app.post("/board/posts")
def board_posts_add():
    """ì‘ì„±: username/password ì¸ì¦ + ì¼ì¼ ì œí•œ"""
    payload = request.get_json(force=True, silent=True) or {}
    ok, uname, is_admin = verify_board_auth(payload)
    if not ok:
        return jsonify({"error":"auth"}), 401

    text = (payload.get("text") or "").strip()
    if not text or len(text) > 60:
        return jsonify({"error":"length"}), 400

    # ì¼ì¼ ì œí•œ(ê´€ë¦¬ìëŠ” ë¬´ì œí•œ)
    if not is_admin:
        used = _count_posts_today(uname)
        if used >= _board_daily_limit(uname):
            return jsonify({"error":"limit"}), 429

    pid = "p_" + uuid4().hex[:10]
    now = int(time.time()*1000)
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("INSERT INTO board_posts (id, username, text, pinned, ts) VALUES (?,?,?,?,?)",
                (pid, uname, text, 0, now))
    conn.commit(); conn.close()
    return jsonify({"ok":True, "id":pid, "ts":now})

@app.put("/board/posts/<pid>")
def board_posts_edit(pid):
    payload = request.get_json(force=True, silent=True) or {}
    ok, uname, is_admin = verify_board_auth(payload)
    if not ok:
        return jsonify({"error":"auth"}), 401
    text = (payload.get("text") or "").strip()
    if not text or len(text) > 60:
        return jsonify({"error":"length"}), 400

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("SELECT username FROM board_posts WHERE id=?", (pid,))
    row = cur.fetchone()
    if not row:
        conn.close(); return jsonify({"error":"not_found"}), 404
    if (row[0] != uname) and (not is_admin):
        conn.close(); return jsonify({"error":"forbidden"}), 403

    cur.execute("UPDATE board_posts SET text=? WHERE id=?", (text, pid))
    conn.commit(); conn.close()
    return jsonify({"ok":True})

@app.delete("/board/posts/<pid>")
def board_posts_delete(pid):
    payload = request.get_json(force=True, silent=True) or {}
    ok, uname, is_admin = verify_board_auth(payload)
    if not ok:
        return jsonify({"error":"auth"}), 401

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("SELECT username FROM board_posts WHERE id=?", (pid,))
    row = cur.fetchone()
    if not row:
        conn.close(); return jsonify({"error":"not_found"}), 404
    if (row[0] != uname) and (not is_admin):
        conn.close(); return jsonify({"error":"forbidden"}), 403

    cur.execute("DELETE FROM board_posts WHERE id=?", (pid,))
    conn.commit(); conn.close()
    return jsonify({"ok":True})

@app.post("/board/pin/<pid>")
def board_posts_pin(pid):
    payload = request.get_json(force=True, silent=True) or {}
    ok, uname, is_admin = verify_board_auth(payload)
    if not ok or not is_admin:
        return jsonify({"error":"admin_only"}), 403

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("SELECT pinned FROM board_posts WHERE id=?", (pid,))
    row = cur.fetchone()
    if not row:
        conn.close(); return jsonify({"error":"not_found"}), 404
    new_pin = 0 if row[0] else 1
    cur.execute("UPDATE board_posts SET pinned=? WHERE id=?", (new_pin, pid))
    conn.commit(); conn.close()
    return jsonify({"ok":True, "pinned": bool(new_pin)})

# === [ADD] ê²Œì‹œíŒ ë¯¸ë‹ˆë¡œê·¸ì¸ ê´€ë¦¬ì ì—¬ë¶€ í™•ì¸ ===
@app.post("/board/auth_check")
def board_auth_check():
    payload = request.get_json(force=True, silent=True) or {}
    ok, uname, is_admin = verify_board_auth(payload)
    if not ok:
        return jsonify({"ok": False}), 401
    return jsonify({"ok": True, "username": uname, "is_admin": bool(is_admin)})

@app.post("/admin/board/limit")
def board_limit_set():
    """ê´€ë¦¬ì: íŠ¹ì • ID ì¼ì¼ ì‘ì„± ì œí•œ ë³€ê²½"""
    payload = request.get_json(force=True, silent=True) or {}
    ok, uname, is_admin = verify_board_auth(payload)
    if not ok or not is_admin:
        return jsonify({"error":"admin_only"}), 403
    target = (payload.get("target") or "").strip().lower()
    n = int(payload.get("limit") or DEFAULT_DAILY)
    if not target:
        return jsonify({"error":"target"}), 400

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("""
        INSERT INTO board_limits (username, daily_limit)
        VALUES (?,?)
        ON CONFLICT(username) DO UPDATE SET daily_limit=excluded.daily_limit
    """, (target, n))
    conn.commit(); conn.close()
    return jsonify({"ok":True, "username": target, "limit": n})

# === Board APIs ===
@app.route("/board/list", methods=["GET"])
def board_list():
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("""
        SELECT id, username, text, pinned, ts
        FROM board_posts
        WHERE (hidden IS NULL OR hidden=0)
        ORDER BY pinned DESC, ts DESC
        LIMIT 200
    """)
    rows = cur.fetchall(); conn.close()
    items = [{"id": r[0], "user": r[1], "text": r[2], "pinned": bool(r[3]), "ts": int(r[4] or 0)} for r in rows]
    return jsonify({"ok": True, "items": items})

@app.route("/board/add", methods=["POST"])
@require_user
def board_add():
    data = (request.get_json(silent=True) or {})
    text = (data.get("text") or "").strip()
    if not text: return jsonify({"ok": False, "error":"EMPTY"}), 400
    if len(text) > 60: return jsonify({"ok": False, "error":"TOO_LONG"}), 400

    uname = _username_from_req()
    user = _get_user(uname)
    is_admin = (user or {}).get("role") == "admin"

    # ì‘ì„± ì •ì§€ ì‚¬ìš©ìë©´ ì¦‰ì‹œ ì°¨ë‹¨
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    r = cur.execute("SELECT IFNULL(posting_blocked,0) FROM users WHERE username=?", (uname,)).fetchone()
    if r and int(r[0]) == 1:
        conn.close()
        return jsonify({"ok": False, "error": "BLOCKED"}), 403
    conn.close()

    # === ì¼ì¼ ì œí•œ: KST ìì • ê¸°ì¤€ (ì‚­ì œê¸€ í¬í•¨ ì¹´ìš´íŠ¸) ===
    now_utc = datetime.utcnow()
    now_kst = now_utc + timedelta(hours=9)
    kst_midnight = datetime(now_kst.year, now_kst.month, now_kst.day, 0, 0, 0)
    boundary_utc = kst_midnight - timedelta(hours=9)
    boundary_ms = int(boundary_utc.timestamp() * 1000)

    # ê´€ë¦¬ìë©´ ë¬´ì œí•œ í†µê³¼
    if not is_admin:
        # per-user í•œë„: board_limits.daily_limit ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ 2íšŒ
        try:
            daily_limit = _default_daily_limit(uname)  # í•¨ìˆ˜ ì •ì˜: server.pyì— ì´ë¯¸ ìˆìŒ
        except Exception:
            daily_limit = 2

        conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
        cur.execute(
            "SELECT COUNT(*) FROM board_posts WHERE username=? AND ts>=?",
            (uname, boundary_ms)
        )
        used = int(cur.fetchone()[0] or 0)
        conn.close()

        if used >= int(daily_limit):
            return jsonify({
                "ok": False,
                "error": "LIMIT",
                "used": used,
                "limit": int(daily_limit),
                "reset_at_kst": int(kst_midnight.timestamp() * 1000)
            }), 400
    # (ê´€ë¦¬ìëŠ” ìœ„ ì œí•œì„ ê±´ë„ˆëœ€)


    # === ì €ì¥ ===
    pid = f"p_{int(time.time()*1000)}_{uuid.uuid4().hex[:5]}"
    ts  = int(time.time()*1000)

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute(
        "INSERT INTO board_posts (id, username, text, pinned, ts, hidden) VALUES (?,?,?,?,?,0)",
        (pid, uname, text, 0, ts)
    )
    conn.commit(); conn.close()

    return jsonify({
        "ok": True,
        "item": {"id": pid, "user": uname, "text": text, "pinned": False, "ts": ts}
    })


@app.route("/board/edit", methods=["POST"])
@require_user
def board_edit():
    data = (request.get_json(silent=True) or {})
    pid  = data.get("id") or ""
    text = (data.get("text") or "").strip()
    if not pid or not text: return jsonify({"ok": False, "error":"BAD_REQ"}), 400
    if len(text) > 60: return jsonify({"ok": False, "error":"TOO_LONG"}), 400

    uname = _username_from_req()
    user = _get_user(uname)
    is_admin = (user or {}).get("role") == "admin"

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("SELECT username FROM board_posts WHERE id=? AND (hidden IS NULL OR hidden=0)", (pid,))
    row = cur.fetchone()
    if not row: 
        conn.close(); return jsonify({"ok": False, "error": "NOT_FOUND"}), 404

    if (not is_admin) and (row[0] != uname):
        conn.close(); return jsonify({"ok": False, "error": "FORBIDDEN"}), 403

    cur.execute("UPDATE board_posts SET text=? WHERE id=?", (text, pid))
    conn.commit(); conn.close()
    return jsonify({"ok": True})

@app.route("/board/delete", methods=["POST"])
@require_user
def board_delete():
    data = (request.get_json(silent=True) or {})
    pid  = data.get("id") or ""
    if not pid: return jsonify({"ok": False, "error":"BAD_REQ"}), 400

    uname = _username_from_req()
    user = _get_user(uname)
    is_admin = (user or {}).get("role") == "admin"

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("SELECT username FROM board_posts WHERE id=? AND (hidden IS NULL OR hidden=0)", (pid,))
    row = cur.fetchone()
    if not row: 
        conn.close(); return jsonify({"ok": False, "error": "NOT_FOUND"}), 404

    if (not is_admin) and (row[0] != uname):
        conn.close(); return jsonify({"ok": False, "error": "FORBIDDEN"}), 403

    cur.execute("UPDATE board_posts SET hidden=1 WHERE id=?", (pid,))
    conn.commit(); conn.close()
    return jsonify({"ok": True})

@app.route("/board/toggle_pin", methods=["POST"])
@require_admin
def board_toggle_pin():
    data = (request.get_json(silent=True) or {})
    pid  = data.get("id") or ""
    if not pid: return jsonify({"ok": False, "error":"BAD_REQ"}), 400

    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("SELECT pinned FROM board_posts WHERE id=? AND (hidden IS NULL OR hidden=0)", (pid,))
    row = cur.fetchone()
    if not row:
        conn.close(); return jsonify({"ok": False, "error":"NOT_FOUND"}), 404

    new_pin = 0 if (row[0] or 0) else 1
    cur.execute("UPDATE board_posts SET pinned=? WHERE id=?", (new_pin, pid))
    conn.commit(); conn.close()
    return jsonify({"ok": True, "pinned": bool(new_pin)})

@app.route("/board/admin/delete_all", methods=["POST"])
@require_admin
def board_admin_delete_all():
    conn = sqlite3.connect(DB_PATH); cur = conn.cursor()
    cur.execute("UPDATE board_posts SET hidden=1 WHERE (hidden IS NULL OR hidden=0)")
    conn.commit(); conn.close()
    return jsonify({"ok": True, "all_deleted": True})

# === END INSERT BLOCK ===

if __name__ == "__main__":
    port = int(os.getenv("PORT", "5000"))
    app.run(host="0.0.0.0", port=port, debug=False)
